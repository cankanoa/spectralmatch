{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"spectralmatch: A toolkit to perform Relative Radiometric Normalization, with utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, and statistics","text":"<p>[!IMPORTANT] This library is experimental and still under heavy development.</p>"},{"location":"#overview","title":"Overview","text":"<p>spectralmatch provides a Python library and QGIS plugin with multiple algorythms to perform Relative Radiometric Normalization (RRN). It also includes utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, statistics, preprocessing, and more.</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p>Automated: Works without manual intervention, making it ideal for large-scale applications.</p> </li> <li> <p>Multiprocessing: Image, window, and band parallel processing. Cloud Optimized GeoTIFF reading and writing.</p> </li> <li> <p>Save Intermediate Steps: Save image stats and block maps for quick reprocessing.</p> </li> <li> <p>Specify Model Images Include all or specified images in the matching solution to bring all images to a central tendency or selected images spectral profile.</p> </li> <li> <p>Consistent Multi-Image Analysis: Ensures uniformity across images by applying systematic corrections with minimal spectral distortion.</p> </li> <li> <p>Seamlessly Blended: Creates smooth transitions between images.</p> </li> <li> <p>Unit Agnostic: Works with any pixel unit and preserves the spectral information for accurate analysis. This inlcludes negative numbers and reflectance.</p> </li> <li> <p>Better Input for Machine Learning Models: Provides high-quality, unbiased data for AI and analytical workflows.</p> </li> <li> <p>Sensor Agnostic: Works with all optical sensors. In addition, images from different sensors can be combined for multisensor analysis.</p> </li> <li> <p>Mosaics: Designed to process and blend vast image collections effectively.</p> </li> <li> <p>Time Series: Normalize images across time with to compare spectral changes.</p> </li> </ul>"},{"location":"#current-matching-algorithms","title":"Current Matching Algorithms","text":""},{"location":"#global-to-local-matching","title":"Global to local matching","text":"<p>This technique is derived from 'An auto-adapting global-to-local color balancing method for optical imagery mosaic' by Yu et al., 2017 (DOI: 10.1016/j.isprsjprs.2017.08.002). It is particularly useful for very high-resolution imagery (satellite or otherwise) and works in a two phase process. First, this method applies least squares regression to estimate scale and offset parameters that align the histograms of all images toward a shared spectral center. This is achieved by constructing a global model based on the overlapping areas of adjacent images, where the spectral relationships are defined. This global model ensures that each image conforms to a consistent radiometric baseline while preserving overall color fidelity. However, global correction alone cannot capture intra-image variability so a second local adjustment phase is performed. The overlap areas are divided into smaller blocks, and each block\u2019s mean is used to fine-tune the color correction. This block-wise tuning helps maintain local contrast and reduces visible seams, resulting in seamless and spectrally consistent mosaics with minimal distortion.</p> <p> Shows the average spectral profile of two WorldView 3 images before and after global to local matching.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<ul> <li> <p>Consistent Spectral Profile: The true spectral response of overlapping areas remains the same throughout the images.</p> </li> <li> <p>Least Squares Modeling: A least squares approach can effectively model and fit all images' spectral profiles.</p> </li> <li> <p>Scale and Offset Adjustment: Applying scale and offset corrections can effectively harmonize images.</p> </li> <li> <p>Minimized Color Differences: The best color correction is achieved when color differences are minimized.</p> </li> <li> <p>Geometric Alignment: Images are assumed to be geometrically aligned with known relative positions.</p> </li> <li> <p>Global Consistency: Overlapping color differences are consistent across the entire image.</p> </li> <li> <p>Local Adjustments: Block-level color differences result from the global application of adjustments.</p> </li> </ul>"},{"location":"#quick-installation-other-methods","title":"Quick Installation (Other methods)","text":""},{"location":"#installation-as-a-qgis-plugin","title":"Installation as a QGIS Plugin","text":"<p>Install the spectralmatch plugin in QGIS and use it in the Processing Toolbox.</p>"},{"location":"#installation-as-a-python-library","title":"Installation as a Python Library","text":"<p>Before installing, ensure you have the following system-level prerequisites: <code>Python \u2265 3.10</code>, <code>pip</code>, <code>PROJ \u2265 9.3</code>, and <code>GDAL = 3.10.2</code>. Use this command to install the library:</p> <pre><code>pip install spectralmatch\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at spectralmatch.github.io/spectralmatch/.</p>"},{"location":"#contributing-guide","title":"Contributing Guide","text":"<p>Contributing Guide is available at spectralmatch.github.io/spectralmatch/contributing.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See LICENSE for details.</p>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>Thank you for your interest in contributing. The sections below outline how the library is structured, how to submit changes, and the conventions to follow when developing new features or improving existing functionality.</p> <p>For convenience, you can copy this auto updated LLM priming prompt with function headers and docs.</p>"},{"location":"contributing/#collaboration-instructions","title":"Collaboration Instructions","text":"<p>We welcome all contributions the project! Please be respectful and work towards improving the library. To get started:</p> <ol> <li> <p>Create an issue describing the feature or bug or just to ask a question. Provide relevant context, desired timeline, any assistance needed, who will be responsible for the work, anticipated results, and any other details.</p> </li> <li> <p>Fork the repository and create a new feature branch.</p> </li> <li> <p>Make your changes and add any necessary tests.</p> </li> <li> <p>Open a Pull Request against the main repository.</p> </li> </ol>"},{"location":"contributing/#design-philosophy","title":"Design Philosophy","text":"<ul> <li>Keep code concise and simple</li> <li>Adapt code for large datasets with windows, multiprocessing, progressive computations, etc</li> <li>Keep code modular and have descriptive names</li> <li>Use PEP 8 code formatting</li> <li>Use functions that are already created when possible</li> <li>Combine similar params into one multi-value parameter</li> <li>Use similar naming convention and input parameter format as other functions.</li> <li>Create docstrings (Google style), tests, and update the docs for new functionality</li> </ul>"},{"location":"contributing/#extensible-function-types","title":"Extensible Function Types","text":"<p>In Relative Radiometric Normalization (RRN) methods often differ in how images are matched, pixels are selected, and seamlines are created. This library organizes those into distinct Python packages, while other operations like aligning rasters, applying masks, merging images, and calculating statistics are more consistent across techniques and are treated as standard utilities.</p>"},{"location":"contributing/#matching-functions","title":"Matching functions","text":"<p>Used to adjust the pixel values of images to ensure radiometric consistency across scenes. These functions compute differences between images and apply transformations so that brightness, contrast, or spectral characteristics align across datasets.</p>"},{"location":"contributing/#masking-functions-pifrcs","title":"Masking functions (PIF/RCS)","text":"<p>Used to define which parts of an image should be kept or discarded based on spatial criteria. These functions apply vector-based filters or logical rules to isolate regions of interest, remove clouds, or exclude invalid data from further processing.</p>"},{"location":"contributing/#seamline-functions","title":"Seamline functions","text":"<p>Used to determine optimal boundaries between overlapping image regions. These functions generate cutlines that split image footprints in a way that minimizes visible seams and balances spatial coverage, often relying on geometric relationships between overlapping areas.</p>"},{"location":"contributing/#standard-ui","title":"Standard UI","text":"<p>Reusable types are organized into the types and validation module. Use these types directly as the types of params inside functions where applicable. Use the appropriate _resolve... function to resolve these inputs into usable variables.</p>"},{"location":"contributing/#inputoutput","title":"Input/Output","text":"<p>The input_images parameter accepts either a tuple or a list. If given as a tuple, it should contain a folder path and a glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). Alternatively, it can be a list of full file paths to individual input images. The output_images parameter defines how output filenames are determined. It can also be a tuple, consisting of an output folder and a filename template where \"$\" is replaced with each input image\u2019s basename (e.g., (\"/output/folder\", \"$_GlobalMatch.tif\")). Alternatively, it may be a list of full output paths, which must match the number of input images. <pre><code># Params\ninput_images\noutput_images\n\n# Types\nSearchFolderOrListFiles = Tuple[str, str] | List[str] # Required\nCreateInFolderOrListFiles = Tuple[str, str] | List[str] # Required\n\n# Resolve\ninput_image_paths = _resolve_paths(\"search\", input_images)\noutput_image_paths = _resolve_paths(\"create\", output_images, (input_image_paths,))\n</code></pre></p>"},{"location":"contributing/#output-dtype","title":"Output dtype","text":"<p>The custom_output_dtype parameter specifies the data type for output rasters and defaults to the input image\u2019s data type if not provided. <pre><code># Param\ncustom_output_dtype\n\n# Type\nCustomOutputDtype = str | None # Default: None\n\n# Resolve\noutput_dtype = _resolve_output_dtype(rasterio.DatasetReader, custom_output_dtype)\n</code></pre></p>"},{"location":"contributing/#nodata-value","title":"Nodata Value","text":"<p>The custom_nodata_value parameter overrides the input nodata value from the first raster in the input rasters if set.  <pre><code># Param\ncustom_nodata_value\n\n# Type\nCustomNodataValue = float | int | None # Default: None\n\n# Resolve\nnodata_value = _resolve_nodata_value(rasterio.DatasetReader, custom_nodata_value)\n</code></pre></p>"},{"location":"contributing/#debug-logs","title":"Debug Logs","text":"<p>The debug_logs parameter enables printing of debug information; it defaults to False. Functions should begin by printing \"Start {process name}\", while all other print statements should be conditional on debug_logs being True. <pre><code># Param\ndebug_logs\n\n# Type\nDebugLogs = bool # Default: False\n\n# No resolve function necessary\n</code></pre></p>"},{"location":"contributing/#vector-mask","title":"Vector Mask","text":"<p>The vector_mask parameter limits statistics calculations to specific areas and is given as a tuple with two or three items: a literal \"include\" or \"exclude\" to define how the mask is applied, a string path to the vector file, and an optional field name used to match geometries based on the input image name (substring match allowed). Defaults to None for no mask.</p> <pre><code># Param\nvector_mask\n\n# Type\nVectorMask = Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None\n\n# No resolve function necessary\n</code></pre>"},{"location":"contributing/#parallel-workers","title":"Parallel Workers","text":"<p>The image_parallel_workers parameter defines the parallelization strategy at the image level. It accepts a tuple such as (\"process\", \"cpu\") to enable multiprocessing across all available CPU cores, or you can use \"thread\" as the backend if threading is preferred. Set it to None to disable image-level parallelism. The window_parallel_workers parameter controls parallelization within each image at the window level and follows the same format. Setting it to None disables window-level parallelism. Processing windows should be done one band at a time for scalability. <pre><code># Params\nimage_parallel_workers\nwindow_parallel_workers\n\n# Types\nImageParallelWorkers = Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None\nWindowParallelWorkers = Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None\n\n# Resolve\nimage_parallel, image_backend, image_max_workers = _resolve_parallel_config(image_parallel_workers)\nwindow_parallel, window_backend, window_max_workers = _resolve_parallel_config(window_parallel_workers)\n\n\n# Main process example\nimage_args = [(arg, other_args, ...) for arg in inputs]\nif image_parallel:\n    with _get_executor(image_backend, image_max_workers) as executor:\n        futures = [executor.submit(_name_process_image, *arg) for arg in image_args]\n        for future in as_completed(futures):\n                result = future.result()\nelse:\n        for arg in image_args:\n            result = _name_process_image(*arg)\n\ndef _name_process_image(image_name, arg_1, arg_2, ...):\n    with rasterio.open(input_image_path) as src:\n        # Open output image as well if saving to image\n        windows = _resolve_windows(src, window_size)\n        window_args = [(window, other_args, ...) for window in windows]\n\n        with _get_executor(\n            window_backend, \n            window_max_workers,\n            initializer=WorkerContext.init,\n            initargs=({image_name: (\"raster\", input_image_path)},)\n            ) as executor:\n            futures = [executor.submit(_name_process_window, *arg) for arg in window_args]\n            for future in as_completed(futures):\n                band, window, result = future.result()\n                # Save result to variable or dataset\n        else:\n            WorkerContext.init({image_name: (\"raster\", input_image_path)})\n            for arg in window_args:\n                band, window, buf = _name_process_window(*arg)\n                # Save result to variable or dataset\n            WorkerContext.close()\n\ndef _name_process_window(image_name, arg_1, arg_2, ...):\n    ds = WorkerContext.get(image_name)\n    # Process result to return\n\n    return band, window, data\n</code></pre></p>"},{"location":"contributing/#windows","title":"Windows","text":"<p>The window_size parameter sets the tile size for reading and writing, using an integer for square tiles, a tuple for custom dimensions, \"internal\" to use the raster\u2019s native tiling (ideal for efficient streaming from COGs), or None to process the full image at once. <pre><code># Param\nwindow_size\n\n# Types\nWindowSize = int | Tuple[int, int] | Literal[\"internal\"] | None\nWindowSizeWithBlock = int | Tuple[int, int] | Literal[\"internal\", \"block\"] | None\n\n# Resolve\nwindows = _resolve_windows(rasterio.DatasetReader, window_size)\n</code></pre></p>"},{"location":"contributing/#cogs","title":"COGs","text":"<p>The save_as_cog parameter, when set to True, saves the output as a Cloud-Optimized GeoTIFF with correct band and block ordering. <pre><code># Param\nSaveAsCog = bool # Default: True\n\n# Type\nSaveAsCog = bool # Default: True\n\n# No resolve function necessary\n</code></pre></p>"},{"location":"contributing/#validate-inputs","title":"Validate Inputs","text":"<p>The validate methods are used to check that input parameters follow expected formats before processing begins. There are different validation methods for different scopes\u2014some are general-purpose (e.g., Universal.validate) and others apply to specific contexts like matching (Match.validate_match). These functions raise clear errors when inputs are misconfigured, helping catch issues early and enforce consistent usage patterns across the library. <pre><code># Validate params example\nUniversal.validate(\n    input_images=input_images,\n    output_images=output_images,\n    vector_mask=vector_mask,\n)\nMatch.validate_match(\n    specify_model_images=specify_model_images,\n    )\n</code></pre></p>"},{"location":"contributing/#file-cleanup","title":"File Cleanup","text":"<p>Temporary generated files can be deleted once they are no longer needed via this command: <pre><code>make clean\n</code></pre></p>"},{"location":"contributing/#docs","title":"Docs","text":""},{"location":"contributing/#serve-docs-locally","title":"Serve docs locally","text":"<p>Runs a local dev server at http://localhost:8000. <pre><code>make docs-serve\n</code></pre></p>"},{"location":"contributing/#build-static-site","title":"Build static site","text":"<p>Generates the static site into the site/ folder.</p> <pre><code>make docs-build\n</code></pre>"},{"location":"contributing/#deploy-to-github-pages","title":"Deploy to GitHub Pages","text":"<p>Deploys built site using mkdocs gh-deploy. <pre><code>make docs-deploy\n</code></pre></p>"},{"location":"contributing/#versioning","title":"Versioning","text":"<p>Uses git tag to create annotated version tags and push them. This also syncs to Pypi. New versions will be released when the maintainer determines sufficient new functionality has been added. <pre><code>make tag version=1.2.3\n</code></pre></p>"},{"location":"contributing/#code-formatting","title":"Code Formatting","text":"<p>This project uses black for code formatting and ruff for linting.</p>"},{"location":"contributing/#set-up-pre-commit-hooks-recommended","title":"Set Up Pre-commit Hooks (Recommended)","text":"<p>To maintain code consistency use this hook to check and correct code formatting automatically:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>"},{"location":"contributing/#manual-formatting","title":"Manual Formatting","text":"<p>Format code: Automatically formats all Python files with black.</p> <pre><code>make format\n</code></pre> <p>Check formatting: Checks that all code is formatted (non-zero exit code if not). <pre><code>make check-format\n</code></pre></p> <p>Lint code: Runs ruff to catch style and quality issues. <pre><code>make lint\n</code></pre></p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>pytest is used for testing. Tests will automatically be run when merging into main but they can also be run locally via: <pre><code>make test\n</code></pre></p> <p>To test a individual folder or file: <pre><code>make test-file path=path/to/folder_or_file\n</code></pre></p>"},{"location":"create_llm_prompt/","title":"Create llm prompt","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport fnmatch\nimport ast\nfrom html import escape\nfrom mkdocs_gen_files import open as gen_open\n</pre> import os import fnmatch import ast from html import escape from mkdocs_gen_files import open as gen_open In\u00a0[\u00a0]: Copied! <pre>def create_initial_prompt_text() -&gt; str:\n    return (\n        \"# LLM Prompt\\n\\n\"\n        \"The following content includes function signatures and docstrings from Python source files, as well as relevant Markdown documentation. Each section is labeled by its relative file path. Use this as context to understand the project structure, purpose, and functionality.\\n\\n\"\n    )\n</pre> def create_initial_prompt_text() -&gt; str:     return (         \"# LLM Prompt\\n\\n\"         \"The following content includes function signatures and docstrings from Python source files, as well as relevant Markdown documentation. Each section is labeled by its relative file path. Use this as context to understand the project structure, purpose, and functionality.\\n\\n\"     ) In\u00a0[\u00a0]: Copied! <pre>def parse_python_files_to_prompt_text(input_directory=\"spectralmatch\", include_filter=\"*.py\", only_include_function_headers=True) -&gt; str:\n    prompt_lines = []\n    for root, _, files in os.walk(input_directory):\n        for filename in fnmatch.filter(files, include_filter):\n            file_path = os.path.join(root, filename)\n            rel_path = os.path.relpath(file_path, input_directory)\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    code = f.read()\n                tree = ast.parse(code)\n            except SyntaxError:\n                continue\n\n            lines_for_file = []\n            if only_include_function_headers:\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.FunctionDef):\n                        args = [arg.arg for arg in node.args.args]\n                        sig = f\"def {node.name}({', '.join(args)}):\"\n                        doc = ast.get_docstring(node)\n                        if doc:\n                            sig += f'\\n    \"\"\"{doc}\"\"\"'\n                        lines_for_file.append(sig)\n            else:\n                lines_for_file.append(code)\n\n            if lines_for_file:\n                prompt_lines.append(f\"### File: {rel_path}\")\n                prompt_lines.extend(lines_for_file)\n\n    if not prompt_lines:\n        return \"\"\n    return \"## Python Section\\n\" + \"\\n\\n\".join(prompt_lines) + \"\\n\"\n</pre> def parse_python_files_to_prompt_text(input_directory=\"spectralmatch\", include_filter=\"*.py\", only_include_function_headers=True) -&gt; str:     prompt_lines = []     for root, _, files in os.walk(input_directory):         for filename in fnmatch.filter(files, include_filter):             file_path = os.path.join(root, filename)             rel_path = os.path.relpath(file_path, input_directory)             try:                 with open(file_path, \"r\", encoding=\"utf-8\") as f:                     code = f.read()                 tree = ast.parse(code)             except SyntaxError:                 continue              lines_for_file = []             if only_include_function_headers:                 for node in ast.walk(tree):                     if isinstance(node, ast.FunctionDef):                         args = [arg.arg for arg in node.args.args]                         sig = f\"def {node.name}({', '.join(args)}):\"                         doc = ast.get_docstring(node)                         if doc:                             sig += f'\\n    \"\"\"{doc}\"\"\"'                         lines_for_file.append(sig)             else:                 lines_for_file.append(code)              if lines_for_file:                 prompt_lines.append(f\"### File: {rel_path}\")                 prompt_lines.extend(lines_for_file)      if not prompt_lines:         return \"\"     return \"## Python Section\\n\" + \"\\n\\n\".join(prompt_lines) + \"\\n\" In\u00a0[\u00a0]: Copied! <pre>def parse_markdown_files_to_prompt_text(input_directory=\"docs\", include_filter=\"*.md\", exclude_filter=\"*prompt*\") -&gt; str:\n    prompt_lines = []\n    for root, _, files in os.walk(input_directory):\n        for filename in files:\n            if fnmatch.fnmatch(filename, include_filter):\n                if exclude_filter and fnmatch.fnmatch(filename, exclude_filter):\n                    continue\n                file_path = os.path.join(root, filename)\n                rel_path = os.path.relpath(file_path, input_directory)\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    content = f.read()\n                prompt_lines.append(f\"### File: {rel_path}\\n{content.strip()}\\n\")\n    if not prompt_lines:\n        return \"\"\n    return \"## Markdown Section\\n\" + \"\\n\\n\".join(prompt_lines) + \"\\n\"\n</pre> def parse_markdown_files_to_prompt_text(input_directory=\"docs\", include_filter=\"*.md\", exclude_filter=\"*prompt*\") -&gt; str:     prompt_lines = []     for root, _, files in os.walk(input_directory):         for filename in files:             if fnmatch.fnmatch(filename, include_filter):                 if exclude_filter and fnmatch.fnmatch(filename, exclude_filter):                     continue                 file_path = os.path.join(root, filename)                 rel_path = os.path.relpath(file_path, input_directory)                 with open(file_path, \"r\", encoding=\"utf-8\") as f:                     content = f.read()                 prompt_lines.append(f\"### File: {rel_path}\\n{content.strip()}\\n\")     if not prompt_lines:         return \"\"     return \"## Markdown Section\\n\" + \"\\n\\n\".join(prompt_lines) + \"\\n\" In\u00a0[\u00a0]: Copied! <pre>def main() -&gt; str:\n    # Build prompt content\n    parts = [\n        create_initial_prompt_text(),\n        parse_python_files_to_prompt_text(),\n        parse_markdown_files_to_prompt_text()\n    ]\n    prompt = \"\\n\".join(filter(None, parts))\n\n    # Load template and inject\n    template_path = os.path.join(\"docs\", \"llm_prompt.md\")\n    with open(template_path, \"r\", encoding=\"utf-8\") as tf:\n        template = tf.read()\n\n    return template.replace(\"{prompt_content}\", prompt)\n</pre> def main() -&gt; str:     # Build prompt content     parts = [         create_initial_prompt_text(),         parse_python_files_to_prompt_text(),         parse_markdown_files_to_prompt_text()     ]     prompt = \"\\n\".join(filter(None, parts))      # Load template and inject     template_path = os.path.join(\"docs\", \"llm_prompt.md\")     with open(template_path, \"r\", encoding=\"utf-8\") as tf:         template = tf.read()      return template.replace(\"{prompt_content}\", prompt) In\u00a0[\u00a0]: Copied! <pre># Write to output during mkdocs build\nwith gen_open(\"llm_prompt.md\", \"w\") as f:\n    f.write(main())\n</pre> # Write to output during mkdocs build with gen_open(\"llm_prompt.md\", \"w\") as f:     f.write(main())"},{"location":"formats_and_requirements/","title":"File Formats and Input Requirements","text":""},{"location":"formats_and_requirements/#input-raster-requirements","title":"Input Raster Requirements","text":"<p>Input rasters must meet specific criteria to ensure compatibility during processing. These are checked by _check_raster_requirements():</p> <ul> <li>Have a valid geotransform</li> <li>Share the same coordinate reference system (CRS)</li> <li>Have an identical number of bands</li> <li>Use consistent nodata values</li> </ul> <p>Additionally, all rasters should:</p> <ul> <li>Be a <code>.tif</code> file</li> <li>Have overlap which represents the same data in each raster</li> <li>Have a consistent spectral profile </li> </ul>"},{"location":"formats_and_requirements/#regression-parameters-file","title":"Regression Parameters File","text":"<p>Regression parameters can be stored in a <code>json</code> file which includes:</p> <ul> <li>Adjustments: Per-band scale and offset values applied to each image.</li> <li>Whole Stats: Per-band mean, std, and size representing overall image statistics.</li> <li>Overlap Stats: Per-image pair mean, std, and size for overlapping geometry regions.</li> </ul> <p>The structure is a dictionary keyed by images basenames (no extension) with the following format:</p> <p><pre><code>{\n  \"image_name\": {\n    \"adjustments\": {\n      \"band_0\": {\"scale\": float, \"offset\": float},\n      ...\n    },\n    \"whole_stats\": {\n      \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n      ...\n    },\n    \"overlap_stats\": {\n      \"other_image\": {\n        \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n        ...\n      },\n      ...\n    }\n  },\n  ...\n}\n</code></pre> This format represents the following: For each image_name there are adjustment, whole_stats and overlap_stats. For each adjustments, for each band, there is scale and offset. For each whole_stats and overlap_stats, for each band, there is mean, std, and size (number of pixels). Each band key follows the format band_0, band_1, etc. Mean and std are floats and size is an integer.</p> <p>This structure is validated by <code>_validate_adjustment_model_structure()</code> before use to ensure consistency and completeness across images and bands. Global regression does not actually use 'adjustments' field because they are recalculated every run.</p>"},{"location":"formats_and_requirements/#block-maps-file","title":"Block Maps File","text":"<p>Block maps are spatial summaries of raster data, where each block represents the mean values of a group of pixels over a fixed region. They are used to reduce image resolution while preserving local radiometric characteristics, enabling efficient comparison and adjustment across images. Each map is structured as a grid of blocks with values for each spectral band. They can be saved as regular <code>geotif</code> files and together store this information: block_local_means, block_reference_mean, num_row, num_col, bounds_canvas_coords. </p> <p>There are two types of block maps, although their format is exactly the same:</p> <ul> <li>Local Block Map: Each block stores the mean value of all pixels within its boundary for a single image.</li> <li>Reference Block Map: Each block is the mean of all images means for its boundary; simply the mean of all local block maps.</li> </ul> <p>Both block maps have the shape: <code>num_row, num_col, num_bands</code>, however, there are multiple (one for each image) local block maps and only one reference block map. Once a reference block map is created it is unique to its input images and cannot be accurately modified to add additional images. However, images can be 'brought' to a reference block map even if they were not involved in its creation as long as it covers that image.</p>"},{"location":"installation/","title":"Installation Methods","text":""},{"location":"installation/#installation-as-qgis-plugin-for-easy-gui-interface","title":"Installation as QGIS Plugin for Easy GUI Interface","text":""},{"location":"installation/#1-download-and-install-qgis","title":"1. Download and install QGIS","text":""},{"location":"installation/#2-open-qgis","title":"2.  Open QGIS","text":""},{"location":"installation/#3-go-to-plugins-manage-and-install-plugins","title":"3.  Go to Plugins \u2192 Manage and Install Plugins\u2026","text":""},{"location":"installation/#4-find-spectralmatch-in-the-list-install-and-enable-it","title":"4.  Find spectralmatch in the list, install, and enable it","text":""},{"location":"installation/#5-find-the-plugin-in-the-processing-toolbox","title":"5.  Find the plugin in the Processing Toolbox","text":""},{"location":"installation/#installation-as-a-python-library-for-use-in-code-recommended","title":"Installation as a Python Library for use in Code (Recommended)","text":""},{"location":"installation/#1-system-requirements","title":"1. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL = 3.10.2</li> <li>pip</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python=3.10 \"gdal=3.10.2\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"installation/#2-install-spectralmatch","title":"2. Install spectralmatch","text":"<p>You can automatically install the library via PyPI. (this method installs only the core code as a library):</p> <pre><code>pip install spectralmatch\n</code></pre>"},{"location":"installation/#3-run-an-example-and-modify-for-your-use-optional","title":"3. Run an example and modify for your use (optional)","text":"<p>Example scripts are provided to verify a successful installation and help you get started quickly in the repository at <code>/docs/examples</code> and downloadable via this <code>link</code>.</p>"},{"location":"installation/#installation-as-python-code-for-development-and-customization","title":"Installation as Python Code for Development and Customization","text":""},{"location":"installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\n</code></pre> <p>Assuming you have Make installed, you can then run <code>make install-setup</code> to automatically complete the remaining setup steps.</p>"},{"location":"installation/#2-system-requirements","title":"2. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL = 3.10.2</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python=3.10 \"gdal=3.10.2\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"installation/#3-install-dependancies-optional-dev-and-docs-dependancies","title":"3. Install Dependancies (Optional Dev and Docs Dependancies)","text":"<p>The <code>pyproject.toml</code> defines core dependancies to run the library and optional dev, and docs dependancies.</p> <pre><code>pip install . # normal dependencies\npip install -e \".[dev]\"   # developer dependencies\npip install -e \".[docs]\"  # documentation dependencies\n</code></pre>"},{"location":"installation/#4-read-the-contributing-guide-if-you-aim-to-contribute","title":"4. Read the Contributing Guide if you aim to contribute","text":""},{"location":"llm_prompt/","title":"LLM Prompt","text":"<p>Use this text to prompt LLM models with context about this codebase which includes function headers and docs.</p> \ud83d\udccb Copy <p>\u2705 Copied!</p> \u2b05 To Readme <pre>\n# LLM Prompt\n\nThe following content includes function signatures and docstrings from Python source files, as well as relevant Markdown documentation. Each section is labeled by its relative file path. Use this as context to understand the project structure, purpose, and functionality.\n\n\n## Python Section\n### File: utils_multiprocessing.py\n\ndef _choose_context(prefer_fork):\n    \"\"\"Chooses the most appropriate multiprocessing context based on platform and preference.\n\nArgs:\n    prefer_fork (bool): If True, prefers \"fork\" context where available; default is True.\n\nReturns:\n    mp.context.BaseContext: Selected multiprocessing context (\"fork\", \"forkserver\", or \"spawn\").\"\"\"\n\ndef _resolve_parallel_config(config):\n    \"\"\"Parses a parallel worker config into execution flags and worker count.\n\nArgs:\n    config (Tuple[\"process\" | \"thread\", \"cpu\" | int] | None): Parallelization strategy; None disables parallelism.\n\nReturns:\n    Tuple[bool, Optional[str], Optional[int]]:\n        - Whether to run in parallel,\n        - The backend (\"process\" or \"thread\"),\n        - Number of workers.\"\"\"\n\ndef _get_executor(backend, max_workers, initializer, initargs):\n    \"\"\"Creates a parallel executor (process or thread) with optional initialization logic.\n\nArgs:\n    backend (str): Execution backend, either \"process\" or \"thread\".\n    max_workers (int): Maximum number of worker processes or threads.\n    initializer (Callable, optional): Function to initialize worker context.\n    initargs (tuple, optional): Arguments to pass to the initializer.\n\nReturns:\n    Executor: An instance of ThreadPoolExecutor or ProcessPoolExecutor.\n\nRaises:\n    ValueError: If the backend is not \"process\" or \"thread\".\"\"\"\n\ndef _run_parallel_images(image_paths, run_parallel_windows, image_parallel_workers, window_parallel_workers):\n    \"\"\"Runs a window-level processing function across multiple images, with optional image-level parallelism.\n\nArgs:\n    image_paths (List[str]): List of input image file paths.\n    run_parallel_windows (Callable): Function to run on each image, accepting (path, window_parallel_workers).\n    image_parallel_workers (Tuple[\"process\" | \"thread\", \"cpu\" | int] | None): Strategy for image-level parallelism.\n    window_parallel_workers (Tuple[\"process\" | \"thread\", \"cpu\" | int] | None): Passed to `run_parallel_windows` for window-level parallelism.\n\nReturns:\n    None\"\"\"\n\ndef _run_parallel_windows(windows, process_fn, window_parallel_workers):\n    \"\"\"Runs a processing function on a list of windows, with optional parallel execution.\n\nArgs:\n    windows (List[Any]): List of window-like objects to process.\n    process_fn (Callable[[Any], Any]): Function to run on each window.\n    window_parallel_workers (Tuple[\"process\" | \"thread\", \"cpu\" | int] | None): Parallel execution strategy; None disables parallelism.\n\nReturns:\n    None\"\"\"\n\ndef _resolve_windows(dataset, window_size):\n    \"\"\"Generates a list of windows for reading a raster dataset based on the given tiling strategy.\n\nArgs:\n    dataset (rasterio.DatasetReader): Open raster dataset.\n    window_size (int | Tuple[int, int] | Literal[\"internal\", \"block\"] | None):\n        Tiling strategy:\n        - int: square tile size,\n        - (int, int): custom width and height in pixels,\n        - \"internal\": use native tiling of dataset,\n        - \"block\": tile by block layout defined in `block_params`,\n        - None: single full-image window.\n\n    block_params (Tuple[int, int, Tuple[float, float, float, float]] | None, optional):\n        Required if window_size is \"block\". A tuple of:\n        - number of block rows (int),\n        - number of block columns (int),\n        - bounding box (minx, miny, maxx, maxy) of canvas extent in image coordinates.\n\nReturns:\n    List[Window]: List of rasterio Windows that cover the dataset.\"\"\"\n\ndef _create_windows(width, height, tile_width, tile_height):\n    \"\"\"Generates tiled windows across a raster based on specified dimensions.\n\nArgs:\n    width (int): Total width of the raster.\n    height (int): Total height of the raster.\n    tile_width (int): Width of each tile.\n    tile_height (int): Height of each tile.\n\nYields:\n    rasterio.windows.Window: A window representing a tile's position and size.\"\"\"\n\ndef init(cls, config):\n    \"\"\"Initializes per-process context from a typed config dictionary.\n\nEach entry maps a key to a tuple describing how to initialize a resource:\n\n    - ('raster', filepath): Open raster with rasterio.\n    - ('shm', shm_name): Attach to shared memory.\n    - ('array', shm_name, shape, dtype): Create NumPy array from shared memory.\n    - ('value', literal): Store a direct Python value.\n\nExamples:\n    {\n        \"input\": (\"raster\", \"/path/to/image.tif\"),\n        \"weights\": (\"array\", \"shm_weights\", (512, 512), \"float32\"),\n        \"debug\": (\"value\", True)\n    }\n\nResources are stored in WorkerContext.cache and accessed via WorkerContext.get(key).\"\"\"\n\ndef get(cls, key):\n\ndef close(cls):\n\n### File: types_and_validation.py\n\ndef validate():\n\ndef validate_match():\n\ndef validate_global_regression():\n\ndef validate_local_block_adjustment():\n\ndef _validate_window_param(val):\n\n### File: handlers.py\n\ndef _resolve_output_dtype(dataset, custom_output_dtype):\n    \"\"\"Resolves the output dtype for a raster operation.\n\nArgs:\n    dataset (rasterio.io.DatasetReader): The input dataset to derive default dtype from.\n    custom_output_dtype (str | None): A user-specified output dtype, or None to use dataset dtype.\n\nReturns:\n    str: The resolved output dtype.\"\"\"\n\ndef _resolve_nodata_value(dataset, custom_nodata_value):\n    \"\"\"Determine the appropriate nodata value for a raster dataset.\n\nPriority is given to a user-provided custom nodata value. If not provided, the function attempts to use the nodata value defined in the dataset metadata. Returns None if neither is available.\n\nArgs:\n    dataset (rasterio.io.DatasetReader): The opened raster dataset.\n    custom_nodata_value (float | int | None): Optional user-defined nodata value.\n\nReturns:\n    float | int | None: The resolved nodata value, or None if unavailable.\"\"\"\n\ndef _resolve_paths(mode, input, args):\n    \"\"\"Resolves a list of input based on the mode and input format.\n\nArgs:\n    mode (Literal[\"search\", \"create\", \"match\", \"name\"]): Type of operation to perform.\n    input (Tuple[str, str] | List[str]): Either a list of file input or a tuple specifying folder/template info.\n    args (Tuple): Additional arguments passed to the called function.\n\nReturns:\n    List[str]: List of resolved input.\"\"\"\n\ndef search_paths(folder_path, pattern, recursive, match_to_paths, debug_logs):\n    \"\"\"Search for files in a folder using a glob pattern.\n\nArgs:\n    folder_path (str): The root folder to search in.\n    pattern (str): A glob pattern (e.g., \"*.tif\", \"**/*.jpg\").\n    recursive (bool, optional): Whether to search for files recursively.\n    match_to_paths (Tuple[List[str], str], optional): If provided, match `reference_paths` to `input_match_paths` using a regex applied to the basenames of `input_match_paths`. The extracted key must be a substring of the reference filename.\n        - reference_paths (List[str]): List of reference paths to align to.\n        - match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via *inclusion* in reference_paths (e.g. \"(.*)_LocalMatch.gpkg$\").\n    debug_logs (bool, optional): Whether to print the matched file paths.\n\nReturns:\n    List[str]: Sorted list of matched file paths.\"\"\"\n\ndef create_paths(output_folder, template, paths_or_bases, debug_logs, replace_symbol, create_folders):\n    \"\"\"Create output paths using a filename template and a list of reference paths or names.\n\nArgs:\n    output_folder (str): Directory to store output files.\n    template (str): Filename template using replace_symbol as placeholder (e.g., \"$_processed.tif\").\n    paths_or_bases (List[str]): List of full paths or bare names to derive replace_symbol from. Inclusion of '/' or '' indicates a path.\n    debug_logs (bool): Whether to print the created paths.\n    replace_symbol (str): Symbol to replace in the template.\n    create_folders (bool): Whether to create output folders if they don't exist.'\n\nReturns:\n    List[str]: List of constructed file paths.\"\"\"\n\ndef match_paths(input_match_paths, reference_paths, match_regex, debug_logs):\n    \"\"\"Match `reference_paths` to `input_match_paths` using a regex applied to the basenames of `input_match_paths`. The extracted key must be a substring of the reference filename.\n\nArgs:\n    input_match_paths (List[str]): List of candidate paths to extract keys from.\n    reference_paths (List[str]): List of reference paths to align to.\n    match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via *inclusion* in reference_paths (e.g. \"(.*)_LocalMatch\\.gpkg$\" (without one of the backslashes)).\n    debug_logs (bool): If True, print matched and unmatched file basenames.\n\nReturns:\n    List[Optional[str]]: A list the same length as `reference_paths` where each\n    element is the matched path from `input_match_paths` or None.\n\nRaises:\n    ValueError: If output list length does not match reference_paths length.\"\"\"\n\ndef _check_raster_requirements(input_image_paths, debug_logs, check_geotransform, check_crs, check_bands, check_nodata, check_resolution):\n    \"\"\"Validates a list of raster image paths to ensure they are compatible for processing.\n\nArgs:\n    input_image_paths (list[str]): Paths to input raster images.\n    debug_logs (bool): If True, prints debug messages.\n    check_geotransform (bool): Check that all images have a valid geotransform.\n    check_crs (bool): Check that all images have the same CRS.\n    check_bands (bool): Check that all images have the same number of bands.\n    check_nodata (bool): Check that all images have the same nodata values per band.\n    check_resolution (bool): Check that all images have the same resolution.\n\nReturns:\n    bool: True if all checks pass.\n\nRaises:\n    ValueError: If any check fails.\"\"\"\n\ndef _get_nodata_value(input_image_paths, custom_nodata_value):\n    \"\"\"Determines the NoData value to use from a list of raster images or a custom override.\n\nArgs:\n    input_image_paths (List[str]): List of raster image paths.\n    custom_nodata_value (float, optional): User-defined NoData value.\n\nReturns:\n    float | None: The determined NoData value, or None if unavailable.\n\nWarnings:\n    Emits a warning if a custom value overrides the image value or if no value is found.\"\"\"\n\n### File: utils.py\n\ndef merge_vectors(input_vector_paths, merged_vector_path, method, debug_logs, create_name_attribute):\n    \"\"\"Merge multiple vector files using the specified geometric method.\n\nArgs:\n    input_vector_paths (List[str]): Paths to input vector files.\n    merged_vector_path (str): Path to save merged output.\n    method (Literal[\"intersection\", \"union\", \"keep\"]): Merge strategy.\n    debug_logs (bool): If True, print debug information.\n    create_name_attribute (Optional[Tuple[str, str]]): Tuple of (field_name, separator).\n        If set, adds a field with all input filenames (no extension), joined by separator.\n\nReturns:\n    None\"\"\"\n\ndef align_rasters(input_images, output_images):\n    \"\"\"Aligns multiple rasters to a common resolution and grid using specified resampling.\n\nArgs:\n    input_images (Universal.SearchFolderOrListFiles): Tuple (folder, pattern) or list of input raster paths.\n    output_images (Universal.CreateInFolderOrListFiles): Tuple (output_folder, template) or list of output paths.\n    resampling_method (Literal[\"nearest\", \"bilinear\", \"cubic\"], optional): Resampling method to use; default is \"bilinear\".\n    tap (bool, optional): If True, aligns outputs to target-aligned pixels (GDAL's -tap); default is False.\n    resolution (Literal[\"highest\", \"average\", \"lowest\"], optional): Strategy for choosing target resolution; default is \"highest\".\n    window_size (Universal.WindowSize, optional): Tiling strategy for windowed alignment.\n    debug_logs (Universal.DebugLogs, optional): If True, prints debug output.\n    image_parallel_workers (Universal.ImageParallelWorkers, optional): Parallelization strategy for image-level alignment.\n    window_parallel_workers (Universal.WindowParallelWorkers, optional): Parallelization strategy for within-image window alignment.\n\nReturns:\n    None\"\"\"\n\ndef _align_process_image(image_name, window_parallel, in_path, out_path, target_res, resampling_method, tap, window_size, debug_logs):\n    \"\"\"Aligns a single raster image to a target resolution and grid, optionally in parallel by window.\n\nArgs:\n    image_name (str): Identifier for the image, used for worker context management.\n    window_parallel (Universal.WindowParallelWorkers): Optional multiprocessing config for window-level alignment.\n    in_path (str): Path to the input raster.\n    out_path (str): Path to save the aligned output raster.\n    target_res (Tuple[float, float]): Target resolution (x, y) to resample the raster to.\n    resampling_method (str): Resampling method: \"nearest\", \"bilinear\", or \"cubic\".\n    tap (bool): If True, aligns raster to target-aligned pixels (GDAL-style -tap).\n    window_size (Universal.WindowSize): Tiling strategy for dividing the image into windows.\n    debug_logs (bool): If True, prints debug output.\n\nReturns:\n    None\"\"\"\n\ndef _align_process_window(src_window, dst_window, band_idx, dst_transform, resampling_method, nodata, debug_logs, image_name):\n    \"\"\"Aligns a single raster window for one band using reproject with a shared dataset.\n\nArgs:\n    src_window (Window): Source window to read.\n    dst_window (Window): Output window (used to compute offset transform and for saving).\n    band_idx (int): Band index to read.\n    dst_transform: The full transform of the output raster.\n    resampling_method: Reprojection resampling method.\n    nodata: NoData value.\n    debug_logs: Print debug info if True.\n    image_name: Key to fetch the raster from WorkerContext.\n\nReturns:\n    Tuple[int, Window, np.ndarray]: Band index, destination window, and aligned data buffer.\"\"\"\n\ndef merge_rasters(input_images, output_image_path):\n    \"\"\"Merges multiple rasters into a single mosaic aligned to the union extent and minimum resolution.\n\nArgs:\n    input_images (Universal.SearchFolderOrListFiles): Tuple (folder, pattern) or list of raster paths to merge.\n    output_image_path (str): Path to save the merged output raster.\n    image_parallel_workers (Universal.ImageParallelWorkers, optional): Strategy for parallelizing image-level merging.\n    window_parallel_workers (Universal.WindowParallelWorkers, optional): Strategy for within-image window merging.\n    window_size (Universal.WindowSize, optional): Tiling strategy for processing windows.\n    debug_logs (Universal.DebugLogs, optional): If True, prints debug output.\n    output_dtype (Universal.CustomOutputDtype, optional): Output data type; defaults to input type if None.\n    custom_nodata_value (Universal.CustomNodataValue, optional): NoData value to use; defaults to first input's value.\n\nReturns:\n    None\"\"\"\n\ndef _merge_raster_process_window(window, band_idx, dtype, debug_logs, image_name, src_transform, dst_transform, nodata_value):\n    \"\"\"Processes a single raster window for merging by reading, masking, and mapping it to the destination grid.\n\nArgs:\n    window (Window): Source window to read.\n    band_idx (int): Zero-based band index to process.\n    dtype (str): Data type to cast the read block to.\n    debug_logs (bool): If True, prints debug output.\n    image_name (str): Identifier for accessing the source dataset from WorkerContext.\n    src_transform: Affine transform of the source image.\n    dst_transform: Affine transform of the destination mosaic.\n    nodata_value (Universal.CustomNodataValue): Value representing NoData pixels.\n\nReturns:\n    tuple[int, Window, np.ndarray]: Band index, destination window, and processed data block (or None if fully masked).\"\"\"\n\ndef mask_rasters(input_images, output_images, vector_mask, window_size, debug_logs, image_parallel_workers, window_parallel_workers, include_touched_pixels):\n    \"\"\"Applies a vector-based mask to one or more rasters, with support for image- and window-level parallelism.\n\nArgs:\n    input_images (Universal.SearchFolderOrListFiles): Tuple (folder, pattern) or list of input raster paths.\n    output_images (Universal.CreateInFolderOrListFiles): Tuple (output_folder, template) or list of output raster paths.\n    vector_mask (Universal.VectorMask, optional): Tuple (\"include\"/\"exclude\", vector path, optional field name) or None.\n    window_size (Universal.WindowSize, optional): Strategy for tiling rasters during processing.\n    debug_logs (Universal.DebugLogs, optional): If True, prints debug information.\n    image_parallel_workers (Universal.ImageParallelWorkers, optional): Strategy for parallelizing image-level masking.\n    window_parallel_workers (Universal.WindowParallelWorkers, optional): Strategy for parallelizing masking within windows.\n    include_touched_pixels (bool, optional): If True, includes pixels touched by mask geometry edges; default is False.\n\nReturns:\n    None\"\"\"\n\ndef _mask_raster_process_image(window_parallel, max_workers, backend, input_image_path, output_image_path, image_name, vector_mask, window_size, debug_logs, include_touched_pixels):\n    \"\"\"Processes a single raster image by applying a vector mask, optionally in parallel by window.\n\nArgs:\n    window_parallel (bool): Whether to use parallel processing at the window level.\n    max_workers (int): Maximum number of worker processes or threads.\n    backend (str): Execution backend, e.g., \"process\".\n    input_image_path (str): Path to the input raster.\n    output_image_path (str): Path to save the masked output raster.\n    image_name (str): Identifier for the raster used in worker context.\n    vector_mask (Universal.VectorMask): Masking config as (\"include\"/\"exclude\", path, optional field).\n    window_size (Universal.WindowSize): Strategy for tiling the raster into windows.\n    debug_logs (bool): If True, enables debug output.\n    include_touched_pixels (bool): If True, includes pixels touched by mask geometry boundaries.\n\nReturns:\n    None\"\"\"\n\ndef _mask_raster_process_window(win, band_idx, image_name, nodata, geoms, invert, include_touched_pixels):\n    \"\"\"Applies a vector-based mask to a single raster window and returns the masked data.\n\nArgs:\n    win (Window): Raster window to process.\n    band_idx (int): Zero-based band index to read.\n    image_name (str): Identifier for the raster in the WorkerContext.\n    nodata (int | float): Value to assign to masked-out pixels.\n    geoms (list | None): List of geometries to mask with, or None to skip masking.\n    invert (bool): If True, masks outside the geometries (exclude mode).\n    include_touched_pixels (bool): If True, includes pixels touched by mask boundaries.\n\nReturns:\n    tuple[Window, np.ndarray]: The window and its corresponding masked data array.\"\"\"\n\n### File: statistics.py\n\ndef compare_image_spectral_profiles(input_image_dict, output_figure_path, title, xlabel, ylabel):\n    \"\"\"Compares spectral profiles of multiple images by plotting median and interquartile ranges.\n\nArgs:\n    input_image_dict (dict): Mapping of labels to image file paths:\n        {\n        'Image A': '/image/a.tif',\n        'Image B': '/image/b.tif'\n        }\n    output_figure_path (str): Path to save the output plot.\n    title (str): Title of the plot.\n    xlabel (str): Label for the x-axis.\n    ylabel (str): Label for the y-axis.\n\nOutputs:\n    Saves a spectral profile comparison figure to the specified path.\"\"\"\n\ndef compare_image_spectral_profiles_pairs(image_groups_dict, output_figure_path, title, xlabel, ylabel):\n    \"\"\"Plots paired spectral profiles for before-and-after image comparisons.\n\nArgs:\n    image_groups_dict (dict): Mapping of labels to image path pairs (before, after):\n        {'Image A': [\n            '/image/before/a.tif',\n            'image/after/a.tif'\n        ],\n        'Image B': [\n            '/image/before/b.tif',\n            '/image/after/b.tif'\n        ]}\n    output_figure_path (str): Path to save the resulting comparison figure.\n    title (str): Title of the plot.\n    xlabel (str): X-axis label.\n    ylabel (str): Y-axis label.\n\nOutputs:\n    Saves a spectral comparison plot showing pre- and post-processing profiles.\"\"\"\n\ndef compare_spatial_spectral_difference_band_average(input_images, output_image_path, title, diff_label, subtitle):\n    \"\"\"Computes and visualizes the average per-band spectral difference between two coregistered, equal size images.\n\nArgs:\n    input_images (list): List of two image file paths to compare.\n    output_image_path (str): Path to save the resulting difference image (PNG).\n    title (str): Title for the plot.\n    diff_label (str): Label for the colorbar indicating the difference metric.\n    subtitle (str): Optional subtitle to display below the plot.\"\"\"\n\n### File: seamline/voronoi_center_seamline.py\n\ndef voronoi_center_seamline(input_images, output_mask):\n    \"\"\"Generates a Voronoi-based seamline mask from edge-matching polygons (EMPs) and writes the result to a vector file.\n\nArgs:\n    input_images (Tuple[str, str] | List[str]):\n        Specifies the input images either as:\n        - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n        - A list of full file paths to individual input images.\n    output_mask (str): Output path for the final seamline polygon vector file.\n    min_point_spacing (float, optional): Minimum spacing between Voronoi seed points; default is 10.\n    min_cut_length (float, optional): Minimum cutline segment length to retain; default is 0.\n    debug_logs (Universal.DebugLogs, optional): Enables debug print statements if True; default is False.\n    image_field_name (str, optional): Name of the attribute field for image ID in output; default is 'image'.\n    debug_vectors_path (str | None, optional): Optional path to save debug layers (cutlines, intersections).\n\nOutputs:\n    Saves a polygon seamline layer to `output_mask`, and optionally saves intermediate cutlines to `debug_vectors_path`.\"\"\"\n\ndef _read_mask(path, debug_logs):\n    \"\"\"Reads a raster mask and returns a binary array where valid data is True.\n\nArgs:\n    path (str): Path to the input raster file.\n    debug_logs (bool, optional): If True, enables debug output; default is False.\n\nReturns:\n    Tuple[np.ndarray, Affine]: A binary mask array and the associated affine transform.\"\"\"\n\ndef _seamline_mask(mask, transform, debug_logs):\n    \"\"\"Extracts polygons from a binary mask and returns the largest as the EMP.\n\nArgs:\n    mask (np.ndarray): Binary mask where True indicates valid area.\n    transform (Affine): Affine transform associated with the mask.\n    debug_logs (bool, optional): If True, prints debug info; default is False.\n\nReturns:\n    Polygon: The largest extracted polygon from the mask.\"\"\"\n\ndef _densify_polygon(poly, dist, debug_logs):\n    \"\"\"Densifies the exterior of the largest polygon by inserting points at regular intervals.\n\nArgs:\n    poly (Polygon | GeometryCollection): Input geometry to densify.\n    dist (float): Maximum distance between inserted points.\n    debug_logs (bool, optional): If True, prints debug info; default is False.\n\nReturns:\n    List[Tuple[float, float]]: List of (x, y) coordinates with added intermediate points.\"\"\"\n\ndef _compute_centerline(a, b, min_point_spacing, min_cut_length, debug_logs, crs, debug_vectors_path):\n    \"\"\"Computes a Voronoi-based centerline between two overlapping polygons.\n\nArgs:\n    a (Polygon): First polygon.\n    b (Polygon): Second polygon.\n    min_point_spacing (float): Minimum spacing between seed points for Voronoi generation.\n    min_cut_length (float): Minimum segment length to include in the centerline graph.\n    debug_logs (bool, optional): If True, prints debug information; default is False.\n    crs (optional): Coordinate reference system used for optional debug output.\n    debug_vectors_path (optional): Path to save debug Voronoi cells; if None, skips saving.\n\nReturns:\n    LineString: Shortest centerline path computed through the Voronoi diagram of the overlap.\"\"\"\n\ndef _segment_emp(emp, cuts, debug_logs):\n    \"\"\"Segments an EMP polygon by sequentially applying centerline cuts, retaining the piece containing the centroid.\n\nArgs:\n    emp (Polygon): The original EMP polygon to segment.\n    cuts (List[LineString]): List of cutlines to apply.\n    debug_logs (bool, optional): If True, prints debug info; default is False.\n\nReturns:\n    Polygon: The segmented portion of the EMP containing the original centroid.\"\"\"\n\ndef _save_intersection_points(a, b, path, crs, pair_id):\n    \"\"\"Saves intersection points between the boundaries of two polygons to a GeoPackage layer.\n\nArgs:\n    a (Polygon): First polygon.\n    b (Polygon): Second polygon.\n    path (str): Path to the output GeoPackage file.\n    crs: Coordinate reference system for the output.\n    pair_id (str): Identifier for the polygon pair, saved as an attribute.\n\nReturns:\n    None\"\"\"\n\ndef _save_voronoi_cells(voronoi_cells, path, crs, layer_name):\n    \"\"\"Saves Voronoi polygon geometries to a specified GeoPackage layer.\n\nArgs:\n    voronoi_cells (GeometryCollection): Collection of Voronoi polygon geometries.\n    path (str): Path to the output GeoPackage file.\n    crs: Coordinate reference system for the output layer.\n    layer_name (str, optional): Name of the layer to write; default is \"voronoi_cells\".\n\nReturns:\n    None\"\"\"\n\n### File: match/lirrn.py\n\ndef main():\n    \"\"\"Run LIRRN normalization on selected subject and reference images.\"\"\"\n\ndef _show_rgb(img, title):\n    \"\"\"Display RGB or first three bands of a multiband image.\"\"\"\n\ndef lirrn(p_n, sub_img, ref_img):\n    \"\"\"Perform location-independent relative radiometric normalization.\"\"\"\n\ndef _linear_reg(sub, ref):\n    \"\"\"Fit a linear model: ref \u2248 a * sub + b.\"\"\"\n\ndef _sample_selection(n, a, b, idx):\n    \"\"\"Select sample pairs from quantized sub/ reference image regions using minimal distance matching.\"\"\"\n\n### File: match/local_block_adjustment.py\n\ndef local_block_adjustment(input_images, output_images):\n    \"\"\"Performs local radiometric adjustment on a set of raster images using block-based statistics.\n\nArgs:\n    input_images (Tuple[str, str] | List[str]):\n        Specifies the input images either as:\n        - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n        - A list of full file paths to individual input images.\n    output_images (Tuple[str, str] | List[str]):\n        Specifies how output filenames are generated or provided:\n        - A tuple with an output folder and a filename template using \"$\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"$_LocalMatch.tif\")).\n        - A list of full output paths, which must match the number of input images.\n    calculation_dtype (str, optional): Precision for internal calculations. Defaults to \"float32\".\n    output_dtype (str | None, optional): Data type for output rasters. Defaults to input image dtype.\n    vector_mask (Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None): A mask limiting pixels to include when calculating stats for each block in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that *includes* (can be substring) input image name to filter geometry by. It is only applied when calculating local blocks, as the reference map is calculated as the mean of all local blocks. Loaded block maps won't have this applied unless it was used when calculating them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.\n    debug_logs (bool, optional): If True, prints progress. Defaults to False.\n    custom_nodata_value (float | int | None, optional): Overrides detected NoData value. Defaults to None.\n    image_parallel_workers (Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.\n    window_parallel_workers (Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.\n    window_size (int | Tuple[int, int] | Literal[\"block\"] | None): Tile size for processing: int for square tiles, (width, height) for custom size, or \"block\" to set as the size of the block map, None for full image. Defaults to None.\n    save_as_cog (bool, optional): If True, saves as COG. Defaults to False.\n    number_of_blocks (int | tuple | Literal[\"coefficient_of_variation\"]): int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.\n    alpha (float, optional): Blending factor between reference and local means. Defaults to 1.0.\n    correction_method (Literal[\"gamma\", \"linear\"], optional): Local correction method. Defaults to \"gamma\".\n    save_block_maps (tuple(str, str) | None): If enabled, saves block maps for review, to resume processing later, or to add additional images to the reference map.\n        - First str is the path to save the global block map.\n        - Second str is the path to save the local block maps, which must include \"$\" which will be replaced my the image name (because there are multiple local maps).\n    load_block_maps (Tuple[str, List[str]] | Tuple[str, None] | Tuple[None, List[str]] | None, optional):\n        Controls loading of precomputed block maps. Can be one of:\n            - Tuple[str, List[str]]: Load both reference and local block maps.\n            - Tuple[str, None]: Load only the reference block map.\n            - Tuple[None, List[str]]: Load only the local block maps.\n            - None: Do not load any block maps.\n        This supports partial or full reuse of precomputed block maps:\n            - Local block maps will still be computed for each input image that is not linked to a local block map by the images name being *included* in the local block maps name (file name).\n            - The reference block map will only be calculated (mean of all local blocks) if not set.\n            - The reference map defines the reference block statistics and the local maps define per-image local block statistics.\n            - Both reference and local maps must have the same canvas extent and dimensions which will be used to set those values.\n    override_bounds_canvas_coords (Tuple[float, float, float, float] | None): Manually set (min_x, min_y, max_x, max_y) bounds to override the computed/loaded canvas extent. If you wish to have a larger extent than the current images, you can manually set this, along with setting a fixed number of blocks, to anticipate images will expand beyond the current extent.\n    block_valid_pixel_threshold (float): Minimum fraction of valid pixels required to include a block (0\u20131).\n\nReturns:\n    List[str]: Paths to the locally adjusted output raster images.\"\"\"\n\ndef _validate_input_params(input_images, output_images, custom_nodata_value, number_of_blocks, alpha, calculation_dtype, output_dtype, debug_logs, window_size, save_as_cog, correction_method, image_parallel_workers, window_parallel_workers, save_block_maps, load_block_maps, override_bounds_canvas_coords, vector_mask, block_valid_pixel_threshold):\n    \"\"\"Validates input parameters for `local_block_adjustment`.\n\nRaises:\n    TypeError or ValueError with a concise message if any parameter is improperly set.\"\"\"\n\ndef _get_pre_computed_block_maps(load_block_maps, calculation_dtype, debug_logs):\n    \"\"\"Load pre-computed block mean maps from files.\n\nArgs:\n    load_block_maps (Tuple[str, List[str]] | Tuple[str, None] | Tuple[None, List[str]]):\n        - Tuple[str, List[str]]: Load both reference and local block maps.\n        - Tuple[str, None]: Load only the reference block map.\n        - Tuple[None, List[str]]: Load only the local block maps.\n    calculation_dtype (str): Numpy dtype to use for reading.\n    debug_logs (bool): To print debug statements or not.\n\nReturns:\n    Tuple[\n        dict[str, np.ndarray],             # block_local_means\n        Optional[np.ndarray],              # block_reference_mean\n        Optional[int],                     # num_row\n        Optional[int],                     # num_col\n        Optional[Tuple[float, float, float, float]]  # bounds_canvas_coords\n    ]\"\"\"\n\ndef get_bounding_rect_images_block_space(block_local_means):\n    \"\"\"Compute block-space bounding rectangles for each image based on valid block values.\n\nArgs:\n    block_local_means (dict[str, np.ndarray]): Per-image block means\n        with shape (num_row, num_col, num_bands).\n\nReturns:\n    dict[str, tuple[int, int, int, int]]: Each entry maps image name to\n        (min_row, min_col, max_row, max_col).\"\"\"\n\ndef _compute_reference_blocks(block_local_means, calculation_dtype):\n    \"\"\"Computes reference block means across images by averaging non-NaN local block means.\n\nArgs:\n    block_local_means (dict[str, np.ndarray]): Per-image block mean arrays.\n    calculation_dtype (str): Numpy dtype for output array.\n\nReturns:\n    np.ndarray: Reference block map of shape (num_row, num_col, num_bands)\"\"\"\n\ndef _apply_adjustment_process_image(name, img_path, out_path, num_bands, block_reference_mean, block_local_mean, bounds_image_block_space, bounds_canvas_coords, window_size, num_row, num_col, nodata_val, alpha, correction_method, calculation_dtype, output_dtype, debug_logs, parallel, backend, max_workers, save_as_cog):\n    \"\"\"Applies local radiometric adjustment to a single image using reference and local block statistics.\n\nArgs:\n    name (str): Image identifier.\n    img_path (str): Path to the input image.\n    out_path (str): Path to save the adjusted output image.\n    num_bands (int): Number of bands in the image.\n    block_reference_mean (np.ndarray): Global reference block mean array.\n    block_local_mean (np.ndarray): Image-specific local block mean array.\n    bounds_image_block_space (tuple): Block-space bounding box for the image.\n    bounds_canvas_coords (tuple): Full canvas extent for normalization.\n    window_size: Tiling strategy for processing.\n    num_row (int): Number of block rows.\n    num_col (int): Number of block columns.\n    nodata_val (float): Value representing missing data.\n    alpha (float): Blending factor for adjustment.\n    correction_method (str): Method to apply (\"gamma\" or \"linear\").\n    calculation_dtype (str): Dtype used for internal computation.\n    output_dtype (str): Dtype used for writing output.\n    debug_logs (bool): If True, logs progress.\n    parallel (bool): Whether to use multiprocessing for window-level processing.\n    backend (str): Backend to use for parallelism.\n    max_workers (int): Number of workers to use if parallel.\n\nWrites:\n    The adjusted image to `out_path`.\"\"\"\n\ndef _apply_adjustment_process_window(name, window, band_idx, num_row, num_col, bounds_canvas_coords, nodata_val, alpha, correction_method, calculation_dtype):\n    \"\"\"Applies radiometric correction to a single raster window using bilinear-interpolated block statistics.\n\nArgs:\n    name (str): Image identifier.\n    window (Window): Raster window to process.\n    band_idx (int): Band index (0-based).\n    num_row (int): Number of block rows in the canvas.\n    num_col (int): Number of block columns in the canvas.\n    bounds_canvas_coords (tuple): Spatial extent of the full block canvas.\n    nodata_val (float | int): NoData value in the raster.\n    alpha (float): Blending factor for correction.\n    correction_method (str): Either \"gamma\" or \"linear\".\n    calculation_dtype (str): Data type for intermediate calculations.\n\nReturns:\n    Tuple[Window, int, np.ndarray]: The window, band index, and corrected data array.\"\"\"\n\ndef _get_bounding_rectangle(image_paths):\n    \"\"\"Calculates the bounding rectangle that encompasses all input raster images.\n\nArgs:\n    image_paths (List[str]): List of raster file paths.\n\nReturns:\n    Tuple[float, float, float, float]: (min_x, min_y, max_x, max_y) of the combined extent.\"\"\"\n\ndef _compute_mosaic_coefficient_of_variation(image_paths, nodata_value, reference_std, reference_mean, base_block_size, band_index, calculation_dtype):\n    \"\"\"Estimates block size for local adjustment using the coefficient of variation across input images.\n\nArgs:\n    image_paths (List[str]): List of input raster file paths.\n    nodata_value (float): Value representing NoData in the input rasters.\n    reference_std (float, optional): Reference standard deviation for comparison. Defaults to 45.0.\n    reference_mean (float, optional): Reference mean for comparison. Defaults to 125.0.\n    base_block_size (Tuple[int, int], optional): Base block size (rows, cols). Defaults to (10, 10).\n    band_index (int, optional): Band index to use for statistics (1-based). Defaults to 1.\n    calculation_dtype (str, optional): Data type for computation. Defaults to \"float32\".\n\nReturns:\n    Tuple[int, int]: Estimated block size (rows, cols) adjusted based on coefficient of variation.\"\"\"\n\ndef _calculate_block_process_image(name, image_path, bounds_canvas_coords, num_row, num_col, num_bands, window_size, debug_logs, nodata_value, calculation_dtype, vector_mask, block_valid_pixel_threshold, parallel, backend, max_workers):\n    \"\"\"Computes per-block mean statistics for a single image by aggregating pixel values into a block grid.\n\nArgs:\n    name (str): Image identifier.\n    image_path (str): Path to the input raster.\n    bounds_canvas_coords (tuple): Full extent of the block canvas (minx, miny, maxx, maxy).\n    num_row (int): Number of block rows.\n    num_col (int): Number of block columns.\n    num_bands (int): Number of image bands.\n    window_size (tuple or \"block\" or None): Tiling strategy for processing.\n    debug_logs (bool): If True, prints progress info.\n    nodata_value (float): Value used to identify invalid pixels.\n    calculation_dtype (str): Numpy dtype for internal arrays.\n    vector_mask (tuple or None): Optional spatial mask to include/exclude regions.\n    block_valid_pixel_threshold (float): Minimum valid pixel ratio to include block.\n    parallel (bool): Whether to use multiprocessing for tiles.\n    backend (str): Parallel execution backend (\"process\" or \"thread\").\n    max_workers (int): Number of parallel workers.\n\nReturns:\n    Tuple[str, np.ndarray, np.ndarray]: (Image name, block mean array, block pixel count array)\"\"\"\n\ndef _calculate_block_process_window(band_index, window, name, geoms, invert, nodata_value, calculation_dtype, transform, block_shape, bounds_canvas_coords):\n    \"\"\"Aggregates pixel values within a raster window into a block grid for one band.\n\nArgs:\n    band_index (int): Band index to process (0-based).\n    window (Window): Raster window to read.\n    name (str): Image identifier used to retrieve dataset.\n    geoms (list or None): Optional vector geometries for masking.\n    invert (bool): Whether to invert the mask.\n    nodata_value (float): NoData value in the raster.\n    calculation_dtype (str): Data type for computation.\n    transform: Affine transform of the dataset.\n    block_shape (tuple): (num_row, num_col) of the block grid.\n    bounds_canvas_coords (tuple): Extent of the full canvas (minx, miny, maxx, maxy).\n\nReturns:\n    Optional[Tuple[np.ndarray, np.ndarray]]: (Sum of values per block, count of valid pixels per block),\n    or None if the window has no valid pixels.\"\"\"\n\ndef _weighted_bilinear_interpolation(C_B, x_frac, y_frac):\n    \"\"\"Performs bilinear interpolation on a 2D array while handling NaN values using a validity mask.\n\nArgs:\n    C_B (np.ndarray): 2D array with possible NaNs to interpolate.\n    x_frac (np.ndarray): Fractional x-coordinates for interpolation.\n    y_frac (np.ndarray): Fractional y-coordinates for interpolation.\n\nReturns:\n    np.ndarray: Interpolated values at the specified fractional coordinates, with NaNs preserved where data is invalid.\"\"\"\n\ndef _download_block_map(block_map, bounding_rect, output_image_path, projection, dtype, nodata_value, width, height, write_bands, window, delete_output):\n    \"\"\"Writes a 3D block map to a raster file, creating or updating specified bands within a target window.\n\nArgs:\n    block_map (np.ndarray): Block data of shape (rows, cols, bands).\n    bounding_rect (tuple): Spatial extent (minx, miny, maxx, maxy).\n    output_image_path (str): Path to the output raster file.\n    projection (rasterio.CRS): Coordinate reference system.\n    dtype (str): Data type for output.\n    nodata_value (float): NoData value to write.\n    width (int): Full raster width.\n    height (int): Full raster height.\n    write_bands (tuple[int] | None): 0-based band indices to write; all if None.\n    window (Window | None): Raster window to write into; defaults to full image.\n\nOutput:\n    Writes the `block_map` array to `output_image_path`, either creating a new raster or updating an existing one.\"\"\"\n\ndef _compute_block_size(input_image_array_path, target_blocks_per_image, bounds_canvas_coords):\n    \"\"\"Calculates the number of rows and columns for dividing a bounding rectangle into target-sized blocks.\n\nArgs:\n    input_image_array_path (list): List of image paths to determine total image count.\n    target_blocks_per_image (int | float): Desired number of blocks per image.\n    bounds_canvas_coords (tuple): Bounding box covering all images (minx, miny, maxx, maxy).\n\nReturns:\n    Tuple[int, int]: Number of rows (num_row) and columns (num_col) for the block grid.\"\"\"\n\ndef _apply_gamma_correction(arr_in, Mrefs, Mins, alpha):\n    \"\"\"Applies gamma correction to input pixel values based on reference and input block means.\n\nArgs:\n    arr_in (np.ndarray): Input pixel values to be corrected.\n    Mrefs (np.ndarray): Reference block means.\n    Mins (np.ndarray): Local block means of the input image.\n    alpha (float, optional): Scaling factor applied to the corrected output. Defaults to 1.0.\n\nReturns:\n    Tuple[np.ndarray, np.ndarray]:\n        - Gamma-corrected pixel values.\n        - Gamma values used in the correction.\n\nRaises:\n    ValueError: If any value in Mins is zero or negative.\"\"\"\n\ndef _smooth_array(input_array, nodata_value, scale_factor):\n    \"\"\"Applies Gaussian smoothing to an array while preserving NoData regions.\n\nArgs:\n    input_array (np.ndarray): 2D array to be smoothed.\n    nodata_value (Optional[float], optional): Value representing NoData. Treated as NaN during smoothing. Defaults to None.\n    scale_factor (float, optional): Sigma value for the Gaussian filter. Controls smoothing extent. Defaults to 1.0.\n\nReturns:\n    np.ndarray: Smoothed array with NoData regions preserved or restored.\"\"\"\n\n### File: match/global_regression.py\n\ndef global_regression(input_images, output_images):\n    \"\"\"Performs global radiometric normalization across overlapping images using least squares regression.\n\nArgs:\n    input_images (Tuple[str, str] | List[str]):\n        Specifies the input images either as:\n        - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n        - A list of full file paths to individual input images.\n    output_images (Tuple[str, str] | List[str]):\n        Specifies how output filenames are generated or provided:\n        - A tuple with an output folder and a filename template using \"$\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"$_GlobalMatch.tif\")).\n        - A list of full output paths, which must match the number of input images.\n    calculation_dtype (str, optional): Data type used for internal calculations. Defaults to \"float32\".\n    output_dtype (str | None, optional): Data type for output rasters. Defaults to input image dtype.\n    vector_mask (Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None): Mask to limit stats calculation to specific areas in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that *includes* (can be substring) input image name to filter geometry by. Loaded stats won't have this applied to them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.\n    debug_logs (bool, optional): If True, prints debug information and constraint matrices. Defaults to False.\n    custom_nodata_value (float | int | None, optional): Overrides detected NoData value. Defaults to None.\n    image_parallel_workers (Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.\n    window_parallel_workers (Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.\n    window_size (int | Tuple[int, int] | Literal[\"internal\"] | None): Tile size for reading and writing: int for square tiles, tuple for (width, height), \"internal\" to use raster's native tiling, or None for full image. \"internal\" enables efficient streaming from COGs.\n    save_as_cog (bool): If True, saves output as a Cloud-Optimized GeoTIFF using proper band and block order.\n    specify_model_images (Tuple[Literal[\"exclude\", \"include\"], List[str]] | None ): First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.\n    custom_mean_factor (float, optional): Weight for mean constraints in regression. Defaults to 1.0.\n    custom_std_factor (float, optional): Weight for standard deviation constraints in regression. Defaults to 1.0.\n    save_adjustments (str | None, optional): The output path of a .json file to save adjustments parameters. Defaults to not saving.\n    load_adjustments (str | None, optional): If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.\n\nReturns:\n    List[str]: Paths to the globally adjusted output raster images.\"\"\"\n\ndef solve_global_model(num_bands, num_total, all_image_names, included_names, input_image_names, all_overlap_stats, all_whole_stats, custom_mean_factor, custom_std_factor, overlapping_pairs, debug_logs):\n    \"\"\"Computes global radiometric normalization parameters (scale and offset) for each image and band using least squares regression.\n\nArgs:\n    num_bands: Number of image bands.\n    num_total: Total number of images (including loaded).\n    all_image_names: Ordered list of all image names.\n    included_names: Subset of images used to constrain the model.\n    input_image_names: Names of input images to apply normalization to.\n    all_overlap_stats: Pairwise overlap statistics per band.\n    all_whole_stats: Whole-image stats (mean, std) per band.\n    custom_mean_factor: Weight for mean constraints.\n    custom_std_factor: Weight for std constraints.\n    overlapping_pairs: Pairs of overlapping images.\n    debug_logs: If True, prints debug information.\n\nReturns:\n    np.ndarray: Adjustment parameters of shape (bands, 2 * num_images, 1).\"\"\"\n\ndef _apply_adjustments_process_image(image_name, input_image_path, output_image_path, scale, offset, num_bands, nodata_val, window_size, calculation_dtype, output_dtype, window_parallel, window_backend, window_max_workers, save_as_cog, debug_logs):\n    \"\"\"Applies scale and offset adjustments to each band of an input image and writes the result to the output path.\n\nArgs:\n    image_name: Identifier for the image in the worker context.\n    input_image_path: Path to the input raster image.\n    output_image_path: Path to save the adjusted output image.\n    scale: Per-band scale factors (1D array of length num_bands).\n    offset: Per-band offset values (1D array of length num_bands).\n    num_bands: Number of image bands.\n    nodata_val: NoData value to preserve during adjustment.\n    window_size: Tiling strategy for processing (None, int, tuple, or \"internal\").\n    calculation_dtype: Data type for computation.\n    output_dtype: Output data type (defaults to input type if None).\n    window_parallel: Whether to parallelize over windows.\n    window_backend: Backend to use for window-level parallelism (\"process\").\n    window_max_workers: Number of parallel workers for window processing.\n    debug_logs: If True, prints debug info during processing.\n\nReturns:\n    None\"\"\"\n\ndef _save_adjustments(save_path, input_image_names, all_params, all_whole_stats, all_overlap_stats, num_bands, calculation_dtype):\n    \"\"\"Saves adjustment parameters, whole-image stats, and overlap stats in a nested JSON format.\n\nArgs:\n    save_path (str): Output JSON path.\n    input_image_names (List[str]): List of input image names.\n    all_params (np.ndarray): Adjustment parameters, shape (bands, 2 * num_images, 1).\n    all_whole_stats (dict): Per-image stats (keyed by image name).\n    all_overlap_stats (dict): Per-pair overlap stats (keyed by image name).\n    num_bands (int): Number of bands.\n    calculation_dtype (str): Precision for saving values (e.g., \"float32\").\"\"\"\n\ndef _validate_adjustment_model_structure(model):\n    \"\"\"Validates the structure of a loaded adjustment model dictionary.\n\nEnsures that:\n- Each top-level key is an image name mapping to a dictionary.\n- Each image has 'adjustments' and 'whole_stats' with per-band keys like 'band_0'.\n- Each band entry in 'adjustments' contains 'scale' and 'offset'.\n- Each band entry in 'whole_stats' contains 'mean', 'std', and 'size'.\n- If present, 'overlap_stats' maps to other image names with valid per-band statistics.\n\nThe expected model structure is a dictionary with this format:\n\n{\n    \"image_name_1\": {\n        \"adjustments\": {\n            \"band_0\": {\"scale\": float, \"offset\": float},\n            \"band_1\": {\"scale\": float, \"offset\": float},\n            ...\n        },\n        \"whole_stats\": {\n            \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n            \"band_1\": {\"mean\": float, \"std\": float, \"size\": int},\n            ...\n        },\n        \"overlap_stats\": {\n            \"image_name_2\": {\n                \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n                \"band_1\": {\"mean\": float, \"std\": float, \"size\": int},\n                ...\n            },\n            ...\n        }\n    },\n    ...\n}\n\n- Keys are image basenames (without extension).\n- Band keys are of the form \"band_0\", \"band_1\", etc.\n- All numerical values are stored as floats (except 'size', which is an int).\n\nArgs:\n    model (dict): Parsed JSON adjustment model.\n\nRaises:\n    ValueError: If any structural issues or missing keys are detected.\"\"\"\n\ndef _apply_adjustments_process_window(window, band_idx, a, b, nodata, calculation_dtype, debug_logs, image_name):\n    \"\"\"Applies a global linear transformation (scale and offset) to a raster tile.\n\nArgs:\n    window (Window): Rasterio window specifying the region to process.\n    band_idx (int): Band index to read and adjust.\n    a (float): Multiplicative factor for normalization.\n    b (float): Additive offset for normalization.\n    nodata (int | float): NoData value to ignore during processing.\n    calculation_dtype (str): Data type to cast the block for computation.\n    debug_logs (bool): If True, prints processing information.\n    image_name (str): Key to fetch the raster from WorkerContext.\n\nReturns:\n    Tuple[Window, np.ndarray]: Window and the adjusted data block.\"\"\"\n\ndef _print_constraint_system(constraint_matrix, adjustment_params, observed_values_vector, overlap_pairs, image_names_with_id):\n    \"\"\"Prints the constraint matrix system with labeled rows and columns for debugging regression inputs.\n\nArgs:\n    constraint_matrix (ndarray): Coefficient matrix used in the regression system.\n    adjustment_params (ndarray): Solved adjustment parameters (regression output).\n    observed_values_vector (ndarray): Target values in the regression system.\n    overlap_pairs (tuple): Pairs of overlapping image indices used in constraints.\n    image_names_with_id (list of tuple): List of (ID, name) pairs corresponding to each image's position in the system.\n\nReturns:\n    None\"\"\"\n\ndef _find_overlaps(image_bounds_dict):\n    \"\"\"Finds all pairs of image names with overlapping spatial bounds.\n\nArgs:\n    image_bounds_dict (dict): Dictionary mapping image names to their rasterio bounds.\n\nReturns:\n    Tuple[Tuple[str, str], ...]: Pairs of image names with overlapping extents.\"\"\"\n\ndef _overlap_stats_process_image(parallel, max_workers, backend, num_bands, input_image_path_i, input_image_path_j, name_i, name_j, bound_i, bound_j, nodata_i, nodata_j, vector_mask, window_size, debug_logs):\n    \"\"\"Computes per-band overlap statistics (mean, std, pixel count) between two images over their intersecting area.\n\nArgs:\n    parallel: Whether to use multiprocessing for window processing.\n    max_workers: Number of workers for parallel processing.\n    backend: Parallelization backend (\"process\").\n    num_bands: Number of image bands.\n    input_image_path_i: Path to the first image.\n    input_image_path_j: Path to the second image.\n    name_i: Identifier for the first image.\n    name_j: Identifier for the second image.\n    bound_i: BoundingBox of the first image.\n    bound_j: BoundingBox of the second image.\n    nodata_i: NoData value for the first image.\n    nodata_j: NoData value for the second image.\n    vector_mask: Optional mask to include/exclude regions, with optional field filter.\n    window_size: Windowing strategy for tile processing.\n    debug_logs: If True, prints overlap bounds and status.\n\nReturns:\n    dict: Nested stats dictionary for each image pair and band.\"\"\"\n\ndef _overlap_stats_process_window(win, band, col_min_i, row_min_i, name_i, name_j, nodata_i, nodata_j, geoms_i, geoms_j, invert, interpolation_method):\n    \"\"\"Processes a single overlapping window between two images, applying masks and interpolation if needed,\nand returns valid pixel pairs for statistical comparison.\n\nArgs:\n    win: Window in image i's coordinate space.\n    band: Band index to process.\n    col_min_i: Column offset of overlap region in image i.\n    row_min_i: Row offset of overlap region in image i.\n    name_i: Image i identifier in WorkerContext.\n    name_j: Image j identifier in WorkerContext.\n    nodata_i: NoData value for image i.\n    nodata_j: NoData value for image j.\n    geoms_i: Optional list of geometries for masking image i.\n    geoms_j: Optional list of geometries for masking image j.\n    invert: Whether to invert the mask logic (exclude vs include).\n    interpolation_method: OpenCV interpolation method for resampling. 1 is bilinear interpolation.\n\nReturns:\n    Tuple of valid pixel arrays (image_i_values, image_j_values), or None if no valid pixels found.\"\"\"\n\ndef _fit_windows_to_pixel_bounds(windows, row_min, row_max, col_min, col_max, row_offset, col_offset):\n    \"\"\"Adjusts a list of image-relative windows to ensure they fit within specified pixel bounds, based on a global offset.\n\nArgs:\n    windows: List of rasterio Window objects (relative to an image region).\n    row_min, row_max: Global pixel row bounds to clip against.\n    col_min, col_max: Global pixel column bounds to clip against.\n    row_offset, col_offset: Offsets to convert window-relative coordinates to global coordinates.\n\nReturns:\n    List[Window]: Windows cropped to the specified global bounds.\"\"\"\n\ndef _whole_stats_process_image(parallel, max_workers, backend, input_image_path, nodata, num_bands, image_name, vector_mask, window_size, debug_logs):\n    \"\"\"Calculates whole-image statistics (mean, std, and valid pixel count) per band, with optional masking and window-level parallelism.\n\nArgs:\n    parallel: Whether to enable multiprocessing for window processing.\n    max_workers: Number of parallel workers to use.\n    backend: Multiprocessing backend (\"process\").\n    input_image_path: Path to the input raster.\n    nodata: NoData value to exclude from stats.\n    num_bands: Number of bands to process.\n    image_name: Identifier for use in WorkerContext.\n    vector_mask: Optional mask tuple to include/exclude specific regions, with optional field filter.\n    window_size: Tiling strategy (None, int, tuple, or \"internal\").\n    debug_logs: If True, prints debug messages.\n\nReturns:\n    dict: Per-band statistics {image_name: {band: {mean, std, size}}}.\"\"\"\n\ndef _whole_stats_process_window(win, band_idx, image_name, nodata, geoms, invert):\n    \"\"\"Extracts valid pixel values from a raster window, optionally applying a geometry mask.\n\nArgs:\n    win: Rasterio window to read.\n    band_idx: Band index to read (0-based).\n    image_name: Identifier for the image in WorkerContext.\n    nodata: NoData value to exclude.\n    geoms: Optional list of geometries for masking.\n    invert: If True, inverts the mask (exclude instead of include).\n\nReturns:\n    np.ndarray or None: 1D array of valid pixel values, or None if none found.\"\"\"\n\n### File: mask/band_math.py\n\ndef threshold_raster(input_images, output_images, threshold_math):\n    \"\"\"Applies a thresholding operation to input raster images using a mathematical expression string.\n\nArgs:\n    input_images (SearchFolderOrListFiles): Input image paths or folder + pattern.\n    output_images (CreateInFolderOrListFiles): Output image paths or folder + pattern.\n    threshold_math (str): A logical expression string using bands (e.g., \"b1 &gt; 5\", \"b1 &gt; 5 &amp; b2 &lt; 10\").\n        Supports:\n            - Band references: b1, b2, ...\n            - Operators: &gt;, &lt;, &gt;=, &lt;=, ==, !=, &amp;, |, ~, and parentheses\n            - Percentile-based thresholds: use e.g. \"5%b1\" to use the 5th percentile of band 1\n    debug_logs (bool, optional): If True, prints debug messages.\n    custom_nodata_value (float | int | None, optional): Override the dataset's nodata value.\n    image_parallel_workers (ImageParallelWorkers, optional): Parallelism config for image-level processing.\n    window_parallel_workers (WindowParallelWorkers, optional): Parallelism config for window-level processing.\n    window_size (WindowSize, optional): Window tiling strategy for memory-efficient processing.\n    custom_output_dtype (CustomOutputDtype, optional): Output data type override.\n    calculation_dtype (CalculationDtype, optional): Internal computation dtype.\"\"\"\n\ndef _threshold_process_image(input_image_path, output_image_path, name, threshold_math, debug_logs, nodata_value, window_parallel_workers, window_size, output_dtype, calculation_dtype):\n    \"\"\"Processes a single input raster image using a threshold expression and writes the result to disk.\n\nArgs:\n    input_image_path (str): Path to input raster image.\n    output_image_path (str): Path to save the output thresholded image.\n    name (str): Image name for worker context.\n    threshold_math (str): Expression string to evaluate pixel-wise conditions.\n    debug_logs (bool): Enable debug logging.\n    nodata_value (float | int | None): Value considered as nodata.\n    window_parallel_workers: Parallel config for window-level processing.\n    window_size: Window tiling size for memory efficiency.\n    output_dtype: Output raster data type.\n    calculation_dtype: Data type used for internal calculations.\"\"\"\n\ndef _threshold_process_window(name, window, threshold_math, debug_logs, nodata_value, calculation_dtype):\n    \"\"\"Applies the threshold logic to a single image window.\n\nArgs:\n    name (str): Image identifier for WorkerContext access.\n    window (rasterio.windows.Window): Window to read and process.\n    threshold_math (str): Logical expression for thresholding using b1, b2, etc.\n    debug_logs (bool): Enable debug logs.\n    nodata_value (float | int | None): Value considered as nodata.\n    calculation_dtype: Dtype to cast bands for threshold computation.\n\nReturns:\n    Tuple[int, rasterio.windows.Window, np.ndarray]: Band index, processed window, thresholded data mask (1 for true, 0 for false).\"\"\"\n\ndef _calculate_threshold_from_percent(input_image_path, threshold, band_index):\n    \"\"\"Calculates a threshold value based on a percentile of valid (non-nodata) pixel values in a raster.\n\nArgs:\n    input_image_path (str): Path to input raster image.\n    threshold (str): Percent string (e.g., \"5%\") indicating the percentile to compute.\n    band_index (int): Band index to evaluate.\n    debug_logs (bool, optional): If True, prints debug info.\n    nodata_value (float | int | None, optional): Value treated as nodata.\n    window_parallel_workers: Optional parallel config.\n    window_size: Tiling strategy.\n    calculation_dtype (str): Internal dtype used for calculations.\n    bins (int): Number of bins for histogram.\n\nReturns:\n    float: Threshold value corresponding to the requested percentile.\"\"\"\n\ndef band_math(input_images, output_images, custom_math):\n\ndef band_math_process_image(input_image_path, output_image_path, name, custom_math, debug_logs, nodata_value, window_parallel_workers, window_size, band_indices, output_dtype, calculation_dtype):\n\ndef band_math_process_window(name, window, custom_math, debug_logs, nodata_value, band_indices, calculation_dtype):\n\ndef post_process_threshold_to_vector(input_image_path, output_vector_path, threshold_val, operator_str):\n    \"\"\"Converts a thresholded raster mask to a vector layer using Rasterio and Fiona.\n\nArgs:\n    input_image_path (str): Path to the input single-band raster.\n    output_vector_path (str): Path to save the output vector file (GeoPackage).\n    threshold_val (float | int): Threshold value to apply.\n    operator_str (str): One of the comparison operators.\n\nReturns:\n    str: Path to the saved vector file.\"\"\"\n\ndef replace_percent_with_threshold(match):\n\n### File: mask/mask.py\n\ndef create_cloud_mask_with_omnicloudmask(input_image_path, red_band_index, green_band_index, nir_band_index, output_mask_path, down_sample_m, debug_logs):\n    \"\"\"Generates a cloud mask using OmniCloudMask from a multi-band image.\n\nArgs:\n    input_image_path (str): Path to the input image.\n    red_band_index (int): Index of the red band.\n    green_band_index (int): Index of the green band.\n    nir_band_index (int): Index of the NIR (or substitute blue) band.\n    output_mask_path (str): Path to save the output cloud mask GeoTIFF.\n    down_sample_m (float, optional): Target resolution (in meters) to downsample the input before processing.\n    debug_logs (bool, optional): Debug logs to console.\n    omnicloud_kwargs: Forwards key word args to OmniCloudMask predict_from_array() function. Repo here: https://github.com/DPIRD-DMA/OmniCloudMask.\n\nOutputs:\n    Saves a single-band cloud mask GeoTIFF at the specified path.\"\"\"\n\ndef post_process_raster_cloud_mask_to_vector(input_image_path, output_vector_path, minimum_mask_size_percentile, polygon_buffering_in_map_units, value_mapping):\n    \"\"\"Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.\n\nArgs:\n    input_image_path (str): Path to the input cloud mask raster.\n    output_vector_path (str): Path to the output vector layer.\n    minimum_mask_size_percentile (float, optional): Percentile threshold to filter small polygons by area.\n    polygon_buffering_in_map_units (dict, optional): Mapping of raster values to buffer distances.\n    value_mapping (dict, optional): Mapping of original raster values to new values before vectorization.\n\nOutputs:\n    Saves a vector layer to the output path.\"\"\"\n\ndef create_ndvi_mask(input_image_path, output_image_path, nir_band, red_band):\n    \"\"\"Computes NDVI from a multi-band image and saves the result as a GeoTIFF.\n\nArgs:\n    input_image_path (str): Path to the input image with NIR and red bands.\n    output_image_path (str): Path to save the NDVI output GeoTIFF.\n    nir_band (int): Band index for NIR (1-based).\n    red_band (int): Band index for red (1-based).\n\nReturns:\n    str: Path to the saved NDVI output.\"\"\"\n\n### File: mask/shadow_mask.py\n\ndef shadow_detection(image_file, shadow_mask_file, convolve_window_size, num_thresholds, struc_elem_size):\n    \"\"\"This function is used to detect shadow - covered areas in an image, as proposed in the paper\n'Near Real - Time Shadow Detection and Removal in Aerial Motion Imagery Application' by Silva G.F., Carneiro G.B.,\nDoth R., Amaral L.A., de Azevedo D.F.G. (2017)\n\nInputs:\n- image_file: Path of image to be processed for shadow removal. It is assumed that the first 3 channels are ordered as\n              Red, Green and Blue respectively\n- shadow_mask_file: Path of shadow mask to be saved\n- convolve_window_size: Size of convolutional matrix filter to be used for blurring of specthem ratio image\n- num_thresholds: Number of thresholds to be used for automatic multilevel global threshold determination\n- struc_elem_size: Size of disk - shaped structuring element to be used for morphological closing operation\n\nOutputs:\n- shadow_mask: Shadow mask for input image\"\"\"\n\ndef shadow_correction(image_file, shadow_mask_file, corrected_image_file, exponent):\n    \"\"\"This function is used to adjust brightness for shadow - covered areas in an image, as proposed in the paper\n'Near Real - Time Shadow Detection and Removal in Aerial Motion Imagery Application' by Silva G.F., Carneiro G.B.,\nDoth R., Amaral L.A., de Azevedo D.F.G. (2017)\n\nInputs:\n- image_file: Path of 3 - channel (red, green, blue) image to be processed for shadow removal\n- shadow_mask_file: Path of shadow mask for corresponding input image\n- corrected_image_file: Path of corrected image to be saved\n- exponent: Exponent to be used for the calculcation of statistics for unshaded and shaded areas\n\nOutputs:\n- corrected_img: Corrected input image\"\"\"\n\n## Markdown Section\n### File: rrn_methods.md\n# Dimensions of Relative Radiometric Normalization (RRN) Methods\n\nRRN methods differ not only in the algorithms used to adjust image values but also in the requirements images must have and other techniques that can be used in conjunction. The following taxonomy summarizes the core dimensions along which RRN techniques vary:\n\n - **Matching algorithm:** The core transformation applied to align radiometry between images.\n - **Geometric alignment required:** The level of spatial alignment necessary for the method.\n - **Pixel selection (PIFs/RCS):** How pseudo-invariant features/control sets are identified.\n - **Adjustment scope:** How corrections are applied to the images.\n - **Overlap:** Whether the method requires overlapping pixels.\n - **Pixel units:** The radiometric units the method is able to operate on.\n - **Bands:** Whether bands relationships are preserved.\n - **Target reference:** What the target image is normalized to.\n\nMultiple matching algorithms can be used in conjunction with multiple pixel selection methods. Note that the most restrictive method will dictate the image requirements (e.g. if using `Global regression` with `Overlapping area` the `Geometric alignment` will need to be `Moderate`). The specific matching algorithm used in each method is flexible and not fixed; it may involve least squares, RANSAC, Theil\u2013Sen, Huber, or other forms of robust regression.\n\n## Matching Algorithms\n\n| Matching algorithm                      | Description                                                                                            | Geometric alignment | Adjustment granularity          | Applies                        | Overlap required | Pixel units | Bands                  | Target reference                           | Year introduced | Key papers                                                                               | Software                                                                                                                                                                                                |\n| --------------------------------------- | ------------------------------------------------------------------------------------------------------ | ------------------- | ------------------------------- | ------------------------------ | ---------------- | ----------- | ---------------------- | ------------------------------------------ | --------------- | ---------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Histogram Matching (HM)                 | Matches histogram distributions between images                                                         | None                | Global                          | Lookup table                   | no               | Any         | Independent            | Reference histogram                        | 1980s           |                                                                                          | ENVI; [HistMatch QGIS Plugin](https://github.com/Gustavoohs/HistMatch); ArcGIS Pro; IMAGINE Mosaic Pro; [landsat R library via histmatch()](https://cran.r-project.org/web/packages/landsat/index.html) |\n| Minimum\u2013Maximum Scale Normalization     | Linearly scales pixel values to match reference min/max                                                | None                | Global                          | Min/max                        | No               | Any         | Independent            | Reference min/max                          | 1980s           |                                                                                          |                                                                                                                                                                                                         |\n| Mean\u2013Standard Deviation Regression      | Fits linear regression using mean and std dev                                                          | None                | Global                          | Gain/offset                    | No               | Any         | Independent/Correlated | Reference mean/std                         | 1980s           |                                                                                          | ArcGIS Pro; [spectralmatch Python library and QGIS plugin](https://github.com/spectralmatch/spectralmatch)                                                                                              |\n| Overlaping pixel-wise Linear Regression | Fits linear regression using overlapping pairs of pixels                                               | Co-registered       | Model                           | Gain/offset                    | Yes              | Any         | Independent/Correlated | Reference image pixels                     | 1980s           |                                                                                          | ArcGIS Pro; [landsat R library via relnorm()](https://cran.r-project.org/web/packages/landsat/index.html)                                                                                               |\n| Block adjusted gamma correction         | Adjusts local brightness via block-based gamma scaling                                                 | Moderate            | Blocks/interpolation resolution | Power function                 | Yes              | Any         | Independent            | Reference block map (mean of local blocks) |                 |                                                                                          | [spectralmatch Python library and QGIS plugin](https://github.com/spectralmatch/spectralmatch)                                                                                                          |\n| CCA/KCCA-Based                          | Finding the most correlated combinations between images                                                | Co-registered       | CCA space resolution            | Matrix                         | Yes              | Any         | Correlated             | Reference canonical components             |                 |                                                                                          |                                                                                                                                                                                                         |\n| Dodging                                 | Smooths brightness using low-pass filtering to reduce lighting artifacts                               | Co-registered       | Blur resolution                 | Low-pass brightness correction | Yes              | Any         | Independent            | Blur created brightness values             |                 |                                                                                          | ArcGIS Pro; IMAGINE Mosaic Pro                                                                                                                                                                          |\n| Illumination Equalization               | Models and removes large-scale illumination differences across images                                  | Co-registered       | Surface model resolution        | Modeled lighting correction    | Yes              | Any         | Independent            | Computed illumination values               |                 |                                                                                          | IMAGINE Mosaic Pro                                                                                                                                                                                      |\n| Wavelet reconstruction                  | Uses ancillary data to model and reconstruct image values at multiple detail levels                    | Co-registered       | Ancillary data resolution       | Decomposition/reconstruction   | Yes              | Any         | Correlated             | Ancillary data                             |                 | [(Gan et al., 2021)](https://doi.org/10.1109/JSTARS.2021.3069855)                        |                                                                                                                                                                                                         |\n| Dual-reference affine interpolation     | Models corrections from the two nearest reference images and applies temporally weighted interpolation | Co-registered       | Model                           | Gain/offset                    | Yes              | Any         | Independent            | Two closest high-quality reference images  | 2020            | [(Hessel et al., 2020)](https://isprs-annals.copernicus.org/articles/V-2-2020/845/2020/) | [rrn-multisensor-multidate Python scripts](https://github.com/chlsl/rrn-multisensor-multidate)                                                                                                          |\n\n## Pixel Selection\n\n| Pixel selection (PIFs/RCS)              | Description                                                                                                                                                                       | Type        | Geometric alignment | Overlap required | Pixel units                        | Year introduced | Key papers                                                                                             | Software                                                                                       |\n| --------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- | ------------------- | ---------------- | ---------------------------------- | --------------- | ------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------- |\n| Whole image                             | Uses all pixels without selection or masking                                                                                                                                      | None        | None                | No               | Any                                |                 |                                                                                                        |                                                                                                |\n| Overlapping area                        | Uses only pixels in the spatial overlap between images                                                                                                                            | None        | Moderate            | Yes              | Any                                |                 |                                                                                                        |                                                                                                |\n| Manual polygons or pixels               | User-defined areas or points chosen as invariant                                                                                                                                  | Manual      | None                | No               | Any                                |                 |                                                                                                        |                                                                                                |\n| Manual threshold                        | Selects pixels based on value threshold                                                                                                                                           | Threshold   | None                | No               | Any                                |                 |                                                                                                        |                                                                                                |\n| Dark/Bright Set (DB)                    | Selects darkest and brightest pixels assumed to be invariant                                                                                                                      | Threshold   | None                | No               | Any/reflectance may perform better |                 |                                                                                                        |                                                                                                |\n| NDVI ratio                              | Uses vegetation indices to isolate vegetated areas for normalization                                                                                                              | Band ratio  | None                | No               | Reflectance                        |                 |                                                                                                        | [spectralmatch Python library and QGIS plugin](https://github.com/spectralmatch/spectralmatch) |\n| K-T ratio                               | Uses the Kauth\u2013Thomas transformation to identify invariant pixels in greenness\u2013brightness space                                                                                   | Band ratio  | None                | No               | Reflectance                        |                 | [(Hall et al., 1991)](https://www.sciencedirect.com/science/article/pii/003442579190062B?via%3Dihub)   | [landsat R library via RCS()](https://cran.r-project.org/web/packages/landsat/index.html)      |\n| Urban materials ratio                   | Assumes that certain **man-made surfaces** (e.g., roads, rooftops) have **stable reflectance over time** and uses their statistical properties to correct radiometric differences | Band ratio  | None                | No               | Reflectance                        | 1988            | [(Schott et al., 1988)](https://www.sciencedirect.com/science/article/pii/0034425788901162?via%3Dihub) | [landsat R library via PIF()](https://cran.r-project.org/web/packages/landsat/index.html)      |\n| No-change  Scattergrams\u00a0(NC)            | Selects pixels near the scatterplot diagonal where reference and target values match closely                                                                                      | Statistical | Co-registered       | Yes              | Any                                |                 | [(De Carvalho et al., 2013)](https://www.mdpi.com/2072-4292/5/6/2763)                                  |                                                                                                |\n| Multivariate Alteration Detection (MAD) | Identifies invariant pixels by transforming image differences into uncorrelated components; selects pixels with minimal change across all bands                                   | Statistical | Co-registered       | Yes              | Any                                |                 |                                                                                                        |                                                                                                |\n| Iteratively Reweighted MAD (IR-MAD)     | Refines MAD by reweighting pixels to improve change detection                                                                                                                     | Statistical | Co-registered       | Yes              | Any                                |                 | [(Canty &amp; Nielsen, 2008)](https://doi.org/10.1016/j.rse.2007.07.013)                                   | [ArrNorm Python scripts](https://github.com/SMByC/ArrNorm)                                     |\n| Multi-Rule-Based Normalization          | Combines several selection rules to identify invariant pixels                                                                                                                     | Statistical | None                | No               | Any                                |                 |                                                                                                        |                                                                                                |\n| PCA                                     | Uses principal component analysis to identify pseudo-invariant pixels along the major axis of multitemporal scatterplots                                                          | Statistical | Co-registered       | Yes              | Any                                | 2002            | [(Du et al., 2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000299?via%3Dihub)    |                                                                                                |\n| Gradient angle similarity               | Selecting the 10% of pixels with the smallest gradient angle differences between an image and its reference                                                                       | Statistical | Co-registered       | Yes              | Any                                | 2020            | [(Hessel et al., 2020)](https://isprs-annals.copernicus.org/articles/V-2-2020/845/2020/)               | [rrn-multisensor-multidate Python scripts](https://github.com/chlsl/rrn-multisensor-multidate) |\n| Feature-Based (Keypoint) RRN            | Matches distinctive features between images and uses their correspondence to guide normalization                                                                                  | Geometric   | Moderate            | Yes              | Any                                |                 |                                                                                                        |                                                                                                |\n| Location-Independent RRN (LIRRN)        | Groups pixels by brightness or spectral similarity, then matches these groups between images to perform group-wise normalization                                                  | Geometric   | Moderate            | Yes              | Any                                | 2024            | [(Maghimi et al., 2024)](https://www.mdpi.com/1424-8220/24/7/2272)                                     | [LIRRN MATLAB scripts](https://github.com/ArminMoghimi/LIRRN/tree/main)                        |\n\n\n### File: formats_and_requirements.md\n# File Formats and Input Requirements\n\n## Input Raster Requirements\nInput rasters must meet specific criteria to ensure compatibility during processing. These are checked by _check_raster_requirements():\n\n- Have a valid geotransform\n- Share the same coordinate reference system (CRS)\n- Have an identical number of bands\n- Use consistent nodata values\n\nAdditionally, all rasters should:\n\n - Be a `.tif` file\n - Have overlap which represents the same data in each raster\n - Have a consistent spectral profile \n\n## Regression Parameters File\nRegression parameters can be stored in a `json` file which includes:\n\n - Adjustments: Per-band scale and offset values applied to each image.\n - Whole Stats: Per-band mean, std, and size representing overall image statistics.\n - Overlap Stats: Per-image pair mean, std, and size for overlapping geometry regions.\n\nThe structure is a dictionary keyed by images basenames (no extension) with the following format:\n\n<pre><code>{\n  \"image_name\": {\n    \"adjustments\": {\n      \"band_0\": {\"scale\": float, \"offset\": float},\n      ...\n    },\n    \"whole_stats\": {\n      \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n      ...\n    },\n    \"overlap_stats\": {\n      \"other_image\": {\n        \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n        ...\n      },\n      ...\n    }\n  },\n  ...\n}\n</code></pre>\nThis format represents the following: For each image_name there are adjustment, whole_stats and overlap_stats. For each adjustments, for each band, there is scale and offset. For each whole_stats and overlap_stats, for each band, there is mean, std, and size (number of pixels). Each band key follows the format band_0, band_1, etc. Mean and std are floats and size is an integer.\n\nThis structure is validated by `_validate_adjustment_model_structure()` before use to ensure consistency and completeness across images and bands. Global regression does not actually use 'adjustments' field because they are recalculated every run.\n\n## Block Maps File\nBlock maps are spatial summaries of raster data, where each block represents the mean values of a group of pixels over a fixed region. They are used to reduce image resolution while preserving local radiometric characteristics, enabling efficient comparison and adjustment across images. Each map is structured as a grid of blocks with values for each spectral band. They can be saved as regular `geotif` files and together store this information: block_local_means, block_reference_mean, num_row, num_col, bounds_canvas_coords. \n\nThere are two types of block maps, although their format is exactly the same:\n\n - **Local Block Map:** Each block stores the mean value of all pixels within its boundary for a single image.\n - **Reference Block Map:** Each block is the mean of all images means for its boundary; simply the mean of all local block maps.\n\nBoth block maps have the shape: `num_row, num_col, num_bands`, however, there are multiple (one for each image) local block maps and only one reference block map. Once a reference block map is created it is unique to its input images and cannot be accurately modified to add additional images. However, images can be 'brought' to a reference block map even if they were not involved in its creation as long as it covers that image.\n\n\n### File: index.md\n# spectralmatch: A toolkit to perform Relative Radiometric Normalization, with utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, and statistics\n\n[![Your-License-Badge](https://img.shields.io/badge/License-MIT-green)](#)\n[![codecov](https://codecov.io/gh/spectralmatch/spectralmatch/graph/badge.svg?token=OKAM0BUUNS)](https://codecov.io/gh/spectralmatch/spectralmatch)\n[![Open in Cloud Shell](https://img.shields.io/badge/Launch-Google_Cloud_Shell-blue?logo=googlecloud)](https://ssh.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https://github.com/spectralmatch/spectralmatch&amp;cloudshell_working_dir=.)\n[![\ud83d\udccb Copy LLM Prompt](https://img.shields.io/badge/\ud83d\udccb_Copy-LLM_Prompt-brightgreen)](https://spectralmatch.github.io/spectralmatch/llm_prompt)\n&gt; [!IMPORTANT]\n&gt; This library is experimental and still under heavy development.\n\n ---\n\n## Overview\n\n![Global and Local Matching](./images/spectralmatch.png)\n\n*spectralmatch* provides a Python library and QGIS plugin with multiple algorythms to perform Relative Radiometric Normalization (RRN). It also includes utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, statistics, preprocessing, and more.\n\n## Features\n\n- **Automated:** Works without manual intervention, making it ideal for large-scale applications.\n\n- **Multiprocessing:** Image, window, and band parallel processing. Cloud Optimized GeoTIFF reading and writing.\n\n- **Save Intermediate Steps:** Save image stats and block maps for quick reprocessing.\n\n- **Specify Model Images** Include all or specified images in the matching solution to bring all images to a central tendency or selected images spectral profile.\n\n- **Consistent Multi-Image Analysis:** Ensures uniformity across images by applying systematic corrections with minimal spectral distortion.\n\n- **Seamlessly Blended:** Creates smooth transitions between images.\n\n- **Unit Agnostic:** Works with any pixel unit and preserves the spectral information for accurate analysis. This inlcludes negative numbers and reflectance.\n\n- **Better Input for Machine Learning Models:** Provides high-quality, unbiased data for AI and analytical workflows.\n\n- **Sensor Agnostic:** Works with all optical sensors. In addition, images from different sensors can be combined for multisensor analysis.\n\n- **Mosaics:** Designed to process and blend vast image collections effectively.\n\n- **Time Series**: Normalize images across time with to compare spectral changes.\n\n---\n\n## Current Matching Algorithms\n\n### Global to local matching\nThis technique is derived from 'An auto-adapting global-to-local color balancing method for optical imagery mosaic' by Yu et al., 2017 (DOI: 10.1016/j.isprsjprs.2017.08.002). It is particularly useful for very high-resolution imagery (satellite or otherwise) and works in a two phase process.\nFirst, this method applies least squares regression to estimate scale and offset parameters that align the histograms of all images toward a shared spectral center. This is achieved by constructing a global model based on the overlapping areas of adjacent images, where the spectral relationships are defined. This global model ensures that each image conforms to a consistent radiometric baseline while preserving overall color fidelity.\nHowever, global correction alone cannot capture intra-image variability so a second local adjustment phase is performed. The overlap areas are divided into smaller blocks, and each block\u2019s mean is used to fine-tune the color correction. This block-wise tuning helps maintain local contrast and reduces visible seams, resulting in seamless and spectrally consistent mosaics with minimal distortion.\n\n\n![Histogram matching graph](./images/matching_histogram.png)\n*Shows the average spectral profile of two WorldView 3 images before and after global to local matching.*\n\n#### Assumptions\n\n- **Consistent Spectral Profile:** The true spectral response of overlapping areas remains the same throughout the images.\n\n- **Least Squares Modeling:** A least squares approach can effectively model and fit all images' spectral profiles.\n\n- **Scale and Offset Adjustment:** Applying scale and offset corrections can effectively harmonize images.\n\n- **Minimized Color Differences:** The best color correction is achieved when color differences are minimized.\n\n- **Geometric Alignment:** Images are assumed to be geometrically aligned with known relative positions.\n\n- **Global Consistency:** Overlapping color differences are consistent across the entire image.\n\n- **Local Adjustments:** Block-level color differences result from the global application of adjustments.\n\n---\n## Quick Installation ([Other methods](https://spectralmatch.github.io/spectralmatch/installation/))\n\n### Installation as a QGIS Plugin\nInstall the spectralmatch plugin in [QGIS](https://qgis.org/download/) and use it in the Processing Toolbox.\n\n### Installation as a Python Library\n\nBefore installing, ensure you have the following system-level prerequisites: `Python \u2265 3.10`, `pip`, `PROJ \u2265 9.3`, and `GDAL = 3.10.2`. Use this command to install the library:\n\n\n<pre><code>pip install spectralmatch\n</code></pre>\n\n---\n\n## Documentation\n\nDocumentation is available at [spectralmatch.github.io/spectralmatch/](https://spectralmatch.github.io/spectralmatch/).\n\n---\n## Contributing Guide\n\nContributing Guide is available at [spectralmatch.github.io/spectralmatch/contributing](https://spectralmatch.github.io/spectralmatch/contributing/).\n\n---\n\n## License\n\nThis project is licensed under the MIT License. See [LICENSE](https://github.com/spectralmatch/spectralmatch/blob/main/LICENSE) for details.\n\n\n### File: contributing.md\n# Contributing Guide\n\nThank you for your interest in contributing. The sections below outline how the library is structured, how to submit changes, and the conventions to follow when developing new features or improving existing functionality.\n\nFor convenience, you can copy [this](/spectralmatch/llm_prompt/) auto updated LLM priming prompt with function headers and docs.\n\n---\n\n## Collaboration Instructions\n\nWe welcome all contributions the project! Please be respectful and work towards improving the library. To get started:\n\n1. [Create an issue](https://github.com/spectralmatch/spectralmatch/issues/new) describing the feature or bug or just to ask a question. Provide relevant context, desired timeline, any assistance needed, who will be responsible for the work, anticipated results, and any other details.\n\n2. [Fork the repository](https://github.com/spectralmatch/spectralmatch/fork) and create a new feature branch.\n\n3. Make your changes and add any necessary tests.\n\n4. Open a Pull Request against the main repository.\n\n---\n\n## Design Philosophy\n\n - Keep code concise and simple\n - Adapt code for large datasets with windows, multiprocessing, progressive computations, etc\n - Keep code modular and have descriptive names\n - Use PEP 8 code formatting\n - Use functions that are already created when possible\n - Combine similar params into one multi-value parameter\n - Use similar naming convention and input parameter format as other functions.\n - Create docstrings (Google style), tests, and update the docs for new functionality\n\n---\n\n## Extensible Function Types\n\nIn Relative Radiometric Normalization (RRN) methods often differ in how images are matched, pixels are selected, and seamlines are created. This library organizes those into distinct Python packages, while other operations like aligning rasters, applying masks, merging images, and calculating statistics are more consistent across techniques and are treated as standard utilities.\n\n### Matching functions\n\nUsed to adjust the pixel values of images to ensure radiometric consistency across scenes. These functions compute differences between images and apply transformations so that brightness, contrast, or spectral characteristics align across datasets.\n\n\n### Masking functions (PIF/RCS)\n\nUsed to define which parts of an image should be kept or discarded based on spatial criteria. These functions apply vector-based filters or logical rules to isolate regions of interest, remove clouds, or exclude invalid data from further processing.\n\n\n### Seamline functions\n\nUsed to determine optimal boundaries between overlapping image regions. These functions generate cutlines that split image footprints in a way that minimizes visible seams and balances spatial coverage, often relying on geometric relationships between overlapping areas.\n\n---\n\n## Standard UI\n\nReusable types are organized into the types and validation module. Use these types directly as the types of params inside functions where applicable. Use the appropriate _resolve... function to resolve these inputs into usable variables.\n\n### Input/Output\nThe input_images parameter accepts either a tuple or a list. If given as a tuple, it should contain a folder path and a glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). Alternatively, it can be a list of full file paths to individual input images. The output_images parameter defines how output filenames are determined. It can also be a tuple, consisting of an output folder and a filename template where \"\\$\" is replaced with each input image\u2019s basename (e.g., (\"/output/folder\", \"$_GlobalMatch.tif\")). Alternatively, it may be a list of full output paths, which must match the number of input images.\n<pre><code># Params\ninput_images\noutput_images\n\n# Types\nSearchFolderOrListFiles = Tuple[str, str] | List[str] # Required\nCreateInFolderOrListFiles = Tuple[str, str] | List[str] # Required\n\n# Resolve\ninput_image_paths = _resolve_paths(\"search\", input_images)\noutput_image_paths = _resolve_paths(\"create\", output_images, (input_image_paths,))\n</code></pre>\n\n### Output dtype\nThe custom_output_dtype parameter specifies the data type for output rasters and defaults to the input image\u2019s data type if not provided.\n<pre><code># Param\ncustom_output_dtype\n\n# Type\nCustomOutputDtype = str | None # Default: None\n\n# Resolve\noutput_dtype = _resolve_output_dtype(rasterio.DatasetReader, custom_output_dtype)\n</code></pre>\n\n\n### Nodata Value\nThe custom_nodata_value parameter overrides the input nodata value from the first raster in the input rasters if set. \n<pre><code># Param\ncustom_nodata_value\n\n# Type\nCustomNodataValue = float | int | None # Default: None\n\n# Resolve\nnodata_value = _resolve_nodata_value(rasterio.DatasetReader, custom_nodata_value)\n</code></pre>\n\n### Debug Logs\nThe debug_logs parameter enables printing of debug information; it defaults to False. Functions should begin by printing \"Start {process name}\", while all other print statements should be conditional on debug_logs being True.\n<pre><code># Param\ndebug_logs\n\n# Type\nDebugLogs = bool # Default: False\n\n# No resolve function necessary\n</code></pre>\n\n### Vector Mask\nThe vector_mask parameter limits statistics calculations to specific areas and is given as a tuple with two or three items: a literal \"include\" or \"exclude\" to define how the mask is applied, a string path to the vector file, and an optional field name used to match geometries based on the input image name (substring match allowed). Defaults to None for no mask.\n\n<pre><code># Param\nvector_mask\n\n# Type\nVectorMask = Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None\n\n# No resolve function necessary\n</code></pre>\n\n### Parallel Workers\nThe image_parallel_workers parameter defines the parallelization strategy at the image level. It accepts a tuple such as (\"process\", \"cpu\") to enable multiprocessing across all available CPU cores, or you can use \"thread\" as the backend if threading is preferred. Set it to None to disable image-level parallelism. The window_parallel_workers parameter controls parallelization within each image at the window level and follows the same format. Setting it to None disables window-level parallelism. Processing windows should be done one band at a time for scalability.\n<pre><code># Params\nimage_parallel_workers\nwindow_parallel_workers\n\n# Types\nImageParallelWorkers = Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None\nWindowParallelWorkers = Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None\n\n# Resolve\nimage_parallel, image_backend, image_max_workers = _resolve_parallel_config(image_parallel_workers)\nwindow_parallel, window_backend, window_max_workers = _resolve_parallel_config(window_parallel_workers)\n\n\n# Main process example\nimage_args = [(arg, other_args, ...) for arg in inputs]\nif image_parallel:\n    with _get_executor(image_backend, image_max_workers) as executor:\n        futures = [executor.submit(_name_process_image, *arg) for arg in image_args]\n        for future in as_completed(futures):\n                result = future.result()\nelse:\n        for arg in image_args:\n            result = _name_process_image(*arg)\n\ndef _name_process_image(image_name, arg_1, arg_2, ...):\n    with rasterio.open(input_image_path) as src:\n        # Open output image as well if saving to image\n        windows = _resolve_windows(src, window_size)\n        window_args = [(window, other_args, ...) for window in windows]\n\n        with _get_executor(\n            window_backend, \n            window_max_workers,\n            initializer=WorkerContext.init,\n            initargs=({image_name: (\"raster\", input_image_path)},)\n            ) as executor:\n            futures = [executor.submit(_name_process_window, *arg) for arg in window_args]\n            for future in as_completed(futures):\n                band, window, result = future.result()\n                # Save result to variable or dataset\n        else:\n            WorkerContext.init({image_name: (\"raster\", input_image_path)})\n            for arg in window_args:\n                band, window, buf = _name_process_window(*arg)\n                # Save result to variable or dataset\n            WorkerContext.close()\n\ndef _name_process_window(image_name, arg_1, arg_2, ...):\n    ds = WorkerContext.get(image_name)\n    # Process result to return\n\n    return band, window, data\n</code></pre>\n\n### Windows\nThe window_size parameter sets the tile size for reading and writing, using an integer for square tiles, a tuple for custom dimensions, \"internal\" to use the raster\u2019s native tiling (ideal for efficient streaming from COGs), or None to process the full image at once.\n<pre><code># Param\nwindow_size\n\n# Types\nWindowSize = int | Tuple[int, int] | Literal[\"internal\"] | None\nWindowSizeWithBlock = int | Tuple[int, int] | Literal[\"internal\", \"block\"] | None\n\n# Resolve\nwindows = _resolve_windows(rasterio.DatasetReader, window_size)\n</code></pre>\n\n### COGs\nThe save_as_cog parameter, when set to True, saves the output as a Cloud-Optimized GeoTIFF with correct band and block ordering.\n<pre><code># Param\nSaveAsCog = bool # Default: True\n\n# Type\nSaveAsCog = bool # Default: True\n\n# No resolve function necessary\n</code></pre>\n\n---\n\n## Validate Inputs\nThe validate methods are used to check that input parameters follow expected formats before processing begins. There are different validation methods for different scopes\u2014some are general-purpose (e.g., Universal.validate) and others apply to specific contexts like matching (Match.validate_match). These functions raise clear errors when inputs are misconfigured, helping catch issues early and enforce consistent usage patterns across the library.\n<pre><code># Validate params example\nUniversal.validate(\n    input_images=input_images,\n    output_images=output_images,\n    vector_mask=vector_mask,\n)\nMatch.validate_match(\n    specify_model_images=specify_model_images,\n    )\n</code></pre>\n\n---\n\n## File Cleanup\nTemporary generated files can be deleted once they are no longer needed via this command:\n<pre><code>make clean\n</code></pre>\n\n---\n\n## Docs\n\n### Serve docs locally\nRuns a local dev server at http://localhost:8000.\n<pre><code>make docs-serve\n</code></pre>\n\n### Build static site\nGenerates the static site into the site/ folder.\n\n<pre><code>make docs-build\n</code></pre>\n\n### Deploy to GitHub Pages\nDeploys built site using mkdocs gh-deploy.\n<pre><code>make docs-deploy\n</code></pre>\n---\n\n## Versioning\nUses git tag to create annotated version tags and push them. This also syncs to Pypi. New versions will be released when the maintainer determines sufficient new functionality has been added.\n<pre><code>make tag version=1.2.3\n</code></pre>\n\n---\n\n## Code Formatting\nThis project uses [black](https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html) for code formatting and ruff for linting.\n\n### Set Up Pre-commit Hooks (Recommended)\nTo maintain code consistency use this hook to check and correct code formatting automatically:\n\n<pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>\n\n### Manual Formatting\n\n**Format code:** Automatically formats all Python files with black.\n\n<pre><code>make format\n</code></pre>\n\n**Check formatting:** Checks that all code is formatted (non-zero exit code if not).\n<pre><code>make check-format\n</code></pre>\n\n**Lint code:** Runs ruff to catch style and quality issues.\n<pre><code>make lint\n</code></pre>\n\n---\n\n## Testing\n[pytest](https://docs.pytest.org/) is used for testing. Tests will automatically be run when merging into main but they can also be run locally via:\n<pre><code>make test\n</code></pre>\n\nTo test a individual folder or file:\n<pre><code>make test-file path=path/to/folder_or_file\n</code></pre>\n\n\n### File: installation.md\n# Installation Methods\n\n---\n\n## Installation as QGIS Plugin for Easy GUI Interface\n\n### 1. [Download](https://qgis.org/download/) and install QGIS\n### 2.  Open QGIS\n### 3.  Go to Plugins \u2192 Manage and Install Plugins\u2026\n### 4.  Find spectralmatch in the list, install, and enable it\n### 5.  Find the plugin in the Processing Toolbox\n\n---\n\n## Installation as a Python Library for use in Code (Recommended)\n\n### 1. System requirements\nBefore installing, ensure you have the following system-level prerequisites:\n\n- Python \u2265 3.10\n- PROJ \u2265 9.3\n- GDAL = 3.10.2\n- pip\n\nAn easy way to install these dependancies is to use [Miniconda](https://www.anaconda.com/docs/getting-started/miniconda/install#quickstart-install-instructions):\n<pre><code>conda create -n spectralmatch python=3.10 \"gdal=3.10.2\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre>\n\n### 2. Install spectralmatch\n\nYou can automatically install the library via [PyPI](https://pypi.org/). (this method installs only the core code as a library):\n\n<pre><code>pip install spectralmatch\n</code></pre>\n\n### 3. Run an example and modify for your use (optional)\n\nExample scripts are provided to verify a successful installation and help you get started quickly in the repository at [`/docs/examples`](https://github.com/spectralmatch/spectralmatch/blob/main/docs/examples/) and downloadable via this [`link`](https://download-directory.github.io/?url=https://github.com/spectralmatch/spectralmatch/tree/main/docs/examples&amp;filename=spectralmatch_examples).\n\n---\n\n## Installation as Python Code for Development and Customization\n\n### 1. Clone the Repository\n<pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\n</code></pre>\n\n&gt; Assuming you have Make installed, you can then run `make install-setup` to automatically complete the remaining setup steps.\n\n### 2. System requirements\nBefore installing, ensure you have the following system-level prerequisites:\n\n- Python \u2265 3.10\n- PROJ \u2265 9.3\n- GDAL = 3.10.2\n\nAn easy way to install these dependancies is to use [Miniconda](https://www.anaconda.com/docs/getting-started/miniconda/install#quickstart-install-instructions):\n<pre><code>conda create -n spectralmatch python=3.10 \"gdal=3.10.2\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre>\n\n### 3. Install Dependancies (Optional Dev and Docs Dependancies)\nThe `pyproject.toml` defines **core** dependancies to run the library and optional **dev**, and **docs** dependancies.\n\n<pre><code>pip install . # normal dependencies\npip install -e \".[dev]\"   # developer dependencies\npip install -e \".[docs]\"  # documentation dependencies\n</code></pre>\n\n### 4. Read the [Contributing Guide](https://spectralmatch.github.io/spectralmatch/contributing/) if you aim to contribute\n\n\n### File: api/match.md\n::: spectralmatch.match.global_regression\n\n::: spectralmatch.match.local_block_adjustment\n\n\n### File: api/statistics.md\n::: spectralmatch.statistics\n\n\n### File: api/mask.md\n::: spectralmatch.mask.mask\n\n\n### File: api/handlers.md\n::: spectralmatch.handlers\n\n\n  </pre>"},{"location":"rrn_methods/","title":"Dimensions of Relative Radiometric Normalization (RRN) Methods","text":"<p>RRN methods differ not only in the algorithms used to adjust image values but also in the requirements images must have and other techniques that can be used in conjunction. The following taxonomy summarizes the core dimensions along which RRN techniques vary:</p> <ul> <li>Matching algorithm: The core transformation applied to align radiometry between images.</li> <li>Geometric alignment required: The level of spatial alignment necessary for the method.</li> <li>Pixel selection (PIFs/RCS): How pseudo-invariant features/control sets are identified.</li> <li>Adjustment scope: How corrections are applied to the images.</li> <li>Overlap: Whether the method requires overlapping pixels.</li> <li>Pixel units: The radiometric units the method is able to operate on.</li> <li>Bands: Whether bands relationships are preserved.</li> <li>Target reference: What the target image is normalized to.</li> </ul> <p>Multiple matching algorithms can be used in conjunction with multiple pixel selection methods. Note that the most restrictive method will dictate the image requirements (e.g. if using <code>Global regression</code> with <code>Overlapping area</code> the <code>Geometric alignment</code> will need to be <code>Moderate</code>). The specific matching algorithm used in each method is flexible and not fixed; it may involve least squares, RANSAC, Theil\u2013Sen, Huber, or other forms of robust regression.</p>"},{"location":"rrn_methods/#matching-algorithms","title":"Matching Algorithms","text":"Matching algorithm Description Geometric alignment Adjustment granularity Applies Overlap required Pixel units Bands Target reference Year introduced Key papers Software Histogram Matching (HM) Matches histogram distributions between images None Global Lookup table no Any Independent Reference histogram 1980s ENVI; HistMatch QGIS Plugin; ArcGIS Pro; IMAGINE Mosaic Pro; landsat R library via histmatch() Minimum\u2013Maximum Scale Normalization Linearly scales pixel values to match reference min/max None Global Min/max No Any Independent Reference min/max 1980s Mean\u2013Standard Deviation Regression Fits linear regression using mean and std dev None Global Gain/offset No Any Independent/Correlated Reference mean/std 1980s ArcGIS Pro; spectralmatch Python library and QGIS plugin Overlaping pixel-wise Linear Regression Fits linear regression using overlapping pairs of pixels Co-registered Model Gain/offset Yes Any Independent/Correlated Reference image pixels 1980s ArcGIS Pro; landsat R library via relnorm() Block adjusted gamma correction Adjusts local brightness via block-based gamma scaling Moderate Blocks/interpolation resolution Power function Yes Any Independent Reference block map (mean of local blocks) spectralmatch Python library and QGIS plugin CCA/KCCA-Based Finding the most correlated combinations between images Co-registered CCA space resolution Matrix Yes Any Correlated Reference canonical components Dodging Smooths brightness using low-pass filtering to reduce lighting artifacts Co-registered Blur resolution Low-pass brightness correction Yes Any Independent Blur created brightness values ArcGIS Pro; IMAGINE Mosaic Pro Illumination Equalization Models and removes large-scale illumination differences across images Co-registered Surface model resolution Modeled lighting correction Yes Any Independent Computed illumination values IMAGINE Mosaic Pro Wavelet reconstruction Uses ancillary data to model and reconstruct image values at multiple detail levels Co-registered Ancillary data resolution Decomposition/reconstruction Yes Any Correlated Ancillary data (Gan et al., 2021) Dual-reference affine interpolation Models corrections from the two nearest reference images and applies temporally weighted interpolation Co-registered Model Gain/offset Yes Any Independent Two closest high-quality reference images 2020 (Hessel et al., 2020) rrn-multisensor-multidate Python scripts"},{"location":"rrn_methods/#pixel-selection","title":"Pixel Selection","text":"Pixel selection (PIFs/RCS) Description Type Geometric alignment Overlap required Pixel units Year introduced Key papers Software Whole image Uses all pixels without selection or masking None None No Any Overlapping area Uses only pixels in the spatial overlap between images None Moderate Yes Any Manual polygons or pixels User-defined areas or points chosen as invariant Manual None No Any Manual threshold Selects pixels based on value threshold Threshold None No Any Dark/Bright Set (DB) Selects darkest and brightest pixels assumed to be invariant Threshold None No Any/reflectance may perform better NDVI ratio Uses vegetation indices to isolate vegetated areas for normalization Band ratio None No Reflectance spectralmatch Python library and QGIS plugin K-T ratio Uses the Kauth\u2013Thomas transformation to identify invariant pixels in greenness\u2013brightness space Band ratio None No Reflectance (Hall et al., 1991) landsat R library via RCS() Urban materials ratio Assumes that certain man-made surfaces (e.g., roads, rooftops) have stable reflectance over time and uses their statistical properties to correct radiometric differences Band ratio None No Reflectance 1988 (Schott et al., 1988) landsat R library via PIF() No-change  Scattergrams\u00a0(NC) Selects pixels near the scatterplot diagonal where reference and target values match closely Statistical Co-registered Yes Any (De Carvalho et al., 2013) Multivariate Alteration Detection (MAD) Identifies invariant pixels by transforming image differences into uncorrelated components; selects pixels with minimal change across all bands Statistical Co-registered Yes Any Iteratively Reweighted MAD (IR-MAD) Refines MAD by reweighting pixels to improve change detection Statistical Co-registered Yes Any (Canty &amp; Nielsen, 2008) ArrNorm Python scripts Multi-Rule-Based Normalization Combines several selection rules to identify invariant pixels Statistical None No Any PCA Uses principal component analysis to identify pseudo-invariant pixels along the major axis of multitemporal scatterplots Statistical Co-registered Yes Any 2002 (Du et al., 2002) Gradient angle similarity Selecting the 10% of pixels with the smallest gradient angle differences between an image and its reference Statistical Co-registered Yes Any 2020 (Hessel et al., 2020) rrn-multisensor-multidate Python scripts Feature-Based (Keypoint) RRN Matches distinctive features between images and uses their correspondence to guide normalization Geometric Moderate Yes Any Location-Independent RRN (LIRRN) Groups pixels by brightness or spectral similarity, then matches these groups between images to perform group-wise normalization Geometric Moderate Yes Any 2024 (Maghimi et al., 2024) LIRRN MATLAB scripts"},{"location":"api/handlers/","title":"Data Handlers for IO","text":""},{"location":"api/handlers/#spectralmatch.handlers.create_paths","title":"<code>create_paths(output_folder, template, paths_or_bases, debug_logs=False, replace_symbol='$', create_folders=True)</code>","text":"<p>Create output paths using a filename template and a list of reference paths or names.</p> <p>Parameters:</p> Name Type Description Default <code>output_folder</code> <code>str</code> <p>Directory to store output files.</p> required <code>template</code> <code>str</code> <p>Filename template using replace_symbol as placeholder (e.g., \"$_processed.tif\").</p> required <code>paths_or_bases</code> <code>List[str]</code> <p>List of full paths or bare names to derive replace_symbol from. Inclusion of '/' or '' indicates a path.</p> required <code>debug_logs</code> <code>bool</code> <p>Whether to print the created paths.</p> <code>False</code> <code>replace_symbol</code> <code>str</code> <p>Symbol to replace in the template.</p> <code>'$'</code> <code>create_folders</code> <code>bool</code> <p>Whether to create output folders if they don't exist.'</p> <code>True</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of constructed file paths.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def create_paths(\n    output_folder: str,\n    template: str,\n    paths_or_bases: List[str],\n    debug_logs: bool = False,\n    replace_symbol: str = \"$\",\n    create_folders: bool = True,\n    ) -&gt; List[str]:\n    \"\"\"\n    Create output paths using a filename template and a list of reference paths or names.\n\n    Args:\n        output_folder (str): Directory to store output files.\n        template (str): Filename template using replace_symbol as placeholder (e.g., \"$_processed.tif\").\n        paths_or_bases (List[str]): List of full paths or bare names to derive replace_symbol from. Inclusion of '/' or '\\' indicates a path.\n        debug_logs (bool): Whether to print the created paths.\n        replace_symbol (str): Symbol to replace in the template.\n        create_folders (bool): Whether to create output folders if they don't exist.'\n\n    Returns:\n        List[str]: List of constructed file paths.\n    \"\"\"\n    output_paths = []\n    for ref in paths_or_bases:\n        base = os.path.splitext(os.path.basename(ref))[0] if ('/' in ref or '\\\\' in ref) else os.path.splitext(ref)[0]\n        filename = template.replace(replace_symbol, base)\n        path = os.path.join(output_folder, filename)\n        output_paths.append(path)\n\n    if create_folders:\n        for path in output_paths:\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n    return output_paths\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.match_paths","title":"<code>match_paths(input_match_paths, reference_paths, match_regex, debug_logs=False)</code>","text":"<p>Match <code>reference_paths</code> to <code>input_match_paths</code> using a regex applied to the basenames of <code>input_match_paths</code>. The extracted key must be a substring of the reference filename.</p> <p>Parameters:</p> Name Type Description Default <code>input_match_paths</code> <code>List[str]</code> <p>List of candidate paths to extract keys from.</p> required <code>reference_paths</code> <code>List[str]</code> <p>List of reference paths to align to.</p> required <code>match_regex</code> <code>str</code> <p>Regex applied to basenames of input_match_paths to extract a key to match via inclusion in reference_paths (e.g. \"(.*)_LocalMatch.gpkg$\" (without one of the backslashes)).</p> required <code>debug_logs</code> <code>bool</code> <p>If True, print matched and unmatched file basenames.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[Optional[str]]</code> <p>List[Optional[str]]: A list the same length as <code>reference_paths</code> where each</p> <code>List[Optional[str]]</code> <p>element is the matched path from <code>input_match_paths</code> or None.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If output list length does not match reference_paths length.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def match_paths(\n    input_match_paths: List[str],\n    reference_paths: List[str],\n    match_regex: str,\n    debug_logs: bool = False,\n    ) -&gt; List[Optional[str]]:\n    \"\"\"\n    Match `reference_paths` to `input_match_paths` using a regex applied to the basenames of `input_match_paths`. The extracted key must be a substring of the reference filename.\n\n    Args:\n        input_match_paths (List[str]): List of candidate paths to extract keys from.\n        reference_paths (List[str]): List of reference paths to align to.\n        match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via *inclusion* in reference_paths (e.g. \"(.*)_LocalMatch\\\\.gpkg$\" (without one of the backslashes)).\n        debug_logs (bool): If True, print matched and unmatched file basenames.\n\n    Returns:\n        List[Optional[str]]: A list the same length as `reference_paths` where each\n        element is the matched path from `input_match_paths` or None.\n\n    Raises:\n        ValueError: If output list length does not match reference_paths length.\n    \"\"\"\n    pattern = re.compile(match_regex)\n    match_keys = {}\n    used_matches = set()\n\n    # Extract keys from input_match_paths\n    for mpath in input_match_paths:\n        basename = os.path.basename(mpath)\n        match = pattern.search(basename)\n        if not match:\n            continue\n        key = match.group(1) if match.groups() else match.group(0)\n        match_keys[key] = mpath\n\n    # Match each reference path\n    matched_list: List[Optional[str]] = []\n    for rpath in reference_paths:\n        rbase = os.path.basename(rpath)\n        matched = None\n        for key, mpath in match_keys.items():\n            if key in rbase:\n                matched = mpath\n                used_matches.add(mpath)\n                break\n        matched_list.append(matched)\n\n    # Validate output length\n    if len(matched_list) != len(reference_paths):\n        raise ValueError(\"Matched list length does not match reference_paths length.\")\n\n    return matched_list\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.search_paths","title":"<code>search_paths(folder_path, pattern, recursive=False, match_to_paths=None, debug_logs=False)</code>","text":"<p>Search for files in a folder using a glob pattern.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>The root folder to search in.</p> required <code>pattern</code> <code>str</code> <p>A glob pattern (e.g., \".tif\", \"/.jpg\").</p> required <code>recursive</code> <code>bool</code> <p>Whether to search for files recursively.</p> <code>False</code> <code>match_to_paths</code> <code>Tuple[List[str], str]</code> <p>If provided, match <code>reference_paths</code> to <code>input_match_paths</code> using a regex applied to the basenames of <code>input_match_paths</code>. The extracted key must be a substring of the reference filename. - reference_paths (List[str]): List of reference paths to align to. - match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via inclusion in reference_paths (e.g. \"(.*)_LocalMatch.gpkg$\").</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Whether to print the matched file paths.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: Sorted list of matched file paths.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def search_paths(\n    folder_path: str,\n    pattern: str,\n    recursive: bool = False,\n    match_to_paths: Tuple[List[str], str] | None = None,\n    debug_logs: bool = False,\n    ) -&gt; List[str]:\n    \"\"\"\n    Search for files in a folder using a glob pattern.\n\n    Args:\n        folder_path (str): The root folder to search in.\n        pattern (str): A glob pattern (e.g., \"*.tif\", \"**/*.jpg\").\n        recursive (bool, optional): Whether to search for files recursively.\n        match_to_paths (Tuple[List[str], str], optional): If provided, match `reference_paths` to `input_match_paths` using a regex applied to the basenames of `input_match_paths`. The extracted key must be a substring of the reference filename.\n            - reference_paths (List[str]): List of reference paths to align to.\n            - match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via *inclusion* in reference_paths (e.g. \"(.*)_LocalMatch.gpkg$\").\n        debug_logs (bool, optional): Whether to print the matched file paths.\n\n    Returns:\n        List[str]: Sorted list of matched file paths.\n    \"\"\"\n    input_paths =  sorted(glob.glob(os.path.join(folder_path, pattern), recursive=recursive))\n\n    if match_to_paths:\n        input_paths = match_paths(input_paths, *match_to_paths)\n\n    return input_paths\n</code></pre>"},{"location":"api/mask/","title":"Create Mask and Pseudo-Invariant Features","text":""},{"location":"api/mask/#spectralmatch.mask.mask.create_cloud_mask_with_omnicloudmask","title":"<code>create_cloud_mask_with_omnicloudmask(input_image_path, red_band_index, green_band_index, nir_band_index, output_mask_path, down_sample_m=None, debug_logs=False, **omnicloud_kwargs)</code>","text":"<p>Generates a cloud mask using OmniCloudMask from a multi-band image.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input image.</p> required <code>red_band_index</code> <code>int</code> <p>Index of the red band.</p> required <code>green_band_index</code> <code>int</code> <p>Index of the green band.</p> required <code>nir_band_index</code> <code>int</code> <p>Index of the NIR (or substitute blue) band.</p> required <code>output_mask_path</code> <code>str</code> <p>Path to save the output cloud mask GeoTIFF.</p> required <code>down_sample_m</code> <code>float</code> <p>Target resolution (in meters) to downsample the input before processing.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Debug logs to console.</p> <code>False</code> <code>omnicloud_kwargs</code> <code>Any</code> <p>Forwards key word args to OmniCloudMask predict_from_array() function. Repo here: https://github.com/DPIRD-DMA/OmniCloudMask.</p> <code>{}</code> Outputs <p>Saves a single-band cloud mask GeoTIFF at the specified path.</p> Source code in <code>spectralmatch/mask/mask.py</code> <pre><code>def create_cloud_mask_with_omnicloudmask(\n    input_image_path,\n    red_band_index,\n    green_band_index,\n    nir_band_index, # Blue band can work if nir isnt available\n    output_mask_path,\n    down_sample_m=None, # Down sample to 10 m if imagery has a spatial resolution &lt; 10 m\n    debug_logs: bool = False,\n    **omnicloud_kwargs: Any,\n    ):\n    \"\"\"\n    Generates a cloud mask using OmniCloudMask from a multi-band image.\n\n    Args:\n        input_image_path (str): Path to the input image.\n        red_band_index (int): Index of the red band.\n        green_band_index (int): Index of the green band.\n        nir_band_index (int): Index of the NIR (or substitute blue) band.\n        output_mask_path (str): Path to save the output cloud mask GeoTIFF.\n        down_sample_m (float, optional): Target resolution (in meters) to downsample the input before processing.\n        debug_logs (bool, optional): Debug logs to console.\n        omnicloud_kwargs: Forwards key word args to OmniCloudMask predict_from_array() function. Repo here: https://github.com/DPIRD-DMA/OmniCloudMask.\n\n    Outputs:\n        Saves a single-band cloud mask GeoTIFF at the specified path.\n    \"\"\"\n\n    print(\"Start create omnicloudmask\")\n    if not os.path.exists(os.path.dirname(output_mask_path)): os.makedirs(os.path.dirname(output_mask_path), exist_ok=True)\n    with rasterio.open(input_image_path) as src:\n        if down_sample_m is not None:\n            # Compute new dimensions based on the image bounds and the desired resolution.\n            left, bottom, right, top = src.bounds\n            new_width = int((right - left) / down_sample_m)\n            new_height = int((top - bottom) / down_sample_m)\n            new_transform = from_origin(left, top, down_sample_m, down_sample_m)\n            # Read the bands with resampling to the new size.\n            red   = src.read(red_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            green = src.read(green_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            nir   = src.read(nir_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            meta = src.meta.copy()\n            meta.update({\n                'width': new_width,\n                'height': new_height,\n                'transform': new_transform,\n            })\n        else:\n            # Read without resampling.\n            red   = src.read(red_band_index)\n            green = src.read(green_band_index)\n            nir   = src.read(nir_band_index)\n            meta = src.meta.copy()\n\n        # Stack bands into an array of shape (3, height, width).\n        band_array = np.stack([red, green, nir], axis=0)\n\n    # Predict the mask (expected shape: (1, height, width))\n    pred_mask = predict_from_array(band_array, **omnicloud_kwargs)\n    pred_mask = np.squeeze(pred_mask)\n\n    # Update metadata for a single-band output.\n    meta.update({\n        'driver': 'GTiff',\n        'count': 1,\n        'dtype': pred_mask.dtype,\n        'nodata': 0,\n    })\n\n    # Write the predicted mask to a GeoTIFF file.\n    with rasterio.open(output_mask_path, 'w', **meta) as dst:\n        dst.write(pred_mask, 1)\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.mask.create_ndvi_mask","title":"<code>create_ndvi_mask(input_image_path, output_image_path, nir_band, red_band)</code>","text":"<p>Computes NDVI from a multi-band image and saves the result as a GeoTIFF.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input image with NIR and red bands.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the NDVI output GeoTIFF.</p> required <code>nir_band</code> <code>int</code> <p>Band index for NIR (1-based).</p> required <code>red_band</code> <code>int</code> <p>Band index for red (1-based).</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the saved NDVI output.</p> Source code in <code>spectralmatch/mask/mask.py</code> <pre><code>def create_ndvi_mask(\n    input_image_path: str,\n    output_image_path: str,\n    nir_band: int,\n    red_band: int,\n    ) -&gt; str:\n    \"\"\"\n    Computes NDVI from a multi-band image and saves the result as a GeoTIFF.\n\n    Args:\n        input_image_path (str): Path to the input image with NIR and red bands.\n        output_image_path (str): Path to save the NDVI output GeoTIFF.\n        nir_band (int): Band index for NIR (1-based).\n        red_band (int): Band index for red (1-based).\n\n    Returns:\n        str: Path to the saved NDVI output.\n    \"\"\"\n\n    print(\"Start ndvi computation\")\n    if not os.path.exists(os.path.dirname(output_image_path)): os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n\n    with rasterio.open(input_image_path) as src:\n        nir = src.read(nir_band).astype(np.float32)\n        red = src.read(red_band).astype(np.float32)\n        ndvi = (nir - red) / (nir + red + 1e-9)\n\n        print(\"NIR min/max:\", np.nanmin(nir), np.nanmax(nir))\n        print(\"Red min/max:\", np.nanmin(red), np.nanmax(red))\n        print(\"NDVI min/max:\", np.nanmin(ndvi), np.nanmax(ndvi))\n\n        profile = src.profile\n        profile.update(dtype=rasterio.float32, count=1)\n\n        with rasterio.open(output_image_path, 'w', **profile) as dst:\n            dst.write(ndvi, 1)\n\n    return output_image_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.mask.post_process_raster_cloud_mask_to_vector","title":"<code>post_process_raster_cloud_mask_to_vector(input_image_path, output_vector_path, minimum_mask_size_percentile=None, polygon_buffering_in_map_units=None, value_mapping=None)</code>","text":"<p>Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input cloud mask raster.</p> required <code>output_vector_path</code> <code>str</code> <p>Path to the output vector layer.</p> required <code>minimum_mask_size_percentile</code> <code>float</code> <p>Percentile threshold to filter small polygons by area.</p> <code>None</code> <code>polygon_buffering_in_map_units</code> <code>dict</code> <p>Mapping of raster values to buffer distances.</p> <code>None</code> <code>value_mapping</code> <code>dict</code> <p>Mapping of original raster values to new values before vectorization.</p> <code>None</code> Outputs <p>Saves a vector layer to the output path.</p> Source code in <code>spectralmatch/mask/mask.py</code> <pre><code>def post_process_raster_cloud_mask_to_vector(\n    input_image_path: str,\n    output_vector_path: str,\n    minimum_mask_size_percentile: float = None,\n    polygon_buffering_in_map_units: dict = None,\n    value_mapping: dict = None\n    ) -&gt; ogr.DataSource:\n    \"\"\"\n    Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.\n\n    Args:\n        input_image_path (str): Path to the input cloud mask raster.\n        output_vector_path (str): Path to the output vector layer.\n        minimum_mask_size_percentile (float, optional): Percentile threshold to filter small polygons by area.\n        polygon_buffering_in_map_units (dict, optional): Mapping of raster values to buffer distances.\n        value_mapping (dict, optional): Mapping of original raster values to new values before vectorization.\n\n    Outputs:\n        Saves a vector layer to the output path.\n    \"\"\"\n\n    print(\"Start post-processing raster cloud mask\")\n    with rasterio.open(input_image_path) as src:\n        raster_data = src.read(1)\n        transform = src.transform\n        crs = src.crs\n\n    if value_mapping is not None:\n        include_mask = np.full(raster_data.shape, True, dtype=bool)\n        mapped = np.copy(raster_data)\n        for orig_value, new_value in value_mapping.items():\n            if new_value is None:\n                include_mask &amp;= raster_data != orig_value  # Exclude from processing\n            else:\n                mapped[raster_data == orig_value] = new_value\n        raster_data = mapped\n    else:\n        include_mask = None\n\n    results = (\n        {'properties': {'value': v}, 'geometry': s}\n        for s, v in shapes(raster_data, mask=include_mask, transform=transform, connectivity=4)\n    )\n    features = list(results)\n    if not features:\n        print(\"No features were detected in the raster mask.\")\n        return None\n\n\n    gdf = gpd.GeoDataFrame.from_features(features, crs=crs)\n\n    gdf['area'] = gdf.geometry.area\n    if minimum_mask_size_percentile is not None:\n        area_threshold = np.percentile(gdf['area'], minimum_mask_size_percentile)\n        print(f\"Area threshold (at {minimum_mask_size_percentile}th percentile): {area_threshold:.2f}\")\n        gdf = gdf[gdf['area'] &gt;= area_threshold].copy()\n\n    if polygon_buffering_in_map_units is not None:\n        gdf['geometry'] = gdf.apply(\n            lambda row: row['geometry'].buffer(polygon_buffering_in_map_units.get(row['value'], 0))\n            if row['value'] in polygon_buffering_in_map_units else row['geometry'],\n            axis=1\n        )\n\n    merged_features = []\n    for val, group in gdf.groupby('value'):\n        # Use union_all() to merge the geometries within the group.\n        # (Requires Shapely 2.0 or later; otherwise use shapely.ops.unary_union on group.geometry.tolist())\n        union_geom = group.geometry.union_all()\n        # If the union produces a single Polygon, add it directly;\n        # if it produces a MultiPolygon, split it into individual features.\n        if union_geom.geom_type == 'Polygon':\n            merged_features.append({'value': val, 'geometry': union_geom})\n        elif union_geom.geom_type == 'MultiPolygon':\n            for geom in union_geom.geoms:\n                merged_features.append({'value': val, 'geometry': geom})\n        else:\n            # In case of unexpected geometry types, skip or handle accordingly.\n            print(f\"Unexpected geometry type for value {val}: {union_geom.geom_type}\")\n    # Create a new GeoDataFrame from merged features.\n    gdf = gpd.GeoDataFrame(merged_features, crs=gdf.crs)\n\n\n    ogr_driver = ogr.GetDriverByName(\"Memory\")\n    mem_ds = ogr_driver.CreateDataSource(\"in_memory\")\n\n    # Determine an appropriate OGR geometry type using the first feature.\n    first_geom = gdf.geometry.iloc[0]\n    if first_geom.geom_type == \"Polygon\":\n        ogr_geom_type = ogr.wkbPolygon\n    elif first_geom.geom_type == \"MultiPolygon\":\n        ogr_geom_type = ogr.wkbMultiPolygon\n    else:\n        ogr_geom_type = ogr.wkbUnknown\n\n    # Convert the CRS to OGR SpatialReference.\n    sr = osr.SpatialReference()\n    try:\n        sr.ImportFromWkt(crs.to_wkt())\n    except AttributeError:\n        sr.ImportFromEPSG(4326)\n\n    mem_layer = mem_ds.CreateLayer(\"post_processed\", sr, ogr_geom_type)\n\n    # Add attribute field for 'value' (and any other non-geometry columns if needed).\n    # Here we add 'value' for example.\n    field_defn = ogr.FieldDefn(\"value\", ogr.OFTInteger)\n    mem_layer.CreateField(field_defn)\n\n    # Add each row from the GeoDataFrame as an OGR feature.\n    for idx, row in gdf.iterrows():\n        feat = ogr.Feature(mem_layer.GetLayerDefn())\n        ogr_geom = ogr.CreateGeometryFromWkt(row['geometry'].wkt)\n        feat.SetGeometry(ogr_geom)\n        feat.SetField(\"value\", row['value'])\n        mem_layer.CreateFeature(feat)\n        feat = None\n\n    driver = ogr.GetDriverByName(\"GPKG\")\n    if os.path.exists(output_vector_path):\n        driver.DeleteDataSource(output_vector_path)\n    out_ds = driver.CreateDataSource(output_vector_path)\n    out_ds.CopyLayer(mem_layer, \"post_processed\")\n    out_ds = None\n\n    return output_vector_path\n</code></pre>"},{"location":"api/match/","title":"Matching Algorithms","text":""},{"location":"api/match/#spectralmatch.match.global_regression.global_regression","title":"<code>global_regression(input_images, output_images, *, calculation_dtype='float32', output_dtype=None, vector_mask=None, debug_logs=False, custom_nodata_value=None, image_parallel_workers=None, window_parallel_workers=None, window_size=None, save_as_cog=False, specify_model_images=None, custom_mean_factor=1.0, custom_std_factor=1.0, save_adjustments=None, load_adjustments=None)</code>","text":"<p>Performs global radiometric normalization across overlapping images using least squares regression.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies the input images either as: - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). - A list of full file paths to individual input images.</p> required <code>output_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies how output filenames are generated or provided: - A tuple with an output folder and a filename template using \"\\(\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"\\)_GlobalMatch.tif\")). - A list of full output paths, which must match the number of input images.</p> required <code>calculation_dtype</code> <code>str</code> <p>Data type used for internal calculations. Defaults to \"float32\".</p> <code>'float32'</code> <code>output_dtype</code> <code>str | None</code> <p>Data type for output rasters. Defaults to input image dtype.</p> <code>None</code> <code>vector_mask</code> <code>Tuple[Literal['include', 'exclude'], str, Optional[str]] | None</code> <p>Mask to limit stats calculation to specific areas in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that includes (can be substring) input image name to filter geometry by. Loaded stats won't have this applied to them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>If True, prints debug information and constraint matrices. Defaults to False.</p> <code>False</code> <code>custom_nodata_value</code> <code>float | int | None</code> <p>Overrides detected NoData value. Defaults to None.</p> <code>None</code> <code>image_parallel_workers</code> <code>Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None</code> <p>Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.</p> <code>None</code> <code>window_parallel_workers</code> <code>Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None</code> <p>Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.</p> <code>None</code> <code>window_size</code> <code>int | Tuple[int, int] | Literal['internal'] | None</code> <p>Tile size for reading and writing: int for square tiles, tuple for (width, height), \"internal\" to use raster's native tiling, or None for full image. \"internal\" enables efficient streaming from COGs.</p> <code>None</code> <code>save_as_cog</code> <code>bool</code> <p>If True, saves output as a Cloud-Optimized GeoTIFF using proper band and block order.</p> <code>False</code> <code>specify_model_images</code> <code>Tuple[Literal['exclude', 'include'], List[str]] | None</code> <p>First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.</p> <code>None</code> <code>custom_mean_factor</code> <code>float</code> <p>Weight for mean constraints in regression. Defaults to 1.0.</p> <code>1.0</code> <code>custom_std_factor</code> <code>float</code> <p>Weight for standard deviation constraints in regression. Defaults to 1.0.</p> <code>1.0</code> <code>save_adjustments</code> <code>str | None</code> <p>The output path of a .json file to save adjustments parameters. Defaults to not saving.</p> <code>None</code> <code>load_adjustments</code> <code>str | None</code> <p>If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List[str]: Paths to the globally adjusted output raster images.</p> Source code in <code>spectralmatch/match/global_regression.py</code> <pre><code>def global_regression(\n    input_images: Universal.SearchFolderOrListFiles,\n    output_images: Universal.CreateInFolderOrListFiles,\n    *,\n    calculation_dtype: Universal.CalculationDtype = \"float32\",\n    output_dtype: Universal.CustomOutputDtype = None,\n    vector_mask: Universal.VectorMask = None,\n    debug_logs: Universal.DebugLogs = False,\n    custom_nodata_value: Universal.CustomNodataValue = None,\n    image_parallel_workers: Universal.ImageParallelWorkers = None,\n    window_parallel_workers: Universal.WindowParallelWorkers = None,\n    window_size: Universal.WindowSize = None,\n    save_as_cog: Universal.SaveAsCog = False,\n    specify_model_images: Match.SpecifyModelImages = None,\n    custom_mean_factor: float = 1.0,\n    custom_std_factor: float = 1.0,\n    save_adjustments: str | None = None,\n    load_adjustments: str | None = None,\n    ) -&gt; list:\n    \"\"\"\n    Performs global radiometric normalization across overlapping images using least squares regression.\n\n    Args:\n        input_images (Tuple[str, str] | List[str]):\n            Specifies the input images either as:\n            - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n            - A list of full file paths to individual input images.\n        output_images (Tuple[str, str] | List[str]):\n            Specifies how output filenames are generated or provided:\n            - A tuple with an output folder and a filename template using \"$\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"$_GlobalMatch.tif\")).\n            - A list of full output paths, which must match the number of input images.\n        calculation_dtype (str, optional): Data type used for internal calculations. Defaults to \"float32\".\n        output_dtype (str | None, optional): Data type for output rasters. Defaults to input image dtype.\n        vector_mask (Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None): Mask to limit stats calculation to specific areas in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that *includes* (can be substring) input image name to filter geometry by. Loaded stats won't have this applied to them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.\n        debug_logs (bool, optional): If True, prints debug information and constraint matrices. Defaults to False.\n        custom_nodata_value (float | int | None, optional): Overrides detected NoData value. Defaults to None.\n        image_parallel_workers (Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.\n        window_parallel_workers (Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.\n        window_size (int | Tuple[int, int] | Literal[\"internal\"] | None): Tile size for reading and writing: int for square tiles, tuple for (width, height), \"internal\" to use raster's native tiling, or None for full image. \"internal\" enables efficient streaming from COGs.\n        save_as_cog (bool): If True, saves output as a Cloud-Optimized GeoTIFF using proper band and block order.\n        specify_model_images (Tuple[Literal[\"exclude\", \"include\"], List[str]] | None ): First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.\n        custom_mean_factor (float, optional): Weight for mean constraints in regression. Defaults to 1.0.\n        custom_std_factor (float, optional): Weight for standard deviation constraints in regression. Defaults to 1.0.\n        save_adjustments (str | None, optional): The output path of a .json file to save adjustments parameters. Defaults to not saving.\n        load_adjustments (str | None, optional): If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.\n\n    Returns:\n        List[str]: Paths to the globally adjusted output raster images.\n    \"\"\"\n\n    print(\"Start global regression\")\n\n    # Validate params\n    Universal.validate(\n        input_images=input_images,\n        output_images=output_images,\n        save_as_cog=save_as_cog,\n        debug_logs=debug_logs,\n        vector_mask=vector_mask,\n        window_size=window_size,\n        custom_nodata_value=custom_nodata_value,\n        image_parallel_workers=image_parallel_workers,\n        window_parallel_workers=window_parallel_workers,\n        calculation_dtype=calculation_dtype,\n        output_dtype=output_dtype,\n    )\n\n    Match.validate_match(\n        specify_model_images=specify_model_images,\n    )\n\n    Match.validate_global_regression(\n        custom_mean_factor=custom_mean_factor,\n        custom_std_factor=custom_std_factor,\n        save_adjustments=save_adjustments,\n        load_adjustments=load_adjustments,\n    )\n\n    # Input and output paths\n    input_image_paths = _resolve_paths(\"search\", input_images)\n    output_image_paths = _resolve_paths(\"create\", output_images, (input_image_paths,))\n\n    if debug_logs: print(f\"Input images: {input_image_paths}\")\n    if debug_logs: print(f\"Output images: {output_image_paths}\")\n\n    input_image_names = [os.path.splitext(os.path.basename(p))[0] for p in input_image_paths]\n    input_image_path_pairs = dict(zip(input_image_names, input_image_paths))\n    output_image_path_pairs = dict(zip(input_image_names, output_image_paths))\n\n    # Check raster requirements\n    _check_raster_requirements(input_image_paths, debug_logs, check_geotransform=True, check_crs=True, check_bands=True, check_nodata=True)\n\n    nodata_val = _get_nodata_value(list(input_image_path_pairs.values()), custom_nodata_value)\n\n    # Determine multiprocessing and worker count\n    image_parallel, image_backend, image_max_workers = _resolve_parallel_config(image_parallel_workers)\n    window_parallel, window_backend, window_max_workers = _resolve_parallel_config(window_parallel_workers)\n\n    # Find loaded and input files if load adjustments\n    loaded_model = {}\n    if load_adjustments:\n        with open(load_adjustments, \"r\") as f:\n            loaded_model = json.load(f)\n        _validate_adjustment_model_structure(loaded_model)\n        loaded_names = set(loaded_model.keys())\n        input_names = set(input_image_names)\n    else:\n        loaded_names = set([])\n        input_names = set(input_image_names)\n\n    matched = input_names &amp; loaded_names\n    only_loaded = loaded_names - input_names\n    only_input = input_names - loaded_names\n    if debug_logs:\n        print(f\"Total images: input images: {len(input_names)}, loaded images {len(loaded_names)}: \")\n        print(f\"    Matched adjustments (to override) ({len(matched)}):\", sorted(matched))\n        print(f\"    Only in loaded adjustments (to add) ({len(only_loaded)}):\", sorted(only_loaded))\n        print(f\"    Only in input (to calculate) ({len(only_input)}):\", sorted(only_input))\n\n    # Find images to include in model\n    included_names = list(matched | only_loaded | only_input)\n    if specify_model_images:\n        mode, names = specify_model_images\n        name_set = set(names)\n        if mode == \"include\":\n            included_names = [n for n in input_image_names if n in name_set]\n        elif mode == \"exclude\":\n            included_names = [n for n in input_image_names if n not in name_set]\n        excluded_names = [n for n in input_image_names if n not in included_names]\n    if debug_logs:\n        print(\"Images to influence the model:\")\n        print(f\"    Included in model ({len(included_names)}): {sorted(included_names)}\")\n        if specify_model_images: print(f\"    Excluded from model ({len(excluded_names)}): {sorted(excluded_names)}\")\n        else: print(f\"    Excluded from model (0): []\")\n\n    if debug_logs: print(\"Calculating statistics\")\n    with rasterio.open(list(input_image_path_pairs.values())[0]) as src: num_bands = src.count\n\n    # Get images bounds\n    all_bounds = {}\n    for name, path in input_image_path_pairs.items():\n        with rasterio.open(path) as ds:\n            all_bounds[name] = ds.bounds\n\n    # Overlap stats\n    overlapping_pairs = _find_overlaps(all_bounds)\n    all_overlap_stats = {}\n\n    # Load overlap stats\n    if load_adjustments:\n        for name_i, model_entry in loaded_model.items():\n            if name_i not in input_image_path_pairs:\n                continue\n\n            for name_j, bands in model_entry.get(\"overlap_stats\", {}).items():\n                if name_j not in input_image_path_pairs:\n                    continue\n\n                all_overlap_stats.setdefault(name_i, {})[name_j] = {\n                    int(k.split(\"_\")[1]): {\n                        \"mean\": bands[k][\"mean\"],\n                        \"std\": bands[k][\"std\"],\n                        \"size\": bands[k][\"size\"]\n                    } for k in bands\n                }\n\n    # Calculate overlap stats\n    parallel_args = [\n        (\n            window_parallel,\n            window_max_workers,\n            window_backend,\n            num_bands,\n            input_image_path_pairs[name_i],\n            input_image_path_pairs[name_j],\n            name_i,\n            name_j,\n            all_bounds[name_i],\n            all_bounds[name_j],\n            nodata_val,\n            nodata_val,\n            vector_mask,\n            window_size,\n            debug_logs,\n        )\n        for name_i, name_j in overlapping_pairs\n        if name_i not in loaded_model or name_j not in loaded_model.get(name_i, {}).get(\"overlap_stats\", {})\n    ]\n\n    if image_parallel:\n        with _get_executor(image_backend, image_max_workers) as executor:\n            futures = [executor.submit(_overlap_stats_process_image, *args) for args in parallel_args]\n            for future in as_completed(futures):\n                stats = future.result()\n                for outer, inner in stats.items():\n                    all_overlap_stats.setdefault(outer, {}).update(inner)\n    else:\n        for args in parallel_args:\n            stats = _overlap_stats_process_image(*args)\n            for outer, inner in stats.items():\n                all_overlap_stats.setdefault(outer, {}).update(inner)\n\n    # Load whole stats\n    all_whole_stats = {\n        name: {\n            int(k.split(\"_\")[1]): {\n                \"mean\": loaded_model[name][\"whole_stats\"][k][\"mean\"],\n                \"std\": loaded_model[name][\"whole_stats\"][k][\"std\"],\n                \"size\": loaded_model[name][\"whole_stats\"][k][\"size\"]\n            }\n            for k in loaded_model[name][\"whole_stats\"]\n        }\n        for name in input_image_path_pairs\n        if name in loaded_model\n    }\n\n    # Calculate whole stats\n    parallel_args = [\n        (\n            window_parallel,\n            window_max_workers,\n            window_backend,\n            image_path,\n            nodata_val,\n            num_bands,\n            image_name,\n            vector_mask,\n            window_size,\n            debug_logs,\n        )\n        for image_name, image_path in input_image_path_pairs.items()\n        if image_name not in loaded_model\n    ]\n\n    # Compute whole stats\n    if image_parallel:\n        with _get_executor(image_backend, image_max_workers) as executor:\n            futures = [executor.submit(_whole_stats_process_image, *args) for args in parallel_args]\n            for future in as_completed(futures):\n                result = future.result()\n                all_whole_stats.update(result)\n    else:\n        for args in parallel_args:\n            result = _whole_stats_process_image(*args)\n            all_whole_stats.update(result)\n\n    # Get image names\n    all_image_names = list(dict.fromkeys(input_image_names + list(loaded_model.keys())))\n    num_total = len(all_image_names)\n\n    # Print model sources\n    if debug_logs:\n        print(f\"\\nCreating model for {len(all_image_names)} total images from {len(included_names)} included:\")\n        print(f\"    {'ID':&lt;4}\\t{'Source':&lt;6}\\t{'Inclusion':&lt;8}\\tName\")\n        for i, name in enumerate(all_image_names):\n            source = \"load\" if name in (matched | only_loaded) else \"calc\"\n            included = \"incl\" if name in included_names else \"excl\"\n            print(f\"    {i:&lt;4}\\t{source:&lt;6}\\t{included:&lt;8}\\t{name}\")\n\n    # Build model\n    all_params = solve_global_model(\n        num_bands,\n        num_total,\n        all_image_names,\n        included_names,\n        input_image_names,\n        all_overlap_stats,\n        all_whole_stats,\n        custom_mean_factor,\n        custom_std_factor,\n        overlapping_pairs,\n        debug_logs,\n    )\n\n    # Save adjustments\n    if save_adjustments:\n        _save_adjustments(\n            save_path=save_adjustments,\n            input_image_names=list(input_image_path_pairs.keys()),\n            all_params=all_params,\n            all_whole_stats=all_whole_stats,\n            all_overlap_stats=all_overlap_stats,\n            num_bands=num_bands,\n            calculation_dtype=calculation_dtype\n        )\n\n    # Apply corrections\n    if debug_logs: print(f\"Apply adjustments and saving results for:\")\n    parallel_args = [\n        (\n            name,\n            img_path,\n            output_image_path_pairs[name],\n            np.array([all_params[b, 2 * idx, 0] for b in range(num_bands)]),\n            np.array([all_params[b, 2 * idx + 1, 0] for b in range(num_bands)]),\n            num_bands,\n            nodata_val,\n            window_size,\n            calculation_dtype,\n            output_dtype,\n            window_parallel,\n            window_backend,\n            window_max_workers,\n            save_as_cog,\n            debug_logs,\n        )\n        for idx, (name, img_path) in enumerate(input_image_path_pairs.items())\n    ]\n\n    if image_parallel:\n        with _get_executor(image_backend, image_max_workers) as executor:\n            futures = [executor.submit(_apply_adjustments_process_image, *args) for args in parallel_args]\n            for future in as_completed(futures):\n                future.result()\n    else:\n        for args in parallel_args:\n            _apply_adjustments_process_image(*args)\n\n    return output_image_paths\n</code></pre>"},{"location":"api/match/#spectralmatch.match.global_regression.solve_global_model","title":"<code>solve_global_model(num_bands, num_total, all_image_names, included_names, input_image_names, all_overlap_stats, all_whole_stats, custom_mean_factor, custom_std_factor, overlapping_pairs, debug_logs=False)</code>","text":"<p>Computes global radiometric normalization parameters (scale and offset) for each image and band using least squares regression.</p> <p>Parameters:</p> Name Type Description Default <code>num_bands</code> <code>int</code> <p>Number of image bands.</p> required <code>num_total</code> <code>int</code> <p>Total number of images (including loaded).</p> required <code>all_image_names</code> <code>list[str]</code> <p>Ordered list of all image names.</p> required <code>included_names</code> <code>list[str]</code> <p>Subset of images used to constrain the model.</p> required <code>input_image_names</code> <code>list[str]</code> <p>Names of input images to apply normalization to.</p> required <code>all_overlap_stats</code> <code>dict</code> <p>Pairwise overlap statistics per band.</p> required <code>all_whole_stats</code> <code>dict</code> <p>Whole-image stats (mean, std) per band.</p> required <code>custom_mean_factor</code> <code>float</code> <p>Weight for mean constraints.</p> required <code>custom_std_factor</code> <code>float</code> <p>Weight for std constraints.</p> required <code>overlapping_pairs</code> <code>tuple[tuple[str, str], ...]</code> <p>Pairs of overlapping images.</p> required <code>debug_logs</code> <code>bool</code> <p>If True, prints debug information.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Adjustment parameters of shape (bands, 2 * num_images, 1).</p> Source code in <code>spectralmatch/match/global_regression.py</code> <pre><code>def solve_global_model(\n    num_bands: int,\n    num_total: int,\n    all_image_names: list[str],\n    included_names: list[str],\n    input_image_names: list[str],\n    all_overlap_stats: dict,\n    all_whole_stats: dict,\n    custom_mean_factor: float,\n    custom_std_factor: float,\n    overlapping_pairs: tuple[tuple[str, str], ...],\n    debug_logs: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    Computes global radiometric normalization parameters (scale and offset) for each image and band using least squares regression.\n\n    Args:\n        num_bands: Number of image bands.\n        num_total: Total number of images (including loaded).\n        all_image_names: Ordered list of all image names.\n        included_names: Subset of images used to constrain the model.\n        input_image_names: Names of input images to apply normalization to.\n        all_overlap_stats: Pairwise overlap statistics per band.\n        all_whole_stats: Whole-image stats (mean, std) per band.\n        custom_mean_factor: Weight for mean constraints.\n        custom_std_factor: Weight for std constraints.\n        overlapping_pairs: Pairs of overlapping images.\n        debug_logs: If True, prints debug information.\n\n    Returns:\n        np.ndarray: Adjustment parameters of shape (bands, 2 * num_images, 1).\n    \"\"\"\n    all_params = np.zeros((num_bands, 2 * num_total, 1), dtype=float)\n    image_names_with_id = [(i, name) for i, name in enumerate(all_image_names)]\n    for b in range(num_bands):\n        if debug_logs: print(f\"\\nProcessing band {b}:\")\n\n        A, y, tot_overlap = [], [], 0\n        for i, name_i in image_names_with_id:\n            for j, name_j in image_names_with_id[i + 1:]:\n                stat = all_overlap_stats.get(name_i, {}).get(name_j)\n                if stat is None:\n                    continue\n\n                # This condition ensures that only overlaps involving at least one included image contribute constraints, allowing external images to be calibrated against the model without influencing it.\n                if name_i not in included_names and name_j not in included_names:\n                    continue\n\n                s = stat[b][\"size\"]\n                m1, v1 = stat[b][\"mean\"], stat[b][\"std\"]\n                m2, v2 = (\n                    all_overlap_stats[name_j][name_i][b][\"mean\"],\n                    all_overlap_stats[name_j][name_i][b][\"std\"],\n                )\n\n                row_m = [0] * (2 * num_total)\n                row_s = [0] * (2 * num_total)\n                row_m[2 * i: 2 * i + 2] = [m1, 1]\n                row_m[2 * j: 2 * j + 2] = [-m2, -1]\n                row_s[2 * i], row_s[2 * j] = v1, -v2\n\n                A.extend([\n                    [v * s * custom_mean_factor for v in row_m],\n                    [v * s * custom_std_factor for v in row_s],\n                ])\n                y.extend([0, 0])\n                tot_overlap += s\n\n        pjj = 1.0 if tot_overlap == 0 else tot_overlap / (2.0 * num_total)\n\n        for name in included_names:\n            mj = all_whole_stats[name][b][\"mean\"]\n            vj = all_whole_stats[name][b][\"std\"]\n            j_idx = all_image_names.index(name)\n            row_m = [0] * (2 * num_total)\n            row_s = [0] * (2 * num_total)\n            row_m[2 * j_idx: 2 * j_idx + 2] = [mj * pjj, 1 * pjj]\n            row_s[2 * j_idx] = vj * pjj\n            A.extend([row_m, row_s])\n            y.extend([mj * pjj, vj * pjj])\n\n        for name in input_image_names:\n            if name in included_names:\n                continue\n            row = [0] * (2 * num_total)\n            A.append(row.copy())\n            y.append(0)\n            A.append(row.copy())\n            y.append(0)\n\n        A_arr = np.asarray(A)\n        y_arr = np.asarray(y)\n        res = least_squares(lambda p: A_arr @ p - y_arr, [1, 0] * num_total)\n        all_params[b, :, 0] = res.x\n\n\n        if debug_logs:\n            _print_constraint_system(\n                constraint_matrix=A_arr,\n                adjustment_params=res.x,\n                observed_values_vector=y_arr,\n                overlap_pairs=overlapping_pairs,\n                image_names_with_id=image_names_with_id,\n\n            )\n    return all_params\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.get_bounding_rect_images_block_space","title":"<code>get_bounding_rect_images_block_space(block_local_means)</code>","text":"<p>Compute block-space bounding rectangles for each image based on valid block values.</p> <p>Parameters:</p> Name Type Description Default <code>block_local_means</code> <code>dict[str, ndarray]</code> <p>Per-image block means with shape (num_row, num_col, num_bands).</p> required <p>Returns:</p> Type Description <code>dict[str, tuple[int, int, int, int]]</code> <p>dict[str, tuple[int, int, int, int]]: Each entry maps image name to (min_row, min_col, max_row, max_col).</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def get_bounding_rect_images_block_space(\n    block_local_means: dict[str, np.ndarray]\n) -&gt; dict[str, tuple[int, int, int, int]]:\n    \"\"\"\n    Compute block-space bounding rectangles for each image based on valid block values.\n\n    Args:\n        block_local_means (dict[str, np.ndarray]): Per-image block means\n            with shape (num_row, num_col, num_bands).\n\n    Returns:\n        dict[str, tuple[int, int, int, int]]: Each entry maps image name to\n            (min_row, min_col, max_row, max_col).\n    \"\"\"\n    output = {}\n\n    for name, arr in block_local_means.items():\n        valid_mask = np.any(~np.isnan(arr), axis=2)\n        rows, cols = np.where(valid_mask)\n\n        if rows.size &gt; 0 and cols.size &gt; 0:\n            min_row, max_row = rows.min(), rows.max() + 1\n            min_col, max_col = cols.min(), cols.max() + 1\n        else:\n            min_row = max_row = min_col = max_col = 0\n\n        output[name] = (min_row, min_col, max_row, max_col)\n\n    return output\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.local_block_adjustment","title":"<code>local_block_adjustment(input_images, output_images, *, calculation_dtype='float32', output_dtype=None, vector_mask=None, debug_logs=False, custom_nodata_value=None, image_parallel_workers=None, window_parallel_workers=None, window_size=None, save_as_cog=False, number_of_blocks=100, alpha=1.0, correction_method='gamma', save_block_maps=None, load_block_maps=None, override_bounds_canvas_coords=None, block_valid_pixel_threshold=0.001)</code>","text":"<p>Performs local radiometric adjustment on a set of raster images using block-based statistics.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies the input images either as: - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). - A list of full file paths to individual input images.</p> required <code>output_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies how output filenames are generated or provided: - A tuple with an output folder and a filename template using \"\\(\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"\\)_LocalMatch.tif\")). - A list of full output paths, which must match the number of input images.</p> required <code>calculation_dtype</code> <code>str</code> <p>Precision for internal calculations. Defaults to \"float32\".</p> <code>'float32'</code> <code>output_dtype</code> <code>str | None</code> <p>Data type for output rasters. Defaults to input image dtype.</p> <code>None</code> <code>vector_mask</code> <code>Tuple[Literal['include', 'exclude'], str, Optional[str]] | None</code> <p>A mask limiting pixels to include when calculating stats for each block in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that includes (can be substring) input image name to filter geometry by. It is only applied when calculating local blocks, as the reference map is calculated as the mean of all local blocks. Loaded block maps won't have this applied unless it was used when calculating them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>If True, prints progress. Defaults to False.</p> <code>False</code> <code>custom_nodata_value</code> <code>float | int | None</code> <p>Overrides detected NoData value. Defaults to None.</p> <code>None</code> <code>image_parallel_workers</code> <code>Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None</code> <p>Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.</p> <code>None</code> <code>window_parallel_workers</code> <code>Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None</code> <p>Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.</p> <code>None</code> <code>window_size</code> <code>int | Tuple[int, int] | Literal['block'] | None</code> <p>Tile size for processing: int for square tiles, (width, height) for custom size, or \"block\" to set as the size of the block map, None for full image. Defaults to None.</p> <code>None</code> <code>save_as_cog</code> <code>bool</code> <p>If True, saves as COG. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int | tuple | Literal['coefficient_of_variation']</code> <p>int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.</p> <code>100</code> <code>alpha</code> <code>float</code> <p>Blending factor between reference and local means. Defaults to 1.0.</p> <code>1.0</code> <code>correction_method</code> <code>Literal['gamma', 'linear']</code> <p>Local correction method. Defaults to \"gamma\".</p> <code>'gamma'</code> <code>save_block_maps</code> <code>tuple(str, str) | None</code> <p>If enabled, saves block maps for review, to resume processing later, or to add additional images to the reference map. - First str is the path to save the global block map. - Second str is the path to save the local block maps, which must include \"$\" which will be replaced my the image name (because there are multiple local maps).</p> <code>None</code> <code>load_block_maps</code> <code>Tuple[str, List[str]] | Tuple[str, None] | Tuple[None, List[str]] | None</code> <p>Controls loading of precomputed block maps. Can be one of:     - Tuple[str, List[str]]: Load both reference and local block maps.     - Tuple[str, None]: Load only the reference block map.     - Tuple[None, List[str]]: Load only the local block maps.     - None: Do not load any block maps. This supports partial or full reuse of precomputed block maps:     - Local block maps will still be computed for each input image that is not linked to a local block map by the images name being included in the local block maps name (file name).     - The reference block map will only be calculated (mean of all local blocks) if not set.     - The reference map defines the reference block statistics and the local maps define per-image local block statistics.     - Both reference and local maps must have the same canvas extent and dimensions which will be used to set those values.</p> <code>None</code> <code>override_bounds_canvas_coords</code> <code>Tuple[float, float, float, float] | None</code> <p>Manually set (min_x, min_y, max_x, max_y) bounds to override the computed/loaded canvas extent. If you wish to have a larger extent than the current images, you can manually set this, along with setting a fixed number of blocks, to anticipate images will expand beyond the current extent.</p> <code>None</code> <code>block_valid_pixel_threshold</code> <code>float</code> <p>Minimum fraction of valid pixels required to include a block (0\u20131).</p> <code>0.001</code> <p>Returns:</p> Type Description <code>list</code> <p>List[str]: Paths to the locally adjusted output raster images.</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def local_block_adjustment(\n    input_images: Universal.SearchFolderOrListFiles,\n    output_images: Universal.CreateInFolderOrListFiles,\n    *,\n    calculation_dtype: Universal.CalculationDtype = \"float32\",\n    output_dtype: Universal.CustomOutputDtype = None,\n    vector_mask: Universal.VectorMask = None,\n    debug_logs: Universal.DebugLogs = False,\n    custom_nodata_value: Universal.CustomNodataValue = None,\n    image_parallel_workers: Universal.ImageParallelWorkers = None,\n    window_parallel_workers: Universal.WindowParallelWorkers = None,\n    window_size: Universal.WindowSizeWithBlock = None,\n    save_as_cog: Universal.SaveAsCog = False,\n    number_of_blocks: int | Tuple[int, int] | Literal[\"coefficient_of_variation\"] = 100,\n    alpha: float = 1.0,\n    correction_method: Literal[\"gamma\", \"linear\"] = \"gamma\",\n    save_block_maps: Tuple[str, str] | None = None,\n    load_block_maps: Tuple[str, List[str]] | Tuple[str, None]| Tuple[None, List[str]] | None = None,\n    override_bounds_canvas_coords: Tuple[float, float, float, float] | None = None,\n    block_valid_pixel_threshold: float = 0.001,\n    )-&gt; list:\n    \"\"\"\n    Performs local radiometric adjustment on a set of raster images using block-based statistics.\n\n    Args:\n        input_images (Tuple[str, str] | List[str]):\n            Specifies the input images either as:\n            - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n            - A list of full file paths to individual input images.\n        output_images (Tuple[str, str] | List[str]):\n            Specifies how output filenames are generated or provided:\n            - A tuple with an output folder and a filename template using \"$\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"$_LocalMatch.tif\")).\n            - A list of full output paths, which must match the number of input images.\n        calculation_dtype (str, optional): Precision for internal calculations. Defaults to \"float32\".\n        output_dtype (str | None, optional): Data type for output rasters. Defaults to input image dtype.\n        vector_mask (Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None): A mask limiting pixels to include when calculating stats for each block in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that *includes* (can be substring) input image name to filter geometry by. It is only applied when calculating local blocks, as the reference map is calculated as the mean of all local blocks. Loaded block maps won't have this applied unless it was used when calculating them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.\n        debug_logs (bool, optional): If True, prints progress. Defaults to False.\n        custom_nodata_value (float | int | None, optional): Overrides detected NoData value. Defaults to None.\n        image_parallel_workers (Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.\n        window_parallel_workers (Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.\n        window_size (int | Tuple[int, int] | Literal[\"block\"] | None): Tile size for processing: int for square tiles, (width, height) for custom size, or \"block\" to set as the size of the block map, None for full image. Defaults to None.\n        save_as_cog (bool, optional): If True, saves as COG. Defaults to False.\n        number_of_blocks (int | tuple | Literal[\"coefficient_of_variation\"]): int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.\n        alpha (float, optional): Blending factor between reference and local means. Defaults to 1.0.\n        correction_method (Literal[\"gamma\", \"linear\"], optional): Local correction method. Defaults to \"gamma\".\n        save_block_maps (tuple(str, str) | None): If enabled, saves block maps for review, to resume processing later, or to add additional images to the reference map.\n            - First str is the path to save the global block map.\n            - Second str is the path to save the local block maps, which must include \"$\" which will be replaced my the image name (because there are multiple local maps).\n        load_block_maps (Tuple[str, List[str]] | Tuple[str, None] | Tuple[None, List[str]] | None, optional):\n            Controls loading of precomputed block maps. Can be one of:\n                - Tuple[str, List[str]]: Load both reference and local block maps.\n                - Tuple[str, None]: Load only the reference block map.\n                - Tuple[None, List[str]]: Load only the local block maps.\n                - None: Do not load any block maps.\n            This supports partial or full reuse of precomputed block maps:\n                - Local block maps will still be computed for each input image that is not linked to a local block map by the images name being *included* in the local block maps name (file name).\n                - The reference block map will only be calculated (mean of all local blocks) if not set.\n                - The reference map defines the reference block statistics and the local maps define per-image local block statistics.\n                - Both reference and local maps must have the same canvas extent and dimensions which will be used to set those values.\n        override_bounds_canvas_coords (Tuple[float, float, float, float] | None): Manually set (min_x, min_y, max_x, max_y) bounds to override the computed/loaded canvas extent. If you wish to have a larger extent than the current images, you can manually set this, along with setting a fixed number of blocks, to anticipate images will expand beyond the current extent.\n        block_valid_pixel_threshold (float): Minimum fraction of valid pixels required to include a block (0\u20131).\n\n    Returns:\n        List[str]: Paths to the locally adjusted output raster images.\n    \"\"\"\n\n    print(\"Start local block adjustment\")\n\n    # Validate params\n    Universal.validate(\n        input_images=input_images,\n        output_images=output_images,\n        save_as_cog=save_as_cog,\n        debug_logs=debug_logs,\n        vector_mask=vector_mask,\n        window_size=window_size,\n        custom_nodata_value=custom_nodata_value,\n        image_parallel_workers=image_parallel_workers,\n        window_parallel_workers=window_parallel_workers,\n        calculation_dtype=calculation_dtype,\n        output_dtype=output_dtype,\n    )\n\n    Match.validate_local_block_adjustment(\n        number_of_blocks=number_of_blocks,\n        alpha=alpha,\n        correction_method=correction_method,\n        save_block_maps=save_block_maps,\n        load_block_maps=load_block_maps,\n        override_bounds_canvas_coords=override_bounds_canvas_coords,\n        block_valid_pixel_threshold=block_valid_pixel_threshold,\n    )\n\n    # Determine multiprocessing and worker count\n    image_parallel, image_backend, image_max_workers = _resolve_parallel_config(image_parallel_workers)\n    window_parallel, window_backend, window_max_workers = _resolve_parallel_config(window_parallel_workers)\n\n    input_image_paths = _resolve_paths(\"search\", input_images)\n    output_image_paths = _resolve_paths(\"create\", output_images, (input_image_paths,))\n\n    if debug_logs: print(f\"Input images: {input_image_paths}\")\n    if debug_logs: print(f\"Output images: {output_image_paths}\")\n\n    input_image_names = [os.path.splitext(os.path.basename(p))[0] for p in input_image_paths]\n    input_image_path_pairs = dict(zip(input_image_names, input_image_paths))\n    output_image_path_pairs = dict(zip(input_image_names, output_image_paths))\n\n    _check_raster_requirements(input_image_paths, debug_logs, check_geotransform=True, check_crs=True, check_bands=True, check_nodata=True)\n\n    if isinstance(window_size, int): window_size = (window_size, window_size)\n    nodata_val = _get_nodata_value(input_image_paths, custom_nodata_value)\n    projection = rasterio.open(input_image_paths[0]).crs\n    if debug_logs: print(f\"Global nodata value: {nodata_val}\")\n    with rasterio.open(input_image_paths[0]) as ds:num_bands = ds.count\n\n    # Load data from precomputed block maps if set\n    if load_block_maps:\n        loaded_block_local_means, loaded_block_reference_mean, loaded_num_row, loaded_num_col, loaded_bounds_canvas_coords = _get_pre_computed_block_maps(load_block_maps, calculation_dtype, debug_logs)\n        loaded_names = list(loaded_block_local_means.keys())\n        block_reference_mean = loaded_block_reference_mean\n\n        matched = list((soft_matches := {\n            input_name: loaded_name\n            for input_name in input_image_names\n            for loaded_name in loaded_names\n            if input_name in loaded_name\n        }).keys())\n        only_loaded = [l for l in loaded_names if not any(n in l for n in input_image_names)]\n        only_input = [n for n in input_image_names if not any(n in l for l in loaded_names)]\n\n    else:\n        only_input = input_image_names\n        matched = []\n        only_loaded = []\n        block_reference_mean = None\n\n    if debug_logs:\n        print(f\"Total images: input images: {len(input_image_names)}, loaded local block maps: {len(loaded_names) if load_block_maps else 0}:\")\n        print(f\"    Matched local block maps (to override) ({len(matched)}):\", sorted(matched))\n        print(f\"    Only in loaded local block maps (to use) ({len(only_loaded)}):\", sorted(only_loaded))\n        print(f\"    Only in input (to compute) ({len(only_input)}):\", sorted(only_input))\n\n    # Unpack path to save block maps\n    if save_block_maps:\n        reference_map_path, local_map_path = save_block_maps\n\n    # Create image bounds dict\n    bounds_images_coords = {\n        name: rasterio.open(path).bounds\n        for name, path in input_image_path_pairs.items()\n    }\n\n    # Get bounds canvas coords\n    if not override_bounds_canvas_coords:\n        if not load_block_maps:\n            bounds_canvas_coords = _get_bounding_rectangle(input_image_paths)\n        else:\n            bounds_canvas_coords = loaded_bounds_canvas_coords\n    else:\n        bounds_canvas_coords = override_bounds_canvas_coords\n        if load_block_maps:\n            if bounds_canvas_coords != loaded_bounds_canvas_coords:\n                raise ValueError(\"Override bounds canvas coordinates do not match loaded block maps bounds\")\n\n    # Calculate the number of blocks\n    if not load_block_maps:\n        if isinstance(number_of_blocks, int):\n            num_row, num_col = _compute_block_size(input_image_paths, number_of_blocks, bounds_canvas_coords)\n        elif isinstance(number_of_blocks, tuple):\n            num_row, num_col = number_of_blocks\n        elif isinstance(number_of_blocks, str):\n            num_row, num_col = _compute_mosaic_coefficient_of_variation(input_image_paths, nodata_val) # This is the approach from the paper to compute bock size\n    else:\n        num_row, num_col = loaded_num_row, loaded_num_col\n\n    if debug_logs: print(\"Computing local block maps:\")\n\n    # Compute local blocks\n    local_blocks_to_calculate = {k: v for k, v in input_image_path_pairs.items() if k in only_input}\n    local_blocks_to_load = {\n        **{k: loaded_block_local_means[soft_matches[k]] for k in matched},\n        **{k: loaded_block_local_means[k] for k in only_loaded},\n    }\n\n    if local_blocks_to_calculate:\n        args = [\n            (\n                name,\n                path,\n                bounds_canvas_coords,\n                num_row,\n                num_col,\n                num_bands,\n                window_size,\n                debug_logs,\n                nodata_val,\n                calculation_dtype,\n                vector_mask,\n                block_valid_pixel_threshold,\n                window_parallel,\n                window_backend,\n                window_max_workers,\n            )\n            for name, path in local_blocks_to_calculate.items()\n        ]\n\n        if image_parallel:\n            with _get_executor(image_backend, image_max_workers) as executor:\n                futures = [executor.submit(_calculate_block_process_image, *arg) for arg in args]\n                results = [f.result() for f in futures]\n        else:\n            results = [_calculate_block_process_image(*arg) for arg in args]\n\n        block_local_means = {name: mean for name, mean, _ in results}\n\n        overlap = set(block_local_means) &amp; set(local_blocks_to_load)\n        if overlap: raise ValueError(f\"Duplicate keys when merging loaded and computed blocks: {overlap}\")\n\n        block_local_means = {**block_local_means, **local_blocks_to_load}\n    else:\n        block_local_means = local_blocks_to_load\n\n    bounds_images_block_space = get_bounding_rect_images_block_space(block_local_means)\n\n    # Compute reference block\n    if debug_logs: print(\"Computing reference block map\")\n    if block_reference_mean is None:\n        block_reference_mean = _compute_reference_blocks(\n            block_local_means,\n            calculation_dtype,\n            )\n\n    if save_block_maps:\n        _download_block_map(\n            np.nan_to_num(block_reference_mean, nan=nodata_val),\n            bounds_canvas_coords,\n            reference_map_path,\n            projection,\n            calculation_dtype,\n            nodata_val,\n            num_col,\n            num_row,\n        )\n        for name, block_local_mean in block_local_means.items():\n            _download_block_map(\n                np.nan_to_num(block_local_mean, nan=nodata_val),\n                bounds_canvas_coords,\n                local_map_path.replace(\"$\", name),\n                projection,\n                calculation_dtype,\n                nodata_val,\n                num_col,\n                num_row,\n            )\n            # _download_block_map(\n            #     np.nan_to_num(block_local_count, nan=nodata_val),\n            #     bounds_canvas_coords,\n            #     os.path.join(output_image_folder, \"BlockLocalCount\", f\"{input_image_name}_BlockLocalCount.tif\"),\n            #     projection,\n            #     calculation_dtype,\n            #     nodata_val,\n            #     num_col,\n            #     num_row,\n            # )\n\n    # block_local_mean = _smooth_array(block_local_mean, nodata_value=global_nodata_value)\n\n    # Apply adjustments to images\n    if debug_logs: print(f\"Computing local correction, applying, and saving:\")\n    args = [\n        (\n            name,\n            input_image_path_pairs[name],\n            output_image_path_pairs[name],\n            num_bands,\n            block_reference_mean,\n            block_local_means[name],\n            bounds_images_block_space[name],\n            bounds_canvas_coords,\n            window_size,\n            num_row,\n            num_col,\n            nodata_val,\n            alpha,\n            correction_method,\n            calculation_dtype,\n            output_dtype,\n            debug_logs,\n            window_parallel,\n            window_backend,\n            window_max_workers,\n            save_as_cog,\n        )\n        for name in input_image_path_pairs\n    ]\n\n    if image_parallel:\n        with _get_executor(image_backend, image_max_workers) as executor:\n            futures = [executor.submit(_apply_adjustment_process_image, *arg) for arg in args]\n            for future in as_completed(futures):\n                future.result()\n    else:\n        for arg in args:\n            _apply_adjustment_process_image(*arg)\n\n    return output_image_paths\n</code></pre>"},{"location":"api/statistics/","title":"Creating Statistical Figures","text":""},{"location":"api/statistics/#spectralmatch.statistics.compare_image_spectral_profiles","title":"<code>compare_image_spectral_profiles(input_image_dict, output_figure_path, title, xlabel, ylabel)</code>","text":"<p>Compares spectral profiles of multiple images by plotting median and interquartile ranges.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_dict</code> <code>dict</code> <p>Mapping of labels to image file paths: { 'Image A': '/image/a.tif', 'Image B': '/image/b.tif' }</p> required <code>output_figure_path</code> <code>str</code> <p>Path to save the output plot.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>xlabel</code> <code>str</code> <p>Label for the x-axis.</p> required <code>ylabel</code> <code>str</code> <p>Label for the y-axis.</p> required Outputs <p>Saves a spectral profile comparison figure to the specified path.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_image_spectral_profiles(\n    input_image_dict,\n    output_figure_path,\n    title,\n    xlabel,\n    ylabel,\n):\n    \"\"\"\n    Compares spectral profiles of multiple images by plotting median and interquartile ranges.\n\n    Args:\n        input_image_dict (dict): Mapping of labels to image file paths:\n            {\n            'Image A': '/image/a.tif',\n            'Image B': '/image/b.tif'\n            }\n        output_figure_path (str): Path to save the output plot.\n        title (str): Title of the plot.\n        xlabel (str): Label for the x-axis.\n        ylabel (str): Label for the y-axis.\n\n    Outputs:\n        Saves a spectral profile comparison figure to the specified path.\n    \"\"\"\n    os.makedirs(os.path.dirname(output_figure_path), exist_ok=True)\n    plt.figure(figsize=(10, 6))\n    colors = itertools.cycle(plt.cm.tab10.colors)\n    spectral_profiles = []\n    labels = []\n\n    for label, image_path in input_image_dict.items():\n        try:\n            with rasterio.open(image_path) as src:\n                image_data = src.read()  # shape: (bands, height, width)\n        except Exception as e:\n            print(f\"Failed to open {image_path}: {e}\")\n            continue\n\n        bands, height, width = image_data.shape\n        reshaped = image_data.reshape(bands, -1)\n        median = np.median(reshaped, axis=1)\n        q25, q75 = np.percentile(reshaped, [25, 75], axis=1)\n        spectral_profiles.append((median, q25, q75))\n        labels.append(label)\n\n    for i, (median, q25, q75) in enumerate(spectral_profiles):\n        color = next(colors)\n        x = range(1, len(median) + 1)\n        plt.plot(x, median, color=color, label=labels[i])\n        plt.fill_between(x, q25, q75, color=color, alpha=0.3)\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(output_figure_path, dpi=300)\n    plt.close()\n    print(f\"Saved: {output_figure_path}\")\n</code></pre>"},{"location":"api/statistics/#spectralmatch.statistics.compare_image_spectral_profiles_pairs","title":"<code>compare_image_spectral_profiles_pairs(image_groups_dict, output_figure_path, title, xlabel, ylabel)</code>","text":"<p>Plots paired spectral profiles for before-and-after image comparisons.</p> <p>Parameters:</p> Name Type Description Default <code>image_groups_dict</code> <code>dict</code> <p>Mapping of labels to image path pairs (before, after): {'Image A': [     '/image/before/a.tif',     'image/after/a.tif' ], 'Image B': [     '/image/before/b.tif',     '/image/after/b.tif' ]}</p> required <code>output_figure_path</code> <code>str</code> <p>Path to save the resulting comparison figure.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>xlabel</code> <code>str</code> <p>X-axis label.</p> required <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> required Outputs <p>Saves a spectral comparison plot showing pre- and post-processing profiles.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_image_spectral_profiles_pairs(\n    image_groups_dict: dict,\n    output_figure_path: str,\n    title: str,\n    xlabel: str,\n    ylabel: str,\n    ):\n    \"\"\"\n    Plots paired spectral profiles for before-and-after image comparisons.\n\n    Args:\n        image_groups_dict (dict): Mapping of labels to image path pairs (before, after):\n            {'Image A': [\n                '/image/before/a.tif',\n                'image/after/a.tif'\n            ],\n            'Image B': [\n                '/image/before/b.tif',\n                '/image/after/b.tif'\n            ]}\n        output_figure_path (str): Path to save the resulting comparison figure.\n        title (str): Title of the plot.\n        xlabel (str): X-axis label.\n        ylabel (str): Y-axis label.\n\n    Outputs:\n        Saves a spectral comparison plot showing pre- and post-processing profiles.\n    \"\"\"\n\n    os.makedirs(os.path.dirname(output_figure_path), exist_ok=True)\n    plt.figure(figsize=(10, 6))\n    colors = itertools.cycle(plt.cm.tab10.colors)\n\n    for label, group in image_groups_dict.items():\n        if len(group) == 2:\n            image_path1, image_path2 = group\n            color = next(colors)\n\n            for i, image_path in enumerate([image_path1, image_path2]):\n                with rasterio.open(image_path) as src:\n                    img = src.read()\n                    num_bands = img.shape[0]\n                    img_reshaped = img.reshape(num_bands, -1)\n                    nodata = src.nodata\n                    if nodata is not None:\n                        img_reshaped = np.where(img_reshaped == nodata, np.nan, img_reshaped)\n                    mean_spectral = np.nanmean(img_reshaped, axis=1)\n                    bands = np.arange(1, num_bands + 1)\n                    linestyle = 'dashed' if i == 0 else 'solid'\n                    plt.plot(bands, mean_spectral, linestyle=linestyle, color=color,\n                             label=f\"{label} - {'Before' if i == 0 else 'After'}\")\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(output_figure_path, dpi=300)\n    plt.close()\n    print(f\"Saved: {output_figure_path}\")\n</code></pre>"},{"location":"api/statistics/#spectralmatch.statistics.compare_spatial_spectral_difference_band_average","title":"<code>compare_spatial_spectral_difference_band_average(input_images, output_image_path, title, diff_label, subtitle)</code>","text":"<p>Computes and visualizes the average per-band spectral difference between two coregistered, equal size images.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>list</code> <p>List of two image file paths to compare.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the resulting difference image (PNG).</p> required <code>title</code> <code>str</code> <p>Title for the plot.</p> required <code>diff_label</code> <code>str</code> <p>Label for the colorbar indicating the difference metric.</p> required <code>subtitle</code> <code>str</code> <p>Optional subtitle to display below the plot.</p> required Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_spatial_spectral_difference_band_average(\n    input_images: list,\n    output_image_path: str,\n    title: str,\n    diff_label: str,\n    subtitle: str,\n):\n    \"\"\"\n    Computes and visualizes the average per-band spectral difference between two coregistered, equal size images.\n\n    Args:\n        input_images (list): List of two image file paths to compare.\n        output_image_path (str): Path to save the resulting difference image (PNG).\n        title (str): Title for the plot.\n        diff_label (str): Label for the colorbar indicating the difference metric.\n        subtitle (str): Optional subtitle to display below the plot.\n    \"\"\"\n\n    if len(input_images) != 2:\n        raise ValueError(\"input_images must be a list of exactly two image paths.\")\n\n    path1, path2 = input_images\n    name1 = os.path.splitext(os.path.basename(path1))[0]\n    name2 = os.path.splitext(os.path.basename(path2))[0]\n\n    with rasterio.open(path1) as src1, rasterio.open(path2) as src2:\n        img1 = src1.read()\n        img2 = src2.read()\n        nodata = src1.nodata\n\n        if img1.shape != img2.shape:\n            raise ValueError(\"Images must have the same dimensions.\")\n\n        diff = np.abs(img2 - img1).astype(\"float32\")\n\n        if nodata is not None:\n            mask = img1[0] != nodata\n            for b in range(1, img1.shape[0]):\n                mask &amp;= img1[b] != nodata\n                mask &amp;= img2[b] != nodata\n            diff[:, ~mask] = np.nan\n\n        with np.errstate(invalid=\"ignore\"):\n            mean_diff = np.full(diff.shape[1:], np.nan)\n            valid_mask = ~np.all(np.isnan(diff), axis=0)\n            mean_diff[valid_mask] = np.nanmean(diff[:, valid_mask], axis=0)\n\n        fig, ax = plt.subplots(figsize=(10, 6), constrained_layout=True)\n        im = ax.imshow(mean_diff, cmap='coolwarm', interpolation='nearest')\n\n        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n        cbar.set_label(diff_label)\n\n        ax.set_title(title, fontsize=14, pad=12)\n        if subtitle:\n            ax.text(0.5, -0.1, subtitle, fontsize=10, ha='center', transform=ax.transAxes)\n\n        ax.axis(\"off\")\n        plt.savefig(output_image_path, dpi=300, bbox_inches='tight')\n        plt.close()\n\n        print(f\"Saved: {output_image_path}\")\n</code></pre>"},{"location":"examples/benchmark/","title":"Benchmark Multithreading","text":"In\u00a0[\u00a0]: Copied! <pre>import os, shutil, tempfile, time\nfrom pathlib import Path\n</pre> import os, shutil, tempfile, time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_origin\n</pre> import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.transform import from_origin In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import global_regression, local_block_adjustment\n</pre> from spectralmatch import global_regression, local_block_adjustment In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def make_fake_rasters(out_dir, n_images, width, height, nodata=0):\n    out_dir = Path(out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n    profile = dict(\n        driver=\"GTiff\",\n        width=width,\n        height=height,\n        count=8,\n        dtype=\"uint16\",\n        nodata=nodata,\n        crs=\"EPSG:3857\",\n        transform=from_origin(0, 0, 1, 1),\n        tiled=True,\n        blockxsize=512,\n        blockysize=512,\n        compress=\"LZW\",\n    )\n    rng = np.random.default_rng(seed=42)\n    paths = []\n    for i in range(n_images):\n        p = out_dir / f\"fake_{i+1}_{width}px.tif\"\n        with rasterio.open(p, \"w\", **profile) as dst:\n            for b in range(1, 9):\n                data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")\n                data[0, 0] = nodata\n                dst.write(data, indexes=b)\n        paths.append(str(p))\n    return paths\n</pre> def make_fake_rasters(out_dir, n_images, width, height, nodata=0):     out_dir = Path(out_dir)     out_dir.mkdir(parents=True, exist_ok=True)     profile = dict(         driver=\"GTiff\",         width=width,         height=height,         count=8,         dtype=\"uint16\",         nodata=nodata,         crs=\"EPSG:3857\",         transform=from_origin(0, 0, 1, 1),         tiled=True,         blockxsize=512,         blockysize=512,         compress=\"LZW\",     )     rng = np.random.default_rng(seed=42)     paths = []     for i in range(n_images):         p = out_dir / f\"fake_{i+1}_{width}px.tif\"         with rasterio.open(p, \"w\", **profile) as dst:             for b in range(1, 9):                 data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")                 data[0, 0] = nodata                 dst.write(data, indexes=b)         paths.append(str(p))     return paths In\u00a0[\u00a0]: Copied! <pre>SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288]\nNUM_IMAGES = 2\nTILE_SIZE = (1024, 1024)\nMAX_WORKERS = 32\n</pre> SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288] NUM_IMAGES = 2 TILE_SIZE = (1024, 1024) MAX_WORKERS = 32 In\u00a0[\u00a0]: Copied! <pre>WORK_DIR = Path(__file__).parent / \"bench_output\"\nWORK_DIR.mkdir(exist_ok=True)\n</pre> WORK_DIR = Path(__file__).parent / \"bench_output\" WORK_DIR.mkdir(exist_ok=True) In\u00a0[\u00a0]: Copied! <pre>SERIAL, PARALLEL = [], []\n</pre> SERIAL, PARALLEL = [], [] In\u00a0[\u00a0]: Copied! <pre>for sz in SIZES:\n    print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")\n    tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))\n    imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)\n\n    t0 = time.time()\n    g_dir = tmp / \"serial_g\"\n    l_dir = tmp / \"serial_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        window_size=TILE_SIZE,\n        parallel=False,\n        debug_logs=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        window_size=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=False,\n        debug_logs=False,\n    )\n    SERIAL.append(time.time() - t0)\n    print(f\"serial   : {SERIAL[-1]:.1f} s\")\n\n    t0 = time.time()\n    g_dir = tmp / \"parallel_g\"\n    l_dir = tmp / \"parallel_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        window_size=TILE_SIZE,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_logs=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        window_size=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_logs=False,\n    )\n    PARALLEL.append(time.time() - t0)\n    print(f\"parallel : {PARALLEL[-1]:.1f} s\")\n\n    shutil.rmtree(tmp, ignore_errors=True)\n</pre> for sz in SIZES:     print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")     tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))     imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)      t0 = time.time()     g_dir = tmp / \"serial_g\"     l_dir = tmp / \"serial_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         window_size=TILE_SIZE,         parallel=False,         debug_logs=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         window_size=TILE_SIZE,         custom_nodata_value=-9999,         parallel=False,         debug_logs=False,     )     SERIAL.append(time.time() - t0)     print(f\"serial   : {SERIAL[-1]:.1f} s\")      t0 = time.time()     g_dir = tmp / \"parallel_g\"     l_dir = tmp / \"parallel_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         window_size=TILE_SIZE,         parallel=True,         max_workers=MAX_WORKERS,         debug_logs=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         window_size=TILE_SIZE,         custom_nodata_value=-9999,         parallel=True,         max_workers=MAX_WORKERS,         debug_logs=False,     )     PARALLEL.append(time.time() - t0)     print(f\"parallel : {PARALLEL[-1]:.1f} s\")      shutil.rmtree(tmp, ignore_errors=True) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 5))\nplt.plot(SIZES, SERIAL, \"-o\", label=\"serial\")\nplt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\")\nplt.xlabel(\"Raster width = height (pixels)\")\nplt.ylabel(\"Total runtime: global + local (seconds)\")\nplt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(8, 5)) plt.plot(SIZES, SERIAL, \"-o\", label=\"serial\") plt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\") plt.xlabel(\"Raster width = height (pixels)\") plt.ylabel(\"Total runtime: global + local (seconds)\") plt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\") plt.grid(True) plt.legend() plt.tight_layout() plt.show()"},{"location":"examples/example_landsat_time_series/","title":"Landsat Time Series","text":"In\u00a0[\u00a0]: Copied! <pre># This notebook demonstrates how to preprocess Landsat 8-9 into a time series with spectralmatch.\n# Starting from 5 Landsat 8-9 OLI/TIRS C2 L1 images, the process includes clipping clouds with OmniCloudMask, masking high NDVI areas as Pseudo Invariant Features (PIFs), applying global regression Relative Radiometric Normalization, fine-tuning overlap areas with local block adjustment, and before vs after statistics.\n# This script is set up to perform matching on all tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif.\n</pre> # This notebook demonstrates how to preprocess Landsat 8-9 into a time series with spectralmatch. # Starting from 5 Landsat 8-9 OLI/TIRS C2 L1 images, the process includes clipping clouds with OmniCloudMask, masking high NDVI areas as Pseudo Invariant Features (PIFs), applying global regression Relative Radiometric Normalization, fine-tuning overlap areas with local block adjustment, and before vs after statistics. # This script is set up to perform matching on all tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. In\u00a0[\u00a0]: Copied! <pre>import os\nfrom spectralmatch import *\n\n# Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder\nworking_directory = os.path.join(os.getcwd(), \"data_landsat\")\nprint(working_directory)\n\ninput_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\nmask_cloud_folder = os.path.join(working_directory, \"MaskCloud\")\nmask_vegetation_folder = os.path.join(working_directory, \"MaskVegetation\")\nmasked_folder = os.path.join(working_directory, \"Masked\")\nstats_folder = os.path.join(working_directory, \"Stats\")\n\nwindow_size = 128\nnum_image_workers = 3\nnum_window_workers = 5\n</pre> import os from spectralmatch import *  # Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder working_directory = os.path.join(os.getcwd(), \"data_landsat\") print(working_directory)  input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"GlobalMatch\") local_folder = os.path.join(working_directory, \"LocalMatch\") mask_cloud_folder = os.path.join(working_directory, \"MaskCloud\") mask_vegetation_folder = os.path.join(working_directory, \"MaskVegetation\") masked_folder = os.path.join(working_directory, \"Masked\") stats_folder = os.path.join(working_directory, \"Stats\")  window_size = 128 num_image_workers = 3 num_window_workers = 5 In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\n\nfor path in input_image_paths:\n    create_cloud_mask_with_omnicloudmask(\n        path,\n        5,\n        3,\n        8,\n        os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.tif\"),\n        # down_sample_m=10\n    )\n\ninput_mask_rasters_paths = search_paths(mask_cloud_folder, \"*.tif\")\n\nfor path in input_mask_rasters_paths:\n    post_process_raster_cloud_mask_to_vector(\n        path,\n        os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}.gpkg\"),\n        None,\n        {1: 50},\n        {0: None, 1: 1, 2: 1, 3: 1}\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\")  for path in input_image_paths:     create_cloud_mask_with_omnicloudmask(         path,         5,         3,         8,         os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.tif\"),         # down_sample_m=10     )  input_mask_rasters_paths = search_paths(mask_cloud_folder, \"*.tif\")  for path in input_mask_rasters_paths:     post_process_raster_cloud_mask_to_vector(         path,         os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}.gpkg\"),         None,         {1: 50},         {0: None, 1: 1, 2: 1, 3: 1}     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\ninput_mask_vectors = search_paths(mask_cloud_folder, \"*.gpkg\", match_to_paths=(input_image_paths, r\"(.*)_CloudMask\\.gpkg$\"))\noutput_paths = create_paths(masked_folder, \"$_CloudMasked.tif\", input_image_paths)\n\nfor input_path, vector_path, output_path in zip(input_image_paths, input_mask_vectors, output_paths):\n    mask_rasters(\n        input_path,\n        vector_path,\n        output_path,\n        (\"include\", \"value\", 1),\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\") input_mask_vectors = search_paths(mask_cloud_folder, \"*.gpkg\", match_to_paths=(input_image_paths, r\"(.*)_CloudMask\\.gpkg$\")) output_paths = create_paths(masked_folder, \"$_CloudMasked.tif\", input_image_paths)  for input_path, vector_path, output_path in zip(input_image_paths, input_mask_vectors, output_paths):     mask_rasters(         input_path,         vector_path,         output_path,         (\"include\", \"value\", 1),     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\nraster_mask_paths = create_paths(mask_vegetation_folder, \"$_VegetationMask.tif\", input_image_paths)\nvector_mask_paths = create_paths(mask_vegetation_folder, \"$.gpkg\", input_image_paths)\n\nfor input_path, raster_path in zip(input_image_paths, raster_mask_paths):\n    create_ndvi_mask(\n        input_path,\n        raster_path,\n        5,\n        4,\n    )\n\nfor raster_path, vector_path in zip(raster_mask_paths, vector_mask_paths):\n    post_process_threshold_to_vector(\n        raster_path,\n        vector_path,\n        0.1,\n        \"&gt;=\",\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\") raster_mask_paths = create_paths(mask_vegetation_folder, \"$_VegetationMask.tif\", input_image_paths) vector_mask_paths = create_paths(mask_vegetation_folder, \"$.gpkg\", input_image_paths)  for input_path, raster_path in zip(input_image_paths, raster_mask_paths):     create_ndvi_mask(         input_path,         raster_path,         5,         4,     )  for raster_path, vector_path in zip(raster_mask_paths, vector_mask_paths):     post_process_threshold_to_vector(         raster_path,         vector_path,         0.1,         \"&gt;=\",     ) In\u00a0[\u00a0]: Copied! <pre># This is just a simple example of creating PIFs based on NDVI values, for a more robust methodology use other techniques to create a better mask vector file\n\ninput_vector_paths = search_paths(mask_vegetation_folder, \"*.gpkg\")\nmerged_vector_pif_path = os.path.join(working_directory, \"Pifs.gpkg\")\n\nmerge_vectors(\n    input_vector_paths,\n    merged_vector_pif_path,\n    create_name_attribute=(\"image\", \", \"),\n    method=\"intersection\",\n    # method=\"keep\", # Create a unique mask per image\n    )\n</pre> # This is just a simple example of creating PIFs based on NDVI values, for a more robust methodology use other techniques to create a better mask vector file  input_vector_paths = search_paths(mask_vegetation_folder, \"*.gpkg\") merged_vector_pif_path = os.path.join(working_directory, \"Pifs.gpkg\")  merge_vectors(     input_vector_paths,     merged_vector_pif_path,     create_name_attribute=(\"image\", \", \"),     method=\"intersection\",     # method=\"keep\", # Create a unique mask per image     ) In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")\n\nglobal_regression(\n    (masked_folder, \"*.tif\"),\n    (global_folder, \"$_GlobalMatch.tif\"),\n    vector_mask=(\"exclude\", vector_mask_path),\n    # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image\n    # save_as_cog=True, # Save output as a Cloud Optimized GeoTIFF\n    debug_logs=True,\n    )\n</pre> vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")  global_regression(     (masked_folder, \"*.tif\"),     (global_folder, \"$_GlobalMatch.tif\"),     vector_mask=(\"exclude\", vector_mask_path),     # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image     # save_as_cog=True, # Save output as a Cloud Optimized GeoTIFF     debug_logs=True,     ) In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")\n\nlocal_block_adjustment(\n    (global_folder, \"*.tif\"),\n    (local_folder, \"$_LocalMatch.tif\"),\n    number_of_blocks=100,\n    vector_mask=(\"exclude\", vector_mask_path),\n    # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image\n    # save_as_cog=True, # Save output as a Cloud Optimized GeoTIFF\n    debug_logs=True,\n    )\n</pre> vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")  local_block_adjustment(     (global_folder, \"*.tif\"),     (local_folder, \"$_LocalMatch.tif\"),     number_of_blocks=100,     vector_mask=(\"exclude\", vector_mask_path),     # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image     # save_as_cog=True, # Save output as a Cloud Optimized GeoTIFF     debug_logs=True,     ) In\u00a0[\u00a0]: Copied! <pre># Compare image spectral profiles\ncompare_image_spectral_profiles(\n    input_image_dict={\n        os.path.splitext(os.path.basename(p))[0]: p\n        for p in search_paths(local_folder, \"*.tif\")\n    },\n    output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n)\n\n# Compare image spectral profiles pairs\nbefore_paths = search_paths(input_folder, \"*.tif\")\nafter_paths = search_paths(local_folder, \"*.tif\")\n\nimage_pairs = {\n    os.path.splitext(os.path.basename(b))[0]: [b, a]\n    for b, a in zip(sorted(before_paths), sorted(after_paths))\n    }\n\ncompare_image_spectral_profiles_pairs(\n    image_pairs,\n    os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n    )\n\n# Compare spatial spectral difference band average\ninput_paths = search_paths(input_folder, \"*.tif\")\nlocal_paths = search_paths(local_folder, \"*.tif\")\nbefore_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))\n\ncompare_spatial_spectral_difference_band_average(\n    input_images=[before_path, after_path],\n    output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),\n    title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",\n    diff_label=\"Reflectance Difference (0\u201310,000)\",\n    subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\",\n)\n</pre>  # Compare image spectral profiles compare_image_spectral_profiles(     input_image_dict={         os.path.splitext(os.path.basename(p))[0]: p         for p in search_paths(local_folder, \"*.tif\")     },     output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles\",     xlabel='Band',     ylabel='Reflectance(0-10,000)', )  # Compare image spectral profiles pairs before_paths = search_paths(input_folder, \"*.tif\") after_paths = search_paths(local_folder, \"*.tif\")  image_pairs = {     os.path.splitext(os.path.basename(b))[0]: [b, a]     for b, a in zip(sorted(before_paths), sorted(after_paths))     }  compare_image_spectral_profiles_pairs(     image_pairs,     os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",     xlabel='Band',     ylabel='Reflectance(0-10,000)',     )  # Compare spatial spectral difference band average input_paths = search_paths(input_folder, \"*.tif\") local_paths = search_paths(local_folder, \"*.tif\") before_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))  compare_spatial_spectral_difference_band_average(     input_images=[before_path, after_path],     output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),     title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",     diff_label=\"Reflectance Difference (0\u201310,000)\",     subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\", )"},{"location":"examples/example_worldview_mosaic/","title":"WorldView Mosaic","text":"In\u00a0[\u00a0]: Copied! <pre># This file demonstrates how to preprocess Worldview3 imagery into a mosaic using spectralmatch.\n# Starting from two overlapping Worldview3 images in reflectance, the process includes global matching, local matching, starting from saved block maps (optional for demonstration purposes), generating seamlines, and marging images, and before vs after statistics.\n# This script is set up to perform matching on all .tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. The easiest way to process your own imagery is to move it inside that folder or change the working_directory to another folder with this structure, alternatively, you can pass in custom lists of image paths.\n</pre> # This file demonstrates how to preprocess Worldview3 imagery into a mosaic using spectralmatch. # Starting from two overlapping Worldview3 images in reflectance, the process includes global matching, local matching, starting from saved block maps (optional for demonstration purposes), generating seamlines, and marging images, and before vs after statistics. # This script is set up to perform matching on all .tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. The easiest way to process your own imagery is to move it inside that folder or change the working_directory to another folder with this structure, alternatively, you can pass in custom lists of image paths. In\u00a0[\u00a0]: Copied! <pre>import os\nfrom spectralmatch import *\n\n# Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder\nworking_directory = os.path.join(os.getcwd(), \"data_worldview\")\nprint(working_directory)\n\ninput_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\naligned_folder = os.path.join(working_directory, \"Aligned\")\nclipped_folder = os.path.join(working_directory, \"Clipped\")\nstats_folder = os.path.join(working_directory, \"Stats\")\n\n\nwindow_size = 128\nnum_image_workers = 3\nnum_window_workers = 5\n</pre> import os from spectralmatch import *  # Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder working_directory = os.path.join(os.getcwd(), \"data_worldview\") print(working_directory)  input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"GlobalMatch\") local_folder = os.path.join(working_directory, \"LocalMatch\") aligned_folder = os.path.join(working_directory, \"Aligned\") clipped_folder = os.path.join(working_directory, \"Clipped\") stats_folder = os.path.join(working_directory, \"Stats\")   window_size = 128 num_image_workers = 3 num_window_workers = 5 In\u00a0[\u00a0]: Copied! <pre>global_regression(\n    (input_folder, \"*.tif\"),\n    (global_folder, \"$_Global.tif\"),\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n    save_as_cog=True,\n    # specify_model_images=(\"include\", ['Worldview_2016-09-22']), # Global matching all input images to the spectral profile of any number of specified images (regression will still be based on overlapping areas, however, only the *included* images statistics will influence the solution)\n    # custom_mean_factor=3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together (applied when creating model)\n    custom_std_factor=3,\n    save_adjustments=os.path.join(global_folder, \"GlobalAdjustments.json\"), # Start from precomputed statistics for images whole and overlap stats\n    # load_adjustments=os.path.join(global_folder, \"GlobalAdjustments.json\"), # Load Statistics\n    )\n</pre>  global_regression(     (input_folder, \"*.tif\"),     (global_folder, \"$_Global.tif\"),     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers),     save_as_cog=True,     # specify_model_images=(\"include\", ['Worldview_2016-09-22']), # Global matching all input images to the spectral profile of any number of specified images (regression will still be based on overlapping areas, however, only the *included* images statistics will influence the solution)     # custom_mean_factor=3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together (applied when creating model)     custom_std_factor=3,     save_adjustments=os.path.join(global_folder, \"GlobalAdjustments.json\"), # Start from precomputed statistics for images whole and overlap stats     # load_adjustments=os.path.join(global_folder, \"GlobalAdjustments.json\"), # Load Statistics     ) In\u00a0[\u00a0]: Copied! <pre>reference_map_path = os.path.join(local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\")\nlocal_maps_path = os.path.join(local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\")\nsearched_paths = search_paths(os.path.join(local_folder, \"LocalBlockMap\"), \"*.tif\")\n\nlocal_block_adjustment(\n    (global_folder, \"*.tif\"),\n    (local_folder, \"$_Local.tif\"),\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n    save_as_cog=True,\n    number_of_blocks=\"coefficient_of_variation\", # Target number of blocks\n    # override_bounds_canvas_coords = (193011.1444011169369332, 2184419.3597142999060452, 205679.2836037494416814, 2198309.8632259583100677), # Local match with a larger canvas than images bounds (perhaps to anticipate adding additional imagery so you don't have to recalculate local block maps each rematch)\n    save_block_maps=(reference_map_path, local_maps_path),\n    # load_block_maps=(reference_map_path, searched_paths), # Local match from saved block maps (this code just passes in local maps, but if a reference map is passed in, it will match images to the reference map without recomputing it)\n    )\n</pre> reference_map_path = os.path.join(local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\") local_maps_path = os.path.join(local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\") searched_paths = search_paths(os.path.join(local_folder, \"LocalBlockMap\"), \"*.tif\")  local_block_adjustment(     (global_folder, \"*.tif\"),     (local_folder, \"$_Local.tif\"),     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers),     save_as_cog=True,     number_of_blocks=\"coefficient_of_variation\", # Target number of blocks     # override_bounds_canvas_coords = (193011.1444011169369332, 2184419.3597142999060452, 205679.2836037494416814, 2198309.8632259583100677), # Local match with a larger canvas than images bounds (perhaps to anticipate adding additional imagery so you don't have to recalculate local block maps each rematch)     save_block_maps=(reference_map_path, local_maps_path),     # load_block_maps=(reference_map_path, searched_paths), # Local match from saved block maps (this code just passes in local maps, but if a reference map is passed in, it will match images to the reference map without recomputing it)     ) In\u00a0[\u00a0]: Copied! <pre>align_rasters(\n    (local_folder, \"*.tif\"),\n    (aligned_folder, \"$_Aligned.tif\"),\n    tap=True,\n    resolution='lowest',\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n    )\n</pre>  align_rasters(     (local_folder, \"*.tif\"),     (aligned_folder, \"$_Aligned.tif\"),     tap=True,     resolution='lowest',     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers),     ) In\u00a0[\u00a0]: Copied! <pre>output_vector_mask = os.path.join(working_directory, \"ImageMasks.gpkg\")\ndebug_vectors_path = os.path.join(working_directory, \"DebugVectors.gpkg\")\n\nvoronoi_center_seamline(\n    (aligned_folder, \"*.tif\"),\n    output_vector_mask,\n    image_field_name='image',\n    debug_logs=True,\n    debug_vectors_path=debug_vectors_path,\n    )\n</pre> output_vector_mask = os.path.join(working_directory, \"ImageMasks.gpkg\") debug_vectors_path = os.path.join(working_directory, \"DebugVectors.gpkg\")  voronoi_center_seamline(     (aligned_folder, \"*.tif\"),     output_vector_mask,     image_field_name='image',     debug_logs=True,     debug_vectors_path=debug_vectors_path,     ) In\u00a0[\u00a0]: Copied! <pre>input_mask_path = os.path.join(working_directory, \"ImageMasks.gpkg\")\n\nmask_rasters(\n    (aligned_folder, \"*.tif\"),\n    (clipped_folder, \"$_Clipped.tif\"),\n    vector_mask=(\"include\", input_mask_path, \"image\"),\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n    )\n</pre> input_mask_path = os.path.join(working_directory, \"ImageMasks.gpkg\")  mask_rasters(     (aligned_folder, \"*.tif\"),     (clipped_folder, \"$_Clipped.tif\"),     vector_mask=(\"include\", input_mask_path, \"image\"),     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers),     ) In\u00a0[\u00a0]: Copied! <pre>output_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")\n\nmerge_rasters(\n    (clipped_folder, \"*.tif\"),\n    output_merged_image_path,\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n)\n</pre> output_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")  merge_rasters(     (clipped_folder, \"*.tif\"),     output_merged_image_path,     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers), ) In\u00a0[\u00a0]: Copied! <pre># Compare image spectral profiles\ncompare_image_spectral_profiles(\n    input_image_dict={\n        os.path.splitext(os.path.basename(p))[0]: p\n        for p in search_paths(local_folder, \"*.tif\")\n    },\n    output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n)\n\n# Compare image spectral profiles pairs\nbefore_paths = search_paths(input_folder, \"*.tif\")\nafter_paths = search_paths(local_folder, \"*.tif\")\n\nimage_pairs = {\n    os.path.splitext(os.path.basename(b))[0]: [b, a]\n    for b, a in zip(sorted(before_paths), sorted(after_paths))\n    }\n\ncompare_image_spectral_profiles_pairs(\n    image_pairs,\n    os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n    )\n\n# Compare spatial spectral difference band average\ninput_paths = search_paths(input_folder, \"*.tif\")\nlocal_paths = search_paths(local_folder, \"*.tif\")\nbefore_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))\n\ncompare_spatial_spectral_difference_band_average(\n    input_images=[before_path, after_path],\n    output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),\n    title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",\n    diff_label=\"Reflectance Difference (0\u201310,000)\",\n    subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\",\n)\n</pre>  # Compare image spectral profiles compare_image_spectral_profiles(     input_image_dict={         os.path.splitext(os.path.basename(p))[0]: p         for p in search_paths(local_folder, \"*.tif\")     },     output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles\",     xlabel='Band',     ylabel='Reflectance(0-10,000)', )  # Compare image spectral profiles pairs before_paths = search_paths(input_folder, \"*.tif\") after_paths = search_paths(local_folder, \"*.tif\")  image_pairs = {     os.path.splitext(os.path.basename(b))[0]: [b, a]     for b, a in zip(sorted(before_paths), sorted(after_paths))     }  compare_image_spectral_profiles_pairs(     image_pairs,     os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",     xlabel='Band',     ylabel='Reflectance(0-10,000)',     )  # Compare spatial spectral difference band average input_paths = search_paths(input_folder, \"*.tif\") local_paths = search_paths(local_folder, \"*.tif\") before_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))  compare_spatial_spectral_difference_band_average(     input_images=[before_path, after_path],     output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),     title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",     diff_label=\"Reflectance Difference (0\u201310,000)\",     subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\", )"}]}