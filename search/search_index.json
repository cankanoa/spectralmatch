{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"spectralmatch: A toolkit for performing Relative Radiometric Normalization, with utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, and statistics","text":"<p>[!IMPORTANT] This library is experimental and still under heavy development.</p>"},{"location":"#overview","title":"Overview","text":"<p>spectralmatch provides a Python library and QGIS plugin with multiple algorythms to perform Relative Radiometric Normalization (RRN). It also includes utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, statistics, preprocessing, and more.</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p>Automated: Works without manual intervention, making it ideal for large-scale applications.</p> </li> <li> <p>Consistent Multi-Image Analysis: Ensures uniformity across images by applying systematic corrections with minimal spectral distortion.</p> </li> <li> <p>Seamlessly Blended: Creates smooth transitions between images without visible seams.</p> </li> <li> <p>Unit Agnostic: Works with any pixel unit and preserves the spectral information for accurate analysis. This inlcludes negative numbers and reflectance.</p> </li> <li> <p>Better Input for Machine Learning Models: Provides high-quality, unbiased data for AI and analytical workflows.</p> </li> <li> <p>Minimizes Color Bias: Avoids excessive color normalization and does not rely on a strict reference image.</p> </li> <li> <p>Sensor Agnostic: Works with all optical sensors. In addition, images from differnt sensors can be combined for multisensor analysis.</p> </li> <li> <p>Parallel Processing: Optimized for modern CPUs to handle large datasets efficiently.</p> </li> <li> <p>Large-Scale Mosaics: Designed to process and blend vast image collections effectively.</p> </li> <li>Time Series: Normalize images across time with to compare spectral changes.</li> </ul>"},{"location":"#current-matching-algorithms","title":"Current Matching Algorithms","text":""},{"location":"#global-to-local-matching","title":"Global to local matching","text":"<p>This technique is derived from 'An auto-adapting global-to-local color balancing method for optical imagery mosaic' by Yu et al., 2017 (DOI: 10.1016/j.isprsjprs.2017.08.002). It is particularly useful for very high-resolution imagery (satellite or otherwise) and works in a two phase process. First, this method applies least squares regression to estimate scale and offset parameters that align the histograms of all images toward a shared spectral center. This is achieved by constructing a global model based on the overlapping areas of adjacent images, where the spectral relationships are defined. This global model ensures that each image conforms to a consistent radiometric baseline while preserving overall color fidelity. However, global correction alone cannot capture intra-image variability so a second local adjustment phase is performed. The overlap areas are divided into smaller blocks, and each block\u2019s mean is used to fine-tune the color correction. This block-wise tuning helps maintain local contrast and reduces visible seams, resulting in seamless and spectrally consistent mosaics with minimal distortion.</p> <p> Shows the average spectral profile of two WorldView 3 images before and after global to local matching.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<ul> <li> <p>Consistent Spectral Profile: The true spectral response of overlapping areas remains the same throughout the images.</p> </li> <li> <p>Least Squares Modeling: A least squares approach can effectively model and fit all images' spectral profiles.</p> </li> <li> <p>Scale and Offset Adjustment: Applying scale and offset corrections can effectively harmonize images.</p> </li> <li> <p>Minimized Color Differences: The best color correction is achieved when color differences are minimized.</p> </li> <li> <p>Geometric Alignment: Images are assumed to be geometrically aligned with known relative positions.</p> </li> <li> <p>Global Consistency: Overlapping color differences are consistent across the entire image.</p> </li> <li> <p>Local Adjustments: Block-level color differences result from the global application of adjustments.</p> </li> </ul>"},{"location":"#installation-with-pypi-and-use-as-a-python-library","title":"Installation with Pypi and use as a Python Library","text":""},{"location":"#1-system-requirements","title":"1. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10 </li> <li>PROJ \u2265 9.3 </li> <li>GDAL \u2265 3.6</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python&gt;=3.10 gdal&gt;=3.6 proj&gt;=9.3 -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"#2-install-spectralmatch-via-pypi-or-source","title":"2. Install spectralmatch (via PyPI or Source)","text":"<p>The recommended way to install is via PyPI. (this method installs only the core code as a library):</p> <pre><code>pip install spectralmatch\n</code></pre> <p>Another install method is to clone the repository and confugure the dependancies with <code>pyproject.toml</code>. (this method installs the whole repository for development or customization):</p> <pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\npip install .\n</code></pre>"},{"location":"#3-run-example-code-and-modify-for-use-optional","title":"3. Run example code and modify for use (optional)","text":"<p>Example scripts are provided to verify a successful installation and help you get started quickly:</p> <ul> <li>Global to local: <code>docs/examples/example_global_to_local.py</code></li> </ul>"},{"location":"#install-and-use-as-a-qgis-plugin","title":"Install and use as a QGIS Plugin","text":"<ol> <li>Download and install QGIS</li> <li>Open QGIS</li> <li>Go to Plugins \u2192 Manage and Install Plugins\u2026</li> <li>Find spectralmatch in the list, install, and enable it</li> <li>Find the plugin in the Processing Toolbox</li> </ol>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at spectralmatch.github.io/spectralmatch/.</p>"},{"location":"#contributing-guide","title":"Contributing Guide","text":"<p>We welcome all contributions the project! To get started: 1. Create an issue with the appropriate label describing the feature or improvement. Provide relevant context, desired timeline, any assistance needed, who will be responsible for the work, anticipated results, and any other details. 2. Fork the repository and create a new feature branch. 3. Make your changes and add any necessary tests. 4. Open a Pull Request against the main repository.</p>"},{"location":"#developer-guide","title":"Developer Guide","text":"<ol> <li> <p>Clone the Repository <pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\n</code></pre></p> </li> <li> <p>Install with Dev andor Docs Extras</p> </li> </ol> <p>There are additional <code>[dev]</code> and <code>[docs]</code> dependancies specified in <code>pyproject.toml</code>:</p> <pre><code>pip install -e \".[dev]\"   # for developer dependencies\npip install -e \".[docs]\"  # for documentation dependencies\n</code></pre> <ol> <li>Set Up Pre-commit Hooks</li> </ol> <p>To maintain code consistency before each commit install these hooks:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>"},{"location":"#testing","title":"Testing","text":"<p>pytest is used for testing. Tests will automatically be run when merging into main but they can also be run locally via:</p> <pre><code>pytest\n</code></pre> <p>Run tests for a specific file or function:</p> <pre><code>pytest folder/file.py\n</code></pre>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See LICENSE for details.</p>"},{"location":"installation/","title":"Installation","text":"<p>...</p>"},{"location":"api/mask/","title":"Masking Module","text":""},{"location":"api/mask/#spectralmatch.mask.post_process_raster_cloud_mask_to_vector","title":"<code>post_process_raster_cloud_mask_to_vector(input_image_path, minimum_mask_size_percentile=None, polygon_buffering_in_map_units=None, value_mapping=None)</code>","text":"<p>Vectorizes a cloud mask raster and post-processes the polygons.</p> <p>Parameters: input_image (str): Path to the input mask raster (e.g., a TIFF). minimum_mask_size_percentile (float, optional): Percentile threshold; polygons whose area is below this percentile are removed. If None, no area-based filtering is applied. polygon_buffering_in_map_units (dict, optional): A dictionary mapping a polygon's 'value' attribute (from vectorization) to a buffering distance in map units. For example: {0: 5, 1: 30} buffers polygons with value 0 by 5 units and those with value 1 by 30 units. If a polygon's value is not in the dictionary, its geometry remains unchanged. value_mapping (dict, optional): A dictionary mapping original pixel values to new group values. For example: {1: 1, 2: 1, 3: 1} clusters pixels with values 1, 2, and 3 together.</p> <p>Returns: ogr.DataSource: An in-memory GDAL vector datasource containing the processed polygon features.</p> <p>The function performs: 1. Reading the first band of the raster mask. 2. Optional value mapping. 3. Vectorization of the raster into polygons. 4. (Optional) Removal of polygons with areas below the given percentile. 5. Buffering for each polygon based on the provided dictionary. 6. Merging of overlapping polygons with the same \"value\". 7. Conversion into an in-memory GDAL vector datasource.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def post_process_raster_cloud_mask_to_vector(\n    input_image_path: str,\n    minimum_mask_size_percentile: float = None,\n    polygon_buffering_in_map_units: dict = None,\n    value_mapping: dict = None\n    ) -&gt; ogr.DataSource:\n\n    \"\"\"\n    Vectorizes a cloud mask raster and post-processes the polygons.\n\n    Parameters:\n    input_image (str): Path to the input mask raster (e.g., a TIFF).\n    minimum_mask_size_percentile (float, optional): Percentile threshold; polygons whose area is below\n    this percentile are removed. If None, no area-based filtering is applied.\n    polygon_buffering_in_map_units (dict, optional): A dictionary mapping a polygon's 'value' attribute\n    (from vectorization) to a buffering distance in map units.\n    For example: {0: 5, 1: 30} buffers polygons with value 0 by 5 units and those with value 1 by 30 units.\n    If a polygon's value is not in the dictionary, its geometry remains unchanged.\n    value_mapping (dict, optional): A dictionary mapping original pixel values to new group values.\n    For example: {1: 1, 2: 1, 3: 1} clusters pixels with values 1, 2, and 3 together.\n\n    Returns:\n    ogr.DataSource: An in-memory GDAL vector datasource containing the processed polygon features.\n\n    The function performs:\n    1. Reading the first band of the raster mask.\n    2. Optional value mapping.\n    3. Vectorization of the raster into polygons.\n    4. (Optional) Removal of polygons with areas below the given percentile.\n    5. Buffering for each polygon based on the provided dictionary.\n    6. Merging of overlapping polygons with the same \"value\".\n    7. Conversion into an in-memory GDAL vector datasource.\n    \"\"\"\n    # --- Step 1: Read the raster mask ---\n    with rasterio.open(input_image_path) as src:\n        raster_data = src.read(1)\n        transform = src.transform\n        crs = src.crs  # Rasterio CRS (usually a pyproj CRS)\n\n    # --- Step 2: Apply optional value mapping ---\n    if value_mapping is not None:\n        mapped = np.copy(raster_data)\n        for orig_value, new_value in value_mapping.items():\n            mapped[raster_data == orig_value] = new_value\n        raster_data = mapped\n\n    # --- Step 3: Vectorize the raster ---\n    results = (\n        {'properties': {'value': v}, 'geometry': s}\n        for s, v in shapes(raster_data, transform=transform, connectivity=4)\n    )\n    features = list(results)\n    if not features:\n        print(\"No features were detected in the raster mask.\")\n        return None\n\n    # Create a GeoDataFrame from the vectorized features.\n    gdf = gpd.GeoDataFrame.from_features(features, crs=crs)\n\n    # --- Step 4: Compute areas and, if requested, filter out small polygons ---\n    gdf['area'] = gdf.geometry.area\n    if minimum_mask_size_percentile is not None:\n        area_threshold = np.percentile(gdf['area'], minimum_mask_size_percentile)\n        print(f\"Area threshold (at {minimum_mask_size_percentile}th percentile): {area_threshold:.2f}\")\n        gdf = gdf[gdf['area'] &gt;= area_threshold].copy()\n\n    # --- Step 5: Apply buffering per polygon based on the provided dictionary ---\n    if polygon_buffering_in_map_units is not None:\n        gdf['geometry'] = gdf.apply(\n            lambda row: row['geometry'].buffer(polygon_buffering_in_map_units.get(row['value'], 0))\n            if row['value'] in polygon_buffering_in_map_units else row['geometry'],\n            axis=1\n        )\n\n    # --- Step 6: Merge overlapping polygons by 'value' ---\n    # Group by the 'value' attribute and merge (union) polygons within each group.\n    merged_features = []\n    for val, group in gdf.groupby('value'):\n        # Use union_all() to merge the geometries within the group.\n        # (Requires Shapely 2.0 or later; otherwise use shapely.ops.unary_union on group.geometry.tolist())\n        union_geom = group.geometry.union_all()\n        # If the union produces a single Polygon, add it directly;\n        # if it produces a MultiPolygon, split it into individual features.\n        if union_geom.geom_type == 'Polygon':\n            merged_features.append({'value': val, 'geometry': union_geom})\n        elif union_geom.geom_type == 'MultiPolygon':\n            for geom in union_geom.geoms:\n                merged_features.append({'value': val, 'geometry': geom})\n        else:\n            # In case of unexpected geometry types, skip or handle accordingly.\n            print(f\"Unexpected geometry type for value {val}: {union_geom.geom_type}\")\n    # Create a new GeoDataFrame from merged features.\n    gdf = gpd.GeoDataFrame(merged_features, crs=gdf.crs)\n\n    # --- Step 7: Convert the GeoDataFrame to an in-memory GDAL vector datasource ---\n    ogr_driver = ogr.GetDriverByName(\"Memory\")\n    mem_ds = ogr_driver.CreateDataSource(\"in_memory\")\n\n    # Determine an appropriate OGR geometry type using the first feature.\n    first_geom = gdf.geometry.iloc[0]\n    if first_geom.geom_type == \"Polygon\":\n        ogr_geom_type = ogr.wkbPolygon\n    elif first_geom.geom_type == \"MultiPolygon\":\n        ogr_geom_type = ogr.wkbMultiPolygon\n    else:\n        ogr_geom_type = ogr.wkbUnknown\n\n    # Convert the CRS to OGR SpatialReference.\n    sr = osr.SpatialReference()\n    try:\n        sr.ImportFromWkt(crs.to_wkt())\n    except AttributeError:\n        sr.ImportFromEPSG(4326)\n\n    mem_layer = mem_ds.CreateLayer(\"post_processed\", sr, ogr_geom_type)\n\n    # Add attribute field for 'value' (and any other non-geometry columns if needed).\n    # Here we add 'value' for example.\n    field_defn = ogr.FieldDefn(\"value\", ogr.OFTInteger)\n    mem_layer.CreateField(field_defn)\n    # Optionally, add other fields (e.g. 'area') if desired.\n\n    # Add each row from the GeoDataFrame as an OGR feature.\n    for idx, row in gdf.iterrows():\n        feat = ogr.Feature(mem_layer.GetLayerDefn())\n        ogr_geom = ogr.CreateGeometryFromWkt(row['geometry'].wkt)\n        feat.SetGeometry(ogr_geom)\n        feat.SetField(\"value\", row['value'])\n        mem_layer.CreateFeature(feat)\n        feat = None\n\n    return mem_ds\n</code></pre>"},{"location":"api/match/","title":"Process Module","text":""},{"location":"api/match/#spectralmatch.match.global_regression.global_regression","title":"<code>global_regression(input_image_paths, output_image_folder, *, custom_mean_factor=1.0, custom_std_factor=1.0, output_global_basename='_global', vector_mask_path=None, tile_width_and_height_tuple=None, debug_mode=False, custom_nodata_value=None, parallel=False, max_workers=None, calc_dtype='float32')</code>","text":"<p>Matches multiple input raster images to a common global statistical range using overlapping areas for deriving statistical adjustments. Adjustments include mean and standard deviation factors, ensuring the images are globally consistent in derived values.</p> <p>This function processes pairs of overlapping raster images to compute statistical parameters, combines global statistics for the entire collection of raster images, and generates output raster images with adjusted pixel values. Additional features such as custom nodata values, vector mask usage, and tiling are supported. The function allows parallel processing to optimize performance.</p> <p>Args: input_image_paths (List[str]): Paths to input raster images. output_image_folder (str): Directory where adjusted images will be saved. custom_mean_factor (float): Scale factor for mean adjustment, default is 1.0. custom_std_factor (float): Scale factor for standard deviation adjustment, default is 1.0. output_global_basename (str): Global basename suffix added to output image filenames, default is \"_global\". vector_mask_path (Optional[str]): Path to a vector mask file used to limit processing, optional. tile_width_and_height_tuple (Optional[Tuple[int, int]]): Tuple specifying tile width and height for tiled processing, optional. debug_mode (bool): Enables debug mode when set to True, default is False. custom_nodata_value (float | None): Override nodata value for rasters, optional. parallel (bool): Enables parallel processing when set to True, default is False. max_workers (int | None): Maximum number of workers for parallel processing, default is None. calc_dtype (str): Data type used for intermediate calculations, default is \"float32\".</p> <p>Returns: List[str]: Paths to the output adjusted raster images.</p> Source code in <code>spectralmatch/match/global_regression.py</code> <pre><code>def global_regression(\n    input_image_paths: List[str],\n    output_image_folder: str,\n    *,\n    custom_mean_factor: float = 1.0,\n    custom_std_factor: float = 1.0,\n    output_global_basename: str = \"_global\",\n    vector_mask_path: Optional[str] = None,\n    tile_width_and_height_tuple: Optional[Tuple[int, int]] = None,\n    debug_mode: bool = False,\n    custom_nodata_value: float | None = None,\n    parallel: bool = False,\n    max_workers: int | None = None,\n    calc_dtype: str = \"float32\",\n    ):\n\n    \"\"\"\n    Matches multiple input raster images to a common global statistical range using overlapping areas\n    for deriving statistical adjustments. Adjustments include mean and standard deviation factors, ensuring\n    the images are globally consistent in derived values.\n\n    This function processes pairs of overlapping raster images to compute statistical parameters, combines\n    global statistics for the entire collection of raster images, and generates output raster images with\n    adjusted pixel values. Additional features such as custom nodata values, vector mask usage, and tiling\n    are supported. The function allows parallel processing to optimize performance.\n\n    Args:\n    input_image_paths (List[str]): Paths to input raster images.\n    output_image_folder (str): Directory where adjusted images will be saved.\n    custom_mean_factor (float): Scale factor for mean adjustment, default is 1.0.\n    custom_std_factor (float): Scale factor for standard deviation adjustment, default is 1.0.\n    output_global_basename (str): Global basename suffix added to output image filenames, default is \"_global\".\n    vector_mask_path (Optional[str]): Path to a vector mask file used to limit processing, optional.\n    tile_width_and_height_tuple (Optional[Tuple[int, int]]): Tuple specifying tile width and height for tiled processing, optional.\n    debug_mode (bool): Enables debug mode when set to True, default is False.\n    custom_nodata_value (float | None): Override nodata value for rasters, optional.\n    parallel (bool): Enables parallel processing when set to True, default is False.\n    max_workers (int | None): Maximum number of workers for parallel processing, default is None.\n    calc_dtype (str): Data type used for intermediate calculations, default is \"float32\".\n\n    Returns:\n    List[str]: Paths to the output adjusted raster images.\n    \"\"\"\n    print(\"Start global matching\")\n\n    _check_raster_requirements(input_image_paths, debug_mode)\n\n    nodata_val = _get_nodata_value(input_image_paths, custom_nodata_value)\n\n    if debug_mode: print(\"Calculating statistics\")\n    with rasterio.open(input_image_paths[0]) as src: num_bands = src.count\n    num_images = len(input_image_paths)\n\n    all_bounds = {}\n    for idx, p in enumerate(input_image_paths):\n        with rasterio.open(p) as ds:\n            all_bounds[idx] = ds.bounds\n\n    overlapping_pairs = _find_overlaps(all_bounds)\n\n    all_overlap_stats = {}\n    for id_i, id_j in overlapping_pairs:\n        stats = _calculate_overlap_stats(\n            num_bands,\n            input_image_paths[id_i],\n            input_image_paths[id_j],\n            id_i,\n            id_j,\n            all_bounds[id_i],\n            all_bounds[id_j],\n            nodata_val,\n            nodata_val,\n            vector_mask_path=vector_mask_path,\n            tile_width_and_height_tuple=tile_width_and_height_tuple,\n            debug_mode=debug_mode,\n        )\n        all_overlap_stats.update(\n            {\n                k_i: {\n                    **all_overlap_stats.get(k_i, {}),\n                    **{\n                        k_j: {**all_overlap_stats.get(k_i, {}).get(k_j, {}), **s}\n                        for k_j, s in v.items()\n                    },\n                }\n                for k_i, v in stats.items()\n            }\n        )\n\n    all_whole_stats = {}\n    for idx, path in enumerate(input_image_paths):\n        all_whole_stats.update(\n            _calculate_whole_stats(\n                input_image_path=path,\n                nodata=nodata_val,\n                num_bands=num_bands,\n                image_id=idx,\n                vector_mask_path=vector_mask_path,\n                tile_width_and_height_tuple=tile_width_and_height_tuple,\n            )\n        )\n\n    all_params = np.zeros((num_bands, 2 * num_images, 1), dtype=float)\n    for b in range(num_bands):\n        if debug_mode: print(f\"Processing band {b} for {num_images} images\")\n\n        A, y, tot_overlap = [], [], 0\n        for i in range(num_images):\n\n            for j in range(i + 1, num_images):\n                stat = all_overlap_stats.get(i, {}).get(j)\n                if stat is None:\n                    continue\n                s = stat[b][\"size\"]\n                m1, v1 = stat[b][\"mean\"], stat[b][\"std\"]\n                m2, v2 = (\n                    all_overlap_stats[j][i][b][\"mean\"],\n                    all_overlap_stats[j][i][b][\"std\"],\n                )\n                row_m = [0] * (2 * num_images)\n                row_s = [0] * (2 * num_images)\n                row_m[2 * i : 2 * i + 2] = [m1, 1]\n                row_m[2 * j : 2 * j + 2] = [-m2, -1]\n                row_s[2 * i], row_s[2 * j] = v1, -v2\n                A.extend(\n                    [\n                        [v * s * custom_mean_factor for v in row_m],\n                        [v * s * custom_std_factor for v in row_s],\n                    ]\n                )\n                y.extend([0, 0])\n                tot_overlap += s\n        pjj = 1.0 if tot_overlap == 0 else tot_overlap / (2.0 * num_images)\n        for j in range(num_images):\n            mj = all_whole_stats[j][b][\"mean\"]\n            vj = all_whole_stats[j][b][\"std\"]\n            row_m = [0] * (2 * num_images)\n            row_s = [0] * (2 * num_images)\n            row_m[2 * j : 2 * j + 2] = [mj * pjj, 1 * pjj]\n            row_s[2 * j] = vj * pjj\n            A.extend([row_m, row_s])\n            y.extend([mj * pjj, vj * pjj])\n\n        A_arr = np.asarray(A)\n        y_arr = np.asarray(y)\n        res = least_squares(lambda p: np.asarray(A) @ p - np.asarray(y), [1, 0] * num_images)\n        if debug_mode:\n            overlap_pairs = overlapping_pairs\n            _print_constraint_system(\n                constraint_matrix=A_arr,\n                adjustment_params=res.x,\n                observed_values_vector=y_arr,\n                overlap_pairs=overlap_pairs,\n                num_images=num_images,\n            )\n\n        all_params[b] = res.x.reshape((2 * num_images, 1))\n\n    img_dir = os.path.join(output_image_folder, \"Images\")\n    if not os.path.exists(img_dir): os.makedirs(img_dir)\n    out_paths: List[str] = []\n\n    if parallel and max_workers is None:\n        max_workers = mp.cpu_count()\n\n    for img_idx, img_path in enumerate(input_image_paths):\n        base = os.path.splitext(os.path.basename(img_path))[0]\n        out_path = os.path.join(img_dir, f\"{base}{output_global_basename}.tif\")\n        out_paths.append(str(out_path))\n\n        if debug_mode: print(f\"Apply adjustments and saving results for {base}\")\n        with rasterio.open(img_path) as src:\n            meta = src.meta.copy()\n            meta.update({\"count\": num_bands, \"nodata\": nodata_val})\n            with rasterio.open(out_path, \"w\", **meta) as dst:\n\n                if tile_width_and_height_tuple:\n                    tw, th = tile_width_and_height_tuple\n                    windows = list(_create_windows(src.width, src.height, tw, th))\n                else:\n                    windows = [Window(0, 0, src.width, src.height)]\n\n                if parallel:\n                    ctx = _choose_context(prefer_fork=True)\n                    pool = ProcessPoolExecutor(\n                        max_workers=max_workers,\n                        mp_context=ctx,\n                        initializer=_init_worker,\n                        initargs=(img_path,),\n                    )\n\n                for b in range(num_bands):\n                    a = all_params[b, 2 * img_idx, 0]\n                    b0 = all_params[b, 2 * img_idx + 1, 0]\n\n                    if parallel:\n                        futs = [\n                            pool.submit(_process_tile_global,\n                                        w,\n                                        b,\n                                        a,\n                                        b0,\n                                        nodata_val,\n                                        calc_dtype,\n                                        debug_mode,\n                                        )\n                            for w in windows\n                        ]\n                        for fut in as_completed(futs):\n                            win, buf = fut.result()\n                            dst.write(buf.astype(meta[\"dtype\"]), b + 1, window=win)\n                    else:\n                        for win in windows:\n                            _, buf = _process_tile_global(\n                                win,\n                                b,\n                                a,\n                                b0,\n                                nodata_val,\n                                debug_mode,\n                            )\n                            dst.write(buf.astype(meta[\"dtype\"]), b + 1, window=win)\n                if parallel:\n                    pool.shutdown()\n\n    print(\"Finished global matching\")\n    return out_paths\n</code></pre>"},{"location":"api/utils/","title":"Common Utils Module","text":""},{"location":"examples/benchmark/","title":"Benchmark","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nBenchmark full pipeline  (global_match + local_match)\n\n\u2022 Synthetic 8-band rasters, 2 overlapping tiles\n\u2022 Tile size = 1024 \u00d7 1024 for both steps\n\u2022 Serial vs parallel (32 workers)\n\"\"\"\n</pre> \"\"\" Benchmark full pipeline  (global_match + local_match)  \u2022 Synthetic 8-band rasters, 2 overlapping tiles \u2022 Tile size = 1024 \u00d7 1024 for both steps \u2022 Serial vs parallel (32 workers) \"\"\" In\u00a0[\u00a0]: Copied! <pre>import os, shutil, tempfile, time\nfrom pathlib import Path\n</pre> import os, shutil, tempfile, time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_origin\n</pre> import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.transform import from_origin In\u00a0[\u00a0]: Copied! <pre>from spectralmatch.process import global_match, local_match\n</pre> from spectralmatch.process import global_match, local_match In\u00a0[\u00a0]: Copied! <pre># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 synthetic raster helper \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef make_fake_rasters(out_dir, n_images, width, height, nodata=0):\n    out_dir = Path(out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n    profile = dict(\n        driver=\"GTiff\",\n        width=width,\n        height=height,\n        count=8,\n        dtype=\"uint16\",\n        nodata=nodata,\n        crs=\"EPSG:3857\",\n        transform=from_origin(0, 0, 1, 1),\n        tiled=True,\n        blockxsize=512,\n        blockysize=512,\n        compress=\"LZW\",\n    )\n    rng = np.random.default_rng(seed=42)\n    paths = []\n    for i in range(n_images):\n        p = out_dir / f\"fake_{i+1}_{width}px.tif\"\n        with rasterio.open(p, \"w\", **profile) as dst:\n            for b in range(1, 9):\n                data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")\n                data[0, 0] = nodata\n                dst.write(data, indexes=b)\n        paths.append(str(p))\n    return paths\n</pre> # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 synthetic raster helper \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def make_fake_rasters(out_dir, n_images, width, height, nodata=0):     out_dir = Path(out_dir)     out_dir.mkdir(parents=True, exist_ok=True)     profile = dict(         driver=\"GTiff\",         width=width,         height=height,         count=8,         dtype=\"uint16\",         nodata=nodata,         crs=\"EPSG:3857\",         transform=from_origin(0, 0, 1, 1),         tiled=True,         blockxsize=512,         blockysize=512,         compress=\"LZW\",     )     rng = np.random.default_rng(seed=42)     paths = []     for i in range(n_images):         p = out_dir / f\"fake_{i+1}_{width}px.tif\"         with rasterio.open(p, \"w\", **profile) as dst:             for b in range(1, 9):                 data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")                 data[0, 0] = nodata                 dst.write(data, indexes=b)         paths.append(str(p))     return paths In\u00a0[\u00a0]: Copied! <pre>SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288]\nNUM_IMAGES = 2\nTILE_SIZE = (1024, 1024)\nMAX_WORKERS = 32\n</pre> SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288] NUM_IMAGES = 2 TILE_SIZE = (1024, 1024) MAX_WORKERS = 32 In\u00a0[\u00a0]: Copied! <pre>WORK_DIR = Path(__file__).parent / \"bench_output\"\nWORK_DIR.mkdir(exist_ok=True)\n</pre> WORK_DIR = Path(__file__).parent / \"bench_output\" WORK_DIR.mkdir(exist_ok=True) In\u00a0[\u00a0]: Copied! <pre>SERIAL, PARALLEL = [], []\n</pre> SERIAL, PARALLEL = [], [] In\u00a0[\u00a0]: Copied! <pre>for sz in SIZES:\n    print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")\n    tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))\n    imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)\n\n    t0 = time.time()\n    g_dir = tmp / \"serial_g\"\n    l_dir = tmp / \"serial_l\"\n\n    global_match(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        tile_width_and_height_tuple=TILE_SIZE,\n        parallel=False,\n        debug_mode=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_match(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        tile_width_and_height_tuple=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=False,\n        debug_mode=False,\n    )\n    SERIAL.append(time.time() - t0)\n    print(f\"serial   : {SERIAL[-1]:.1f} s\")\n\n    t0 = time.time()\n    g_dir = tmp / \"parallel_g\"\n    l_dir = tmp / \"parallel_l\"\n\n    global_match(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        tile_width_and_height_tuple=TILE_SIZE,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_mode=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_match(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        tile_width_and_height_tuple=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_mode=False,\n    )\n    PARALLEL.append(time.time() - t0)\n    print(f\"parallel : {PARALLEL[-1]:.1f} s\")\n\n    shutil.rmtree(tmp, ignore_errors=True)\n</pre> for sz in SIZES:     print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")     tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))     imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)      t0 = time.time()     g_dir = tmp / \"serial_g\"     l_dir = tmp / \"serial_l\"      global_match(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         tile_width_and_height_tuple=TILE_SIZE,         parallel=False,         debug_mode=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_match(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         tile_width_and_height_tuple=TILE_SIZE,         custom_nodata_value=-9999,         parallel=False,         debug_mode=False,     )     SERIAL.append(time.time() - t0)     print(f\"serial   : {SERIAL[-1]:.1f} s\")      t0 = time.time()     g_dir = tmp / \"parallel_g\"     l_dir = tmp / \"parallel_l\"      global_match(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         tile_width_and_height_tuple=TILE_SIZE,         parallel=True,         max_workers=MAX_WORKERS,         debug_mode=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_match(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         tile_width_and_height_tuple=TILE_SIZE,         custom_nodata_value=-9999,         parallel=True,         max_workers=MAX_WORKERS,         debug_mode=False,     )     PARALLEL.append(time.time() - t0)     print(f\"parallel : {PARALLEL[-1]:.1f} s\")      shutil.rmtree(tmp, ignore_errors=True) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 5))\nplt.plot(SIZES, SERIAL, \"-o\", label=\"serial\")\nplt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\")\nplt.xlabel(\"Raster width = height (pixels)\")\nplt.ylabel(\"Total runtime: global + local (seconds)\")\nplt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(8, 5)) plt.plot(SIZES, SERIAL, \"-o\", label=\"serial\") plt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\") plt.xlabel(\"Raster width = height (pixels)\") plt.ylabel(\"Total runtime: global + local (seconds)\") plt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\") plt.grid(True) plt.legend() plt.tight_layout() plt.show()"},{"location":"examples/example_global_to_local/","title":"Example global to local","text":"In\u00a0[\u00a0]: Copied! <pre>import os\n</pre> import os In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import global_regression, local_block_adjustment\nfrom spectralmatch import merge_rasters\n</pre> from spectralmatch import global_regression, local_block_adjustment from spectralmatch import merge_rasters In\u00a0[\u00a0]: Copied! <pre># -------------------- Parameters\nworking_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"example_data\")\n# This script is setup to perform matching on all tif files from a folder within the working directory called \"input\" e.g. working_directory/input/*.tif.\n</pre> # -------------------- Parameters working_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"example_data\") # This script is setup to perform matching on all tif files from a folder within the working directory called \"input\" e.g. working_directory/input/*.tif. In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = working_directory + \"/Input/Masks.gpkg\"\n</pre> vector_mask_path = working_directory + \"/Input/Masks.gpkg\" In\u00a0[\u00a0]: Copied! <pre>input_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"Output/GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"Output/LocalMatch\")\n</pre> input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"Output/GlobalMatch\") local_folder = os.path.join(working_directory, \"Output/LocalMatch\") In\u00a0[\u00a0]: Copied! <pre># -------------------- Global histogram matching\ninput_image_paths_array = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")]\n</pre> # -------------------- Global histogram matching input_image_paths_array = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")] In\u00a0[\u00a0]: Copied! <pre>matched_global_images_paths = global_regression(\n    input_image_paths_array,\n    global_folder,\n    custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together\n    custom_std_factor = 1,\n    # vector_mask_path=vector_mask_path,\n    debug_mode=True,\n    tile_width_and_height_tuple=(512, 512),\n    parallel=True,\n    )\n</pre> matched_global_images_paths = global_regression(     input_image_paths_array,     global_folder,     custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together     custom_std_factor = 1,     # vector_mask_path=vector_mask_path,     debug_mode=True,     tile_width_and_height_tuple=(512, 512),     parallel=True,     ) In\u00a0[\u00a0]: Copied! <pre>merge_rasters(\n    matched_global_images_paths, # Rasters are layered with the last ones on top\n    os.path.join(working_directory, \"Output/GlobalMatch/MatchedGlobalImages.tif\"),\n    tile_width_and_height_tuple=(512, 512),\n    )\n</pre> merge_rasters(     matched_global_images_paths, # Rasters are layered with the last ones on top     os.path.join(working_directory, \"Output/GlobalMatch/MatchedGlobalImages.tif\"),     tile_width_and_height_tuple=(512, 512),     ) In\u00a0[\u00a0]: Copied! <pre># -------------------- Local histogram matching\nglobal_image_paths_array = [os.path.join(f\"{global_folder}/Images\", f) for f in os.listdir(f\"{global_folder}/Images\") if f.lower().endswith(\".tif\")]\n</pre> # -------------------- Local histogram matching global_image_paths_array = [os.path.join(f\"{global_folder}/Images\", f) for f in os.listdir(f\"{global_folder}/Images\") if f.lower().endswith(\".tif\")] In\u00a0[\u00a0]: Copied! <pre>matched_local_images_paths = local_block_adjustment(\n    global_image_paths_array,\n    local_folder,\n    target_blocks_per_image=100,\n    projection=\"EPSG:6635\",\n    debug_mode=True,\n    # custom_nodata_value=-9999,\n    tile_width_and_height_tuple=(512, 512),\n    parallel=True,\n    )\n</pre> matched_local_images_paths = local_block_adjustment(     global_image_paths_array,     local_folder,     target_blocks_per_image=100,     projection=\"EPSG:6635\",     debug_mode=True,     # custom_nodata_value=-9999,     tile_width_and_height_tuple=(512, 512),     parallel=True,     ) In\u00a0[\u00a0]: Copied! <pre>merge_rasters(\n    matched_local_images_paths, # Rasters are layered with the last ones on top\n    os.path.join(working_directory, \"Output/LocalMatch/MatchedLocalImages.tif\"),\n    tile_width_and_height_tuple=(512, 512),\n    )\n</pre> merge_rasters(     matched_local_images_paths, # Rasters are layered with the last ones on top     os.path.join(working_directory, \"Output/LocalMatch/MatchedLocalImages.tif\"),     tile_width_and_height_tuple=(512, 512),     ) In\u00a0[\u00a0]: Copied! <pre>print(\"Done with global and local histogram matching\")\n</pre> print(\"Done with global and local histogram matching\")"},{"location":"examples/example_data/benchmark/","title":"Benchmark","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nBenchmark full pipeline  (global_match + local_match)\n\n\u2022 Synthetic 8-band rasters, 2 overlapping tiles\n\u2022 Tile size = 1024 \u00d7 1024 for both steps\n\u2022 Serial vs parallel (32 workers)\n\"\"\"\n</pre> \"\"\" Benchmark full pipeline  (global_match + local_match)  \u2022 Synthetic 8-band rasters, 2 overlapping tiles \u2022 Tile size = 1024 \u00d7 1024 for both steps \u2022 Serial vs parallel (32 workers) \"\"\" In\u00a0[\u00a0]: Copied! <pre>import os, shutil, tempfile, time\nfrom pathlib import Path\n</pre> import os, shutil, tempfile, time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_origin\n</pre> import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.transform import from_origin In\u00a0[\u00a0]: Copied! <pre>from spectralmatch.process import global_match, local_match\n</pre> from spectralmatch.process import global_match, local_match In\u00a0[\u00a0]: Copied! <pre># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 synthetic raster helper \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef make_fake_rasters(out_dir, n_images, width, height, nodata=0):\n    out_dir = Path(out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n    profile = dict(\n        driver=\"GTiff\",\n        width=width,\n        height=height,\n        count=8,\n        dtype=\"uint16\",\n        nodata=nodata,\n        crs=\"EPSG:3857\",\n        transform=from_origin(0, 0, 1, 1),\n        tiled=True,\n        blockxsize=512,\n        blockysize=512,\n        compress=\"LZW\",\n    )\n    rng = np.random.default_rng(seed=42)\n    paths = []\n    for i in range(n_images):\n        p = out_dir / f\"fake_{i+1}_{width}px.tif\"\n        with rasterio.open(p, \"w\", **profile) as dst:\n            for b in range(1, 9):\n                data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")\n                data[0, 0] = nodata\n                dst.write(data, indexes=b)\n        paths.append(str(p))\n    return paths\n</pre> # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 synthetic raster helper \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def make_fake_rasters(out_dir, n_images, width, height, nodata=0):     out_dir = Path(out_dir)     out_dir.mkdir(parents=True, exist_ok=True)     profile = dict(         driver=\"GTiff\",         width=width,         height=height,         count=8,         dtype=\"uint16\",         nodata=nodata,         crs=\"EPSG:3857\",         transform=from_origin(0, 0, 1, 1),         tiled=True,         blockxsize=512,         blockysize=512,         compress=\"LZW\",     )     rng = np.random.default_rng(seed=42)     paths = []     for i in range(n_images):         p = out_dir / f\"fake_{i+1}_{width}px.tif\"         with rasterio.open(p, \"w\", **profile) as dst:             for b in range(1, 9):                 data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")                 data[0, 0] = nodata                 dst.write(data, indexes=b)         paths.append(str(p))     return paths In\u00a0[\u00a0]: Copied! <pre>SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288]\nNUM_IMAGES = 2\nTILE_SIZE = (1024, 1024)\nMAX_WORKERS = 32\n</pre> SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288] NUM_IMAGES = 2 TILE_SIZE = (1024, 1024) MAX_WORKERS = 32 In\u00a0[\u00a0]: Copied! <pre>WORK_DIR = Path(__file__).parent / \"bench_output\"\nWORK_DIR.mkdir(exist_ok=True)\n</pre> WORK_DIR = Path(__file__).parent / \"bench_output\" WORK_DIR.mkdir(exist_ok=True) In\u00a0[\u00a0]: Copied! <pre>SERIAL, PARALLEL = [], []\n</pre> SERIAL, PARALLEL = [], [] In\u00a0[\u00a0]: Copied! <pre>for sz in SIZES:\n    print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")\n    tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))\n    imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)\n\n    t0 = time.time()\n    g_dir = tmp / \"serial_g\"\n    l_dir = tmp / \"serial_l\"\n\n    global_match(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        tile_width_and_height_tuple=TILE_SIZE,\n        parallel=False,\n        debug_mode=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_match(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        tile_width_and_height_tuple=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=False,\n        debug_mode=False,\n    )\n    SERIAL.append(time.time() - t0)\n    print(f\"serial   : {SERIAL[-1]:.1f} s\")\n\n    t0 = time.time()\n    g_dir = tmp / \"parallel_g\"\n    l_dir = tmp / \"parallel_l\"\n\n    global_match(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        tile_width_and_height_tuple=TILE_SIZE,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_mode=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_match(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        tile_width_and_height_tuple=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_mode=False,\n    )\n    PARALLEL.append(time.time() - t0)\n    print(f\"parallel : {PARALLEL[-1]:.1f} s\")\n\n    shutil.rmtree(tmp, ignore_errors=True)\n</pre> for sz in SIZES:     print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")     tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))     imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)      t0 = time.time()     g_dir = tmp / \"serial_g\"     l_dir = tmp / \"serial_l\"      global_match(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         tile_width_and_height_tuple=TILE_SIZE,         parallel=False,         debug_mode=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_match(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         tile_width_and_height_tuple=TILE_SIZE,         custom_nodata_value=-9999,         parallel=False,         debug_mode=False,     )     SERIAL.append(time.time() - t0)     print(f\"serial   : {SERIAL[-1]:.1f} s\")      t0 = time.time()     g_dir = tmp / \"parallel_g\"     l_dir = tmp / \"parallel_l\"      global_match(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         tile_width_and_height_tuple=TILE_SIZE,         parallel=True,         max_workers=MAX_WORKERS,         debug_mode=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_match(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         tile_width_and_height_tuple=TILE_SIZE,         custom_nodata_value=-9999,         parallel=True,         max_workers=MAX_WORKERS,         debug_mode=False,     )     PARALLEL.append(time.time() - t0)     print(f\"parallel : {PARALLEL[-1]:.1f} s\")      shutil.rmtree(tmp, ignore_errors=True) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 5))\nplt.plot(SIZES, SERIAL, \"-o\", label=\"serial\")\nplt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\")\nplt.xlabel(\"Raster width = height (pixels)\")\nplt.ylabel(\"Total runtime: global + local (seconds)\")\nplt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(8, 5)) plt.plot(SIZES, SERIAL, \"-o\", label=\"serial\") plt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\") plt.xlabel(\"Raster width = height (pixels)\") plt.ylabel(\"Total runtime: global + local (seconds)\") plt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\") plt.grid(True) plt.legend() plt.tight_layout() plt.show()"}]}