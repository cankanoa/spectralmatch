{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"spectralmatch: A toolkit to perform Relative Radiometric Normalization, with utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, and statistics","text":"<p>[!IMPORTANT] This library is experimental and still under heavy development.</p>"},{"location":"#overview","title":"Overview","text":"<p>spectralmatch provides a Python library and QGIS plugin with multiple algorythms to perform Relative Radiometric Normalization (RRN). It also includes utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, statistics, preprocessing, and more.</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p>Automated: Works without manual intervention, making it ideal for large-scale applications.</p> </li> <li> <p>Multiprocessing: Image, window, and band parallel processing. Cloud Optimized GeoTIFF reading and writing.</p> </li> <li> <p>Save Intermediate Steps: Save image stats and block maps for quick reprocessing.</p> </li> <li> <p>Specify Model Images Include all or specified images in the matching solution to bring all images to a central tendency or selected images spectral profile.</p> </li> <li> <p>Consistent Multi-Image Analysis: Ensures uniformity across images by applying systematic corrections with minimal spectral distortion.</p> </li> <li> <p>Seamlessly Blended: Creates smooth transitions between images.</p> </li> <li> <p>Unit Agnostic: Works with any pixel unit and preserves the spectral information for accurate analysis. This inlcludes negative numbers and reflectance.</p> </li> <li> <p>Better Input for Machine Learning Models: Provides high-quality, unbiased data for AI and analytical workflows.</p> </li> <li> <p>Sensor Agnostic: Works with all optical sensors. In addition, images from different sensors can be combined for multisensor analysis.</p> </li> <li> <p>Mosaics: Designed to process and blend vast image collections effectively.</p> </li> <li> <p>Time Series: Normalize images across time with to compare spectral changes.</p> </li> </ul>"},{"location":"#current-matching-algorithms","title":"Current Matching Algorithms","text":""},{"location":"#global-to-local-matching","title":"Global to local matching","text":"<p>This technique is derived from 'An auto-adapting global-to-local color balancing method for optical imagery mosaic' by Yu et al., 2017 (DOI: 10.1016/j.isprsjprs.2017.08.002). It is particularly useful for very high-resolution imagery (satellite or otherwise) and works in a two phase process. First, this method applies least squares regression to estimate scale and offset parameters that align the histograms of all images toward a shared spectral center. This is achieved by constructing a global model based on the overlapping areas of adjacent images, where the spectral relationships are defined. This global model ensures that each image conforms to a consistent radiometric baseline while preserving overall color fidelity. However, global correction alone cannot capture intra-image variability so a second local adjustment phase is performed. The overlap areas are divided into smaller blocks, and each block\u2019s mean is used to fine-tune the color correction. This block-wise tuning helps maintain local contrast and reduces visible seams, resulting in seamless and spectrally consistent mosaics with minimal distortion.</p> <p> Shows the average spectral profile of two WorldView 3 images before and after global to local matching.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<ul> <li> <p>Consistent Spectral Profile: The true spectral response of overlapping areas remains the same throughout the images.</p> </li> <li> <p>Least Squares Modeling: A least squares approach can effectively model and fit all images' spectral profiles.</p> </li> <li> <p>Scale and Offset Adjustment: Applying scale and offset corrections can effectively harmonize images.</p> </li> <li> <p>Minimized Color Differences: The best color correction is achieved when color differences are minimized.</p> </li> <li> <p>Geometric Alignment: Images are assumed to be geometrically aligned with known relative positions.</p> </li> <li> <p>Global Consistency: Overlapping color differences are consistent across the entire image.</p> </li> <li> <p>Local Adjustments: Block-level color differences result from the global application of adjustments.</p> </li> </ul>"},{"location":"#quick-installation-other-methods","title":"Quick Installation (Other methods)","text":""},{"location":"#installation-as-a-qgis-plugin","title":"Installation as a QGIS Plugin","text":"<p>Install the spectralmatch plugin in QGIS and use it in the Processing Toolbox.</p>"},{"location":"#installation-as-a-python-library","title":"Installation as a Python Library","text":"<p>Before installing, ensure you have the following system-level prerequisites: <code>Python \u2265 3.10</code>, <code>pip</code>, <code>PROJ \u2265 9.3</code>, and <code>GDAL = 3.10.2</code>. Use this command to install the library:</p> <pre><code>pip install spectralmatch\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at spectralmatch.github.io/spectralmatch/.</p>"},{"location":"#contributing-guide","title":"Contributing Guide","text":"<p>Contributing Guide is available at spectralmatch.github.io/spectralmatch/contributing.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See LICENSE for details.</p>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>Thank you for your interest in contributing. The sections below outline how the library is structured, how to submit changes, and the conventions to follow when developing new features or improving existing functionality.</p>"},{"location":"contributing/#collaboration-instructions","title":"Collaboration Instructions","text":"<p>We welcome all contributions the project! Please be respectful and work towards improving the library. To get started:</p> <ol> <li> <p>Create an issue describing the feature or bug or just to ask a question. Provide relevant context, desired timeline, any assistance needed, who will be responsible for the work, anticipated results, and any other details.</p> </li> <li> <p>Fork the repository and create a new feature branch.</p> </li> <li> <p>Make your changes and add any necessary tests.</p> </li> <li> <p>Open a Pull Request against the main repository.</p> </li> </ol>"},{"location":"contributing/#design-philosophy","title":"Design Philosophy","text":"<ul> <li>Keep code concise and simple</li> <li>Adapt code for large datasets with windows, multiprocessing, progressive computations, etc</li> <li>Keep code modular and have descriptive names</li> <li>Use PEP 8 code formatting</li> <li>Use functions that are already created when possible</li> <li>Combine similar params into one multi-value parameter</li> <li>Use similar naming convention and input parameter format as other functions.</li> <li>Create docstrings (Google style), tests, and update the docs for new functionality</li> </ul>"},{"location":"contributing/#extensible-function-types","title":"Extensible Function Types","text":"<p>In Relative Radiometric Normalization (RRN) methods often differ in how images are matched, pixels are selected, and seamlines are created. This library organizes those into distinct Python packages, while other operations like aligning rasters, applying masks, merging images, and calculating statistics are more consistent across techniques and are treated as standard utilities.</p>"},{"location":"contributing/#matching-functions","title":"Matching functions","text":"<p>Used to adjust the pixel values of images to ensure radiometric consistency across scenes. These functions compute differences between images and apply transformations so that brightness, contrast, or spectral characteristics align across datasets.</p>"},{"location":"contributing/#masking-functions-pifrcs","title":"Masking functions (PIF/RCS)","text":"<p>Used to define which parts of an image should be kept or discarded based on spatial criteria. These functions apply vector-based filters or logical rules to isolate regions of interest, remove clouds, or exclude invalid data from further processing.</p>"},{"location":"contributing/#seamline-functions","title":"Seamline functions","text":"<p>Used to determine optimal boundaries between overlapping image regions. These functions generate cutlines that split image footprints in a way that minimizes visible seams and balances spatial coverage, often relying on geometric relationships between overlapping areas.</p>"},{"location":"contributing/#standard-ui","title":"Standard UI","text":"<p>Reusable types are organized into the types and validation module. Use these types directly as the types of params inside functions where applicable. Use the appropriate _resolve... function to resolve these inputs into usable variables.</p>"},{"location":"contributing/#inputoutput","title":"Input/Output","text":"<p>The input_images parameter accepts either a tuple or a list. If given as a tuple, it should contain a folder path and a glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). Alternatively, it can be a list of full file paths to individual input images. The output_images parameter defines how output filenames are determined. It can also be a tuple, consisting of an output folder and a filename template where \"$\" is replaced with each input image\u2019s basename (e.g., (\"/output/folder\", \"$_GlobalMatch.tif\")). Alternatively, it may be a list of full output paths, which must match the number of input images. <pre><code># Params\ninput_images\noutput_images\n\n# Types\nSearchFolderOrListFiles = Tuple[str, str] | List[str] # Required\nCreateInFolderOrListFiles = Tuple[str, str] | List[str] # Required\n\n# Resolve\ninput_image_paths = _resolve_paths(\"search\", input_images)\noutput_image_paths = _resolve_paths(\"create\", output_images, (input_image_paths,))\n</code></pre></p>"},{"location":"contributing/#nodata-value","title":"Nodata Value","text":"<p>The output_dtype parameter specifies the data type for output rasters and defaults to the input image\u2019s data type if not provided or None. Functions should begin by printing \"Start {process name}\", while all other print statements should be conditional on debug_logs being True. <pre><code># Param\ncustom_nodata_value\n\n# Type\nDebugLogs = bool # Default: False\n\n# No resolve function necessary\n</code></pre></p>"},{"location":"contributing/#debug-logs","title":"Debug Logs","text":"<p>The debug_logs parameter enables printing of debug information and constraint matrices when set to True; it defaults to False. <pre><code># Param\ndebug_logs\n\n# Type\nDebugLogs = bool # Default: False\n\n# No resolve function necessary\n</code></pre></p>"},{"location":"contributing/#vector-mask","title":"Vector Mask","text":"<p>The vector_mask parameter limits statistics calculations to specific areas and is given as a tuple with two or three items: a literal \"include\" or \"exclude\" to define how the mask is applied, a string path to the vector file, and an optional field name used to match geometries based on the input image name (substring match allowed). Defaults to None for no mask.</p> <pre><code># Param\nvector_mask\n\n# Type\nVectorMask = Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None\n\n# No resolve function necessary\n</code></pre>"},{"location":"contributing/#parallel-workers","title":"Parallel Workers","text":"<p>The image_parallel_workers parameter defines the parallelization strategy at the image level. It accepts a tuple such as (\"process\", \"cpu\") to enable multiprocessing across all available CPU cores, or you can use \"thread\" as the backend if threading is preferred. Set it to None to disable image-level parallelism. The window_parallel_workers parameter controls parallelization within each image at the window level and follows the same format. Setting it to None disables window-level parallelism. Processing windows should be done one band at a time for scalability. <pre><code># Params\nimage_parallel_workers\nwindow_parallel_workers\n\n# Types\nImageParallelWorkers = Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None\nWindowParallelWorkers = Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None\n\n# Resolve\nimage_parallel, image_backend, image_max_workers = _resolve_parallel_config(image_parallel_workers)\nwindow_parallel, window_backend, window_max_workers = _resolve_parallel_config(window_parallel_workers)\n</code></pre></p>"},{"location":"contributing/#windows","title":"Windows","text":"<p>The window_size parameter sets the tile size for reading and writing, using an integer for square tiles, a tuple for custom dimensions, \"internal\" to use the raster\u2019s native tiling (ideal for efficient streaming from COGs), or None to process the full image at once. <pre><code># Param\nwindow_size\n\n# Types\nWindowSize = int | Tuple[int, int] | Literal[\"internal\"] | None\nWindowSizeWithBlock = int | Tuple[int, int] | Literal[\"internal\", \"block\"] | None\n\n# Resolve\nwindows = _resolve_windows(rasterio.DatasetReader, window_size)\n</code></pre></p>"},{"location":"contributing/#cogs","title":"COGs","text":"<p>The save_as_cog parameter, when set to True, saves the output as a Cloud-Optimized GeoTIFF with correct band and block ordering. <pre><code># Param\nSaveAsCog = bool # Default: True\n\n# Type\nSaveAsCog = bool # Default: True\n\n# No resolve function necessary\n</code></pre></p>"},{"location":"contributing/#validate-inputs","title":"Validate Inputs","text":"<p>The validate methods are used to check that input parameters follow expected formats before processing begins. There are different validation methods for different scopes\u2014some are general-purpose (e.g., Universal.validate) and others apply to specific contexts like matching (Match.validate_match). These functions raise clear errors when inputs are misconfigured, helping catch issues early and enforce consistent usage patterns across the library. <pre><code># Validate params example\nUniversal.validate(\n    input_images=input_images,\n    output_images=output_images,\n    vector_mask=vector_mask,\n)\nMatch.validate_match(\n    specify_model_images=specify_model_images,\n    )\n</code></pre></p>"},{"location":"contributing/#file-cleanup","title":"File Cleanup","text":"<p>Temporary generated files can be deleted once they are no longer needed via this command: <pre><code>make clean\n</code></pre></p>"},{"location":"contributing/#docs","title":"Docs","text":""},{"location":"contributing/#serve-docs-locally","title":"Serve docs locally","text":"<p>Runs a local dev server at http://localhost:8000. <pre><code>make docs-serve\n</code></pre></p>"},{"location":"contributing/#build-static-site","title":"Build static site","text":"<p>Generates the static site into the site/ folder.</p> <pre><code>make docs-build\n</code></pre>"},{"location":"contributing/#deploy-to-github-pages","title":"Deploy to GitHub Pages","text":"<p>Deploys built site using mkdocs gh-deploy. <pre><code>make docs-deploy\n</code></pre></p>"},{"location":"contributing/#versioning","title":"Versioning","text":"<p>Uses git tag to create annotated version tags and push them. This also syncs to Pypi. New versions will be released when the maintainer determines sufficient new functionality has been added. <pre><code>make tag version=1.2.3\n</code></pre></p>"},{"location":"contributing/#code-formatting","title":"Code Formatting","text":"<p>This project uses black for code formatting and ruff for linting.</p>"},{"location":"contributing/#set-up-pre-commit-hooks-recommended","title":"Set Up Pre-commit Hooks (Recommended)","text":"<p>To maintain code consistency use this hook to check and correct code formatting automatically:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>"},{"location":"contributing/#manual-formatting","title":"Manual Formatting","text":"<p>Format code: Automatically formats all Python files with black.</p> <pre><code>make format\n</code></pre> <p>Check formatting: Checks that all code is formatted (non-zero exit code if not). <pre><code>make check-format\n</code></pre></p> <p>Lint code: Runs ruff to catch style and quality issues. <pre><code>make lint\n</code></pre></p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>pytest is used for testing. Tests will automatically be run when merging into main but they can also be run locally via: <pre><code>make test\n</code></pre></p> <p>To test a individual folder or file: <pre><code>make test-file path=path/to/folder_or_file\n</code></pre></p>"},{"location":"formats_and_requirements/","title":"File Formats and Input Requirements","text":""},{"location":"formats_and_requirements/#input-raster-requirements","title":"Input Raster Requirements","text":"<p>Input rasters must meet specific criteria to ensure compatibility during processing. These are checked by _check_raster_requirements():</p> <ul> <li>Have a valid geotransform</li> <li>Share the same coordinate reference system (CRS)</li> <li>Have an identical number of bands</li> <li>Use consistent nodata values</li> </ul> <p>Additionally, all rasters should:</p> <ul> <li>Be a <code>.tif</code> file</li> <li>Have overlap which represents the same data in each raster</li> <li>Have a consistent spectral profile </li> </ul>"},{"location":"formats_and_requirements/#regression-parameters-file","title":"Regression Parameters File","text":"<p>Regression parameters can be stored in a <code>json</code> file which includes:</p> <ul> <li>Adjustments: Per-band scale and offset values applied to each image.</li> <li>Whole Stats: Per-band mean, std, and size representing overall image statistics.</li> <li>Overlap Stats: Per-image pair mean, std, and size for overlapping geometry regions.</li> </ul> <p>The structure is a dictionary keyed by images basenames (no extension) with the following format:</p> <p><pre><code>{\n  \"image_name\": {\n    \"adjustments\": {\n      \"band_0\": {\"scale\": float, \"offset\": float},\n      ...\n    },\n    \"whole_stats\": {\n      \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n      ...\n    },\n    \"overlap_stats\": {\n      \"other_image\": {\n        \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n        ...\n      },\n      ...\n    }\n  },\n  ...\n}\n</code></pre> This format represents the following: For each image_name there are adjustment, whole_stats and overlap_stats. For each adjustments, for each band, there is scale and offset. For each whole_stats and overlap_stats, for each band, there is mean, std, and size (number of pixels). Each band key follows the format band_0, band_1, etc. Mean and std are floats and size is an integer.</p> <p>This structure is validated by <code>_validate_adjustment_model_structure()</code> before use to ensure consistency and completeness across images and bands. Global regression does not actually use 'adjustments' field because they are recalculated every run.</p>"},{"location":"formats_and_requirements/#block-maps-file","title":"Block Maps File","text":"<p>Block maps are spatial summaries of raster data, where each block represents the mean values of a group of pixels over a fixed region. They are used to reduce image resolution while preserving local radiometric characteristics, enabling efficient comparison and adjustment across images. Each map is structured as a grid of blocks with values for each spectral band. They can be saved as regular <code>geotif</code> files and together store this information: block_local_means, block_reference_mean, num_row, num_col, bounds_canvas_coords. </p> <p>There are two types of block maps, although their format is exactly the same:</p> <ul> <li>Local Block Map: Each block stores the mean value of all pixels within its boundary for a single image.</li> <li>Reference Block Map: Each block is the mean of all images means for its boundary; simply the mean of all local block maps.</li> </ul> <p>Both block maps have the shape: <code>num_row, num_col, num_bands</code>, however, there are multiple (one for each image) local block maps and only one reference block map. Once a reference block map is created it is unique to its input images and cannot be accurately modified to add additional images. However, images can be 'brought' to a reference block map even if they were not involved in its creation as long as it covers that image.</p>"},{"location":"installation/","title":"Installation Methods","text":""},{"location":"installation/#installation-as-qgis-plugin-for-easy-gui-interface","title":"Installation as QGIS Plugin for Easy GUI Interface","text":""},{"location":"installation/#1-download-and-install-qgis","title":"1. Download and install QGIS","text":""},{"location":"installation/#2-open-qgis","title":"2.  Open QGIS","text":""},{"location":"installation/#3-go-to-plugins-manage-and-install-plugins","title":"3.  Go to Plugins \u2192 Manage and Install Plugins\u2026","text":""},{"location":"installation/#4-find-spectralmatch-in-the-list-install-and-enable-it","title":"4.  Find spectralmatch in the list, install, and enable it","text":""},{"location":"installation/#5-find-the-plugin-in-the-processing-toolbox","title":"5.  Find the plugin in the Processing Toolbox","text":""},{"location":"installation/#installation-as-a-python-library-for-use-in-code-recommended","title":"Installation as a Python Library for use in Code (Recommended)","text":""},{"location":"installation/#1-system-requirements","title":"1. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL = 3.10.2</li> <li>pip</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python=3.10 \"gdal=3.10.2\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"installation/#2-install-spectralmatch","title":"2. Install spectralmatch","text":"<p>You can automatically install the library via PyPI. (this method installs only the core code as a library):</p> <pre><code>pip install spectralmatch\n</code></pre>"},{"location":"installation/#3-run-an-example-and-modify-for-your-use-optional","title":"3. Run an example and modify for your use (optional)","text":"<p>Example scripts are provided to verify a successful installation and help you get started quickly in the repository at <code>/docs/examples</code> and downloadable via this <code>link</code>.</p>"},{"location":"installation/#installation-as-python-code-for-development-and-customization","title":"Installation as Python Code for Development and Customization","text":""},{"location":"installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\n</code></pre> <p>Assuming you have Make installed, you can then run <code>make install-setup</code> to automatically complete the remaining setup steps.</p>"},{"location":"installation/#2-system-requirements","title":"2. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL = 3.10.2</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python=3.10 \"gdal=3.10.2\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"installation/#3-install-dependancies-optional-dev-and-docs-dependancies","title":"3. Install Dependancies (Optional Dev and Docs Dependancies)","text":"<p>The <code>pyproject.toml</code> defines core dependancies to run the library and optional dev, and docs dependancies.</p> <pre><code>pip install . # normal dependencies\npip install -e \".[dev]\"   # developer dependencies\npip install -e \".[docs]\"  # documentation dependencies\n</code></pre>"},{"location":"installation/#4-read-the-contributing-guide-if-you-aim-to-contribute","title":"4. Read the Contributing Guide if you aim to contribute","text":""},{"location":"rrn_methods/","title":"Dimensions of Relative Radiometric Normalization (RRN) Methods","text":"<p>RRN methods differ not only in the algorithms used to adjust image values but also in the requirements images must have and other techniques that can be used in conjunction. The following taxonomy summarizes the core dimensions along which RRN techniques vary:</p> <ul> <li>Matching algorithm: The core transformation applied to align radiometry between images.</li> <li>Geometric alignment required: The level of spatial alignment necessary for the method.</li> <li>Pixel selection (PIFs/RCS): How pseudo-invariant features/control sets are identified.</li> <li>Adjustment scope: How corrections are applied to the images.</li> <li>Overlap: Whether the method requires overlapping pixels.</li> <li>Pixel units: The radiometric units the method is able to operate on.</li> <li>Bands: Whether bands relationships are preserved.</li> <li>Target reference: What the target image is normalized to.</li> </ul> <p>Multiple matching algorithms can be used in conjunction with multiple pixel selection methods. Note that the most restrictive method will dictate the image requirements (e.g. if using <code>Global regression</code> with <code>Overlapping area</code> the <code>Geometric alignment</code> will need to be <code>Moderate</code>). The specific matching algorithm used in each method is flexible and not fixed; it may involve least squares, RANSAC, Theil\u2013Sen, Huber, or other forms of robust regression.</p>"},{"location":"rrn_methods/#matching-algorithms","title":"Matching Algorithms","text":"Matching algorithm Description Geometric alignment Adjustment granularity Applies Overlap required Pixel units Bands Target reference Year introduced Key papers Software Histogram Matching (HM) Matches histogram distributions between images None Global Lookup table no Any Independent Reference histogram 1980s ENVI; HistMatch QGIS Plugin; ArcGIS Pro; IMAGINE Mosaic Pro; landsat R library via histmatch() Minimum\u2013Maximum Scale Normalization Linearly scales pixel values to match reference min/max None Global Min/max No Any Independent Reference min/max 1980s Mean\u2013Standard Deviation Regression Fits linear regression using mean and std dev None Global Gain/offset No Any Independent/Correlated Reference mean/std 1980s ArcGIS Pro; spectralmatch Python library and QGIS plugin Overlaping pixel-wise Linear Regression Fits linear regression using overlapping pairs of pixels Co-registered Model Gain/offset Yes Any Independent/Correlated Reference image pixels 1980s ArcGIS Pro; landsat R library via relnorm() Block adjusted gamma correction Adjusts local brightness via block-based gamma scaling Moderate Blocks/interpolation resolution Power function Yes Any Independent Reference block map (mean of local blocks) spectralmatch Python library and QGIS plugin CCA/KCCA-Based Finding the most correlated combinations between images Co-registered CCA space resolution Matrix Yes Any Correlated Reference canonical components Dodging Smooths brightness using low-pass filtering to reduce lighting artifacts Co-registered Blur resolution Low-pass brightness correction Yes Any Independent Blur created brightness values ArcGIS Pro; IMAGINE Mosaic Pro Illumination Equalization Models and removes large-scale illumination differences across images Co-registered Surface model resolution Modeled lighting correction Yes Any Independent Computed illumination values IMAGINE Mosaic Pro Wavelet reconstruction Uses ancillary data to model and reconstruct image values at multiple detail levels Co-registered Ancillary data resolution Decomposition/reconstruction Yes Any Correlated Ancillary data (Gan et al., 2021) Dual-reference affine interpolation Models corrections from the two nearest reference images and applies temporally weighted interpolation Co-registered Model Gain/offset Yes Any Independent Two closest high-quality reference images 2020 (Hessel et al., 2020) rrn-multisensor-multidate Python scripts"},{"location":"rrn_methods/#pixel-selection","title":"Pixel Selection","text":"Pixel selection (PIFs/RCS) Description Type Geometric alignment Overlap required Pixel units Year introduced Key papers Software Whole image Uses all pixels without selection or masking None None No Any Overlapping area Uses only pixels in the spatial overlap between images None Moderate Yes Any Manual polygons or pixels User-defined areas or points chosen as invariant Manual None No Any Manual threshold Selects pixels based on value threshold Threshold None No Any Dark/Bright Set (DB) Selects darkest and brightest pixels assumed to be invariant Threshold None No Any/reflectance may perform better NDVI ratio Uses vegetation indices to isolate vegetated areas for normalization Band ratio None No Reflectance spectralmatch Python library and QGIS plugin K-T ratio Uses the Kauth\u2013Thomas transformation to identify invariant pixels in greenness\u2013brightness space Band ratio None No Reflectance (Hall et al., 1991) landsat R library via RCS() Urban materials ratio Assumes that certain man-made surfaces (e.g., roads, rooftops) have stable reflectance over time and uses their statistical properties to correct radiometric differences Band ratio None No Reflectance 1988 (Schott et al., 1988) landsat R library via PIF() No-change  Scattergrams\u00a0(NC) Selects pixels near the scatterplot diagonal where reference and target values match closely Statistical Co-registered Yes Any (De Carvalho et al., 2013) Multivariate Alteration Detection (MAD) Identifies invariant pixels by transforming image differences into uncorrelated components; selects pixels with minimal change across all bands Statistical Co-registered Yes Any Iteratively Reweighted MAD (IR-MAD) Refines MAD by reweighting pixels to improve change detection Statistical Co-registered Yes Any (Canty &amp; Nielsen, 2008) ArrNorm Python scripts Multi-Rule-Based Normalization Combines several selection rules to identify invariant pixels Statistical None No Any PCA Uses principal component analysis to identify pseudo-invariant pixels along the major axis of multitemporal scatterplots Statistical Co-registered Yes Any 2002 (Du et al., 2002) Gradient angle similarity Selecting the 10% of pixels with the smallest gradient angle differences between an image and its reference Statistical Co-registered Yes Any 2020 (Hessel et al., 2020) rrn-multisensor-multidate Python scripts Feature-Based (Keypoint) RRN Matches distinctive features between images and uses their correspondence to guide normalization Geometric Moderate Yes Any Location-Independent RRN (LIRRN) Groups pixels by brightness or spectral similarity, then matches these groups between images to perform group-wise normalization Geometric Moderate Yes Any 2024 (Maghimi et al., 2024) LIRRN MATLAB scripts"},{"location":"api/handlers/","title":"Data Handlers for IO","text":""},{"location":"api/handlers/#spectralmatch.handlers.create_paths","title":"<code>create_paths(output_folder, template, paths_or_bases, debug_logs=False, replace_symbol='$', create_folders=True)</code>","text":"<p>Create output paths using a filename template and a list of reference paths or names.</p> <p>Parameters:</p> Name Type Description Default <code>output_folder</code> <code>str</code> <p>Directory to store output files.</p> required <code>template</code> <code>str</code> <p>Filename template using replace_symbol as placeholder (e.g., \"$_processed.tif\").</p> required <code>paths_or_bases</code> <code>List[str]</code> <p>List of full paths or bare names to derive replace_symbol from. Inclusion of '/' or '' indicates a path.</p> required <code>debug_logs</code> <code>bool</code> <p>Whether to print the created paths.</p> <code>False</code> <code>replace_symbol</code> <code>str</code> <p>Symbol to replace in the template.</p> <code>'$'</code> <code>create_folders</code> <code>bool</code> <p>Whether to create output folders if they don't exist.'</p> <code>True</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of constructed file paths.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def create_paths(\n    output_folder: str,\n    template: str,\n    paths_or_bases: List[str],\n    debug_logs: bool = False,\n    replace_symbol: str = \"$\",\n    create_folders: bool = True,\n    ) -&gt; List[str]:\n    \"\"\"\n    Create output paths using a filename template and a list of reference paths or names.\n\n    Args:\n        output_folder (str): Directory to store output files.\n        template (str): Filename template using replace_symbol as placeholder (e.g., \"$_processed.tif\").\n        paths_or_bases (List[str]): List of full paths or bare names to derive replace_symbol from. Inclusion of '/' or '\\' indicates a path.\n        debug_logs (bool): Whether to print the created paths.\n        replace_symbol (str): Symbol to replace in the template.\n        create_folders (bool): Whether to create output folders if they don't exist.'\n\n    Returns:\n        List[str]: List of constructed file paths.\n    \"\"\"\n    output_paths = []\n    for ref in paths_or_bases:\n        base = os.path.splitext(os.path.basename(ref))[0] if ('/' in ref or '\\\\' in ref) else os.path.splitext(ref)[0]\n        filename = template.replace(replace_symbol, base)\n        path = os.path.join(output_folder, filename)\n        output_paths.append(path)\n\n    if create_folders:\n        for path in output_paths:\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n    return output_paths\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.match_paths","title":"<code>match_paths(input_match_paths, reference_paths, match_regex, debug_logs=False)</code>","text":"<p>Match <code>reference_paths</code> to <code>input_match_paths</code> using a regex applied to the basenames of <code>input_match_paths</code>. The extracted key must be a substring of the reference filename.</p> <p>Parameters:</p> Name Type Description Default <code>input_match_paths</code> <code>List[str]</code> <p>List of candidate paths to extract keys from.</p> required <code>reference_paths</code> <code>List[str]</code> <p>List of reference paths to align to.</p> required <code>match_regex</code> <code>str</code> <p>Regex applied to basenames of input_match_paths to extract a key to match via inclusion in reference_paths (e.g. r\"(.*)_LocalMatch.gpkg$\").</p> required <code>debug_logs</code> <code>bool</code> <p>If True, print matched and unmatched file basenames.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[Optional[str]]</code> <p>List[Optional[str]]: A list the same length as <code>reference_paths</code> where each</p> <code>List[Optional[str]]</code> <p>element is the matched path from <code>input_match_paths</code> or None.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If output list length does not match reference_paths length.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def match_paths(\n    input_match_paths: List[str],\n    reference_paths: List[str],\n    match_regex: str,\n    debug_logs: bool = False,\n    ) -&gt; List[Optional[str]]:\n    \"\"\"\n    Match `reference_paths` to `input_match_paths` using a regex applied to the basenames of `input_match_paths`. The extracted key must be a substring of the reference filename.\n\n    Args:\n        input_match_paths (List[str]): List of candidate paths to extract keys from.\n        reference_paths (List[str]): List of reference paths to align to.\n        match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via *inclusion* in reference_paths (e.g. r\\\"(.*)_LocalMatch\\.gpkg$\").\n        debug_logs (bool): If True, print matched and unmatched file basenames.\n\n    Returns:\n        List[Optional[str]]: A list the same length as `reference_paths` where each\n        element is the matched path from `input_match_paths` or None.\n\n    Raises:\n        ValueError: If output list length does not match reference_paths length.\n    \"\"\"\n    pattern = re.compile(match_regex)\n    match_keys = {}\n    used_matches = set()\n\n    # Extract keys from input_match_paths\n    for mpath in input_match_paths:\n        basename = os.path.basename(mpath)\n        match = pattern.search(basename)\n        if not match:\n            continue\n        key = match.group(1) if match.groups() else match.group(0)\n        match_keys[key] = mpath\n\n    # Match each reference path\n    matched_list: List[Optional[str]] = []\n    for rpath in reference_paths:\n        rbase = os.path.basename(rpath)\n        matched = None\n        for key, mpath in match_keys.items():\n            if key in rbase:\n                matched = mpath\n                used_matches.add(mpath)\n                break\n        matched_list.append(matched)\n\n    # Validate output length\n    if len(matched_list) != len(reference_paths):\n        raise ValueError(\"Matched list length does not match reference_paths length.\")\n\n    return matched_list\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.search_paths","title":"<code>search_paths(folder_path, pattern, recursive=False, match_to_paths=None, debug_logs=False)</code>","text":"<p>Search for files in a folder using a glob pattern.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>The root folder to search in.</p> required <code>pattern</code> <code>str</code> <p>A glob pattern (e.g., \".tif\", \"/.jpg\").</p> required <code>recursive</code> <code>bool</code> <p>Whether to search for files recursively.</p> <code>False</code> <code>match_to_paths</code> <code>Tuple[List[str], str]</code> <p>If provided, match <code>reference_paths</code> to <code>input_match_paths</code> using a regex applied to the basenames of <code>input_match_paths</code>. The extracted key must be a substring of the reference filename. - reference_paths (List[str]): List of reference paths to align to. - match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via inclusion in reference_paths (e.g. \"(.*)_LocalMatch.gpkg$\").</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Whether to print the matched file paths.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: Sorted list of matched file paths.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def search_paths(\n    folder_path: str,\n    pattern: str,\n    recursive: bool = False,\n    match_to_paths: Tuple[List[str], str] | None = None,\n    debug_logs: bool = False,\n    ) -&gt; List[str]:\n    \"\"\"\n    Search for files in a folder using a glob pattern.\n\n    Args:\n        folder_path (str): The root folder to search in.\n        pattern (str): A glob pattern (e.g., \"*.tif\", \"**/*.jpg\").\n        recursive (bool, optional): Whether to search for files recursively.\n        match_to_paths (Tuple[List[str], str], optional): If provided, match `reference_paths` to `input_match_paths` using a regex applied to the basenames of `input_match_paths`. The extracted key must be a substring of the reference filename.\n            - reference_paths (List[str]): List of reference paths to align to.\n            - match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via *inclusion* in reference_paths (e.g. \"(.*)_LocalMatch.gpkg$\").\n        debug_logs (bool, optional): Whether to print the matched file paths.\n\n    Returns:\n        List[str]: Sorted list of matched file paths.\n    \"\"\"\n    input_paths =  sorted(glob.glob(os.path.join(folder_path, pattern), recursive=recursive))\n\n    if match_to_paths:\n        input_paths = match_paths(input_paths, *match_to_paths)\n\n    return input_paths\n</code></pre>"},{"location":"api/mask/","title":"Create Mask and Pseudo-Invariant Features","text":""},{"location":"api/mask/#spectralmatch.mask.mask.create_cloud_mask_with_omnicloudmask","title":"<code>create_cloud_mask_with_omnicloudmask(input_image_path, red_band_index, green_band_index, nir_band_index, output_mask_path, down_sample_m=None, debug_logs=False, **omnicloud_kwargs)</code>","text":"<p>Generates a cloud mask using OmniCloudMask from a multi-band image.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input image.</p> required <code>red_band_index</code> <code>int</code> <p>Index of the red band.</p> required <code>green_band_index</code> <code>int</code> <p>Index of the green band.</p> required <code>nir_band_index</code> <code>int</code> <p>Index of the NIR (or substitute blue) band.</p> required <code>output_mask_path</code> <code>str</code> <p>Path to save the output cloud mask GeoTIFF.</p> required <code>down_sample_m</code> <code>float</code> <p>Target resolution (in meters) to downsample the input before processing.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Debug logs to console.</p> <code>False</code> <code>omnicloud_kwargs</code> <code>Any</code> <p>Forwards key word args to OmniCloudMask predict_from_array() function. Repo here: https://github.com/DPIRD-DMA/OmniCloudMask.</p> <code>{}</code> Outputs <p>Saves a single-band cloud mask GeoTIFF at the specified path.</p> Source code in <code>spectralmatch/mask/mask.py</code> <pre><code>def create_cloud_mask_with_omnicloudmask(\n    input_image_path,\n    red_band_index,\n    green_band_index,\n    nir_band_index, # Blue band can work if nir isnt available\n    output_mask_path,\n    down_sample_m=None, # Down sample to 10 m if imagery has a spatial resolution &lt; 10 m\n    debug_logs: bool = False,\n    **omnicloud_kwargs: Any,\n    ):\n    \"\"\"\n    Generates a cloud mask using OmniCloudMask from a multi-band image.\n\n    Args:\n        input_image_path (str): Path to the input image.\n        red_band_index (int): Index of the red band.\n        green_band_index (int): Index of the green band.\n        nir_band_index (int): Index of the NIR (or substitute blue) band.\n        output_mask_path (str): Path to save the output cloud mask GeoTIFF.\n        down_sample_m (float, optional): Target resolution (in meters) to downsample the input before processing.\n        debug_logs (bool, optional): Debug logs to console.\n        omnicloud_kwargs: Forwards key word args to OmniCloudMask predict_from_array() function. Repo here: https://github.com/DPIRD-DMA/OmniCloudMask.\n\n    Outputs:\n        Saves a single-band cloud mask GeoTIFF at the specified path.\n    \"\"\"\n\n    print(\"Start create omnicloudmask\")\n    if not os.path.exists(os.path.dirname(output_mask_path)): os.makedirs(os.path.dirname(output_mask_path), exist_ok=True)\n    with rasterio.open(input_image_path) as src:\n        if down_sample_m is not None:\n            # Compute new dimensions based on the image bounds and the desired resolution.\n            left, bottom, right, top = src.bounds\n            new_width = int((right - left) / down_sample_m)\n            new_height = int((top - bottom) / down_sample_m)\n            new_transform = from_origin(left, top, down_sample_m, down_sample_m)\n            # Read the bands with resampling to the new size.\n            red   = src.read(red_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            green = src.read(green_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            nir   = src.read(nir_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            meta = src.meta.copy()\n            meta.update({\n                'width': new_width,\n                'height': new_height,\n                'transform': new_transform,\n            })\n        else:\n            # Read without resampling.\n            red   = src.read(red_band_index)\n            green = src.read(green_band_index)\n            nir   = src.read(nir_band_index)\n            meta = src.meta.copy()\n\n        # Stack bands into an array of shape (3, height, width).\n        band_array = np.stack([red, green, nir], axis=0)\n\n    # Predict the mask (expected shape: (1, height, width))\n    pred_mask = predict_from_array(band_array, **omnicloud_kwargs)\n    pred_mask = np.squeeze(pred_mask)\n\n    # Update metadata for a single-band output.\n    meta.update({\n        'driver': 'GTiff',\n        'count': 1,\n        'dtype': pred_mask.dtype,\n        'nodata': 0,\n    })\n\n    # Write the predicted mask to a GeoTIFF file.\n    with rasterio.open(output_mask_path, 'w', **meta) as dst:\n        dst.write(pred_mask, 1)\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.mask.create_ndvi_mask","title":"<code>create_ndvi_mask(input_image_path, output_image_path, nir_band, red_band)</code>","text":"<p>Computes NDVI from a multi-band image and saves the result as a GeoTIFF.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input image with NIR and red bands.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the NDVI output GeoTIFF.</p> required <code>nir_band</code> <code>int</code> <p>Band index for NIR (1-based).</p> required <code>red_band</code> <code>int</code> <p>Band index for red (1-based).</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the saved NDVI output.</p> Source code in <code>spectralmatch/mask/mask.py</code> <pre><code>def create_ndvi_mask(\n    input_image_path: str,\n    output_image_path: str,\n    nir_band: int,\n    red_band: int,\n    ) -&gt; str:\n    \"\"\"\n    Computes NDVI from a multi-band image and saves the result as a GeoTIFF.\n\n    Args:\n        input_image_path (str): Path to the input image with NIR and red bands.\n        output_image_path (str): Path to save the NDVI output GeoTIFF.\n        nir_band (int): Band index for NIR (1-based).\n        red_band (int): Band index for red (1-based).\n\n    Returns:\n        str: Path to the saved NDVI output.\n    \"\"\"\n\n    print(\"Start ndvi computation\")\n    if not os.path.exists(os.path.dirname(output_image_path)): os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n\n    with rasterio.open(input_image_path) as src:\n        nir = src.read(nir_band).astype(np.float32)\n        red = src.read(red_band).astype(np.float32)\n        ndvi = (nir - red) / (nir + red + 1e-9)\n\n        print(\"NIR min/max:\", np.nanmin(nir), np.nanmax(nir))\n        print(\"Red min/max:\", np.nanmin(red), np.nanmax(red))\n        print(\"NDVI min/max:\", np.nanmin(ndvi), np.nanmax(ndvi))\n\n        profile = src.profile\n        profile.update(dtype=rasterio.float32, count=1)\n\n        with rasterio.open(output_image_path, 'w', **profile) as dst:\n            dst.write(ndvi, 1)\n\n    return output_image_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.mask.custom_band_math","title":"<code>custom_band_math(input_images, output_vector_mask, custom_math, threshold=0.5, debug_logs=False)</code>","text":"<p>Applies custom band math expression to raster images and saves result as a vector mask.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>str | list[str] | tuple</code> <p>Path(s) to input raster(s).</p> required <code>output_vector_mask</code> <code>str</code> <p>Path to save the vector mask (GeoPackage or Shapefile).</p> required <code>custom_math</code> <code>str</code> <p>Math expression using b1, b2, ..., e.g., \"(b1 / (b4 + 1e-6)) &gt; 2\".</p> required <code>threshold</code> <code>float</code> <p>Threshold to convert result to a binary mask if expression is continuous.</p> <code>0.5</code> <code>debug_logs</code> <code>bool</code> <p>Print debug logs if True.</p> <code>False</code> Source code in <code>spectralmatch/mask/mask.py</code> <pre><code>def custom_band_math(\n    input_images,\n    output_vector_mask: str,\n    custom_math: str,\n    threshold: float = 0.5,\n    debug_logs: bool = False,\n):\n    \"\"\"\n    Applies custom band math expression to raster images and saves result as a vector mask.\n\n    Args:\n        input_images (str | list[str] | tuple): Path(s) to input raster(s).\n        output_vector_mask (str): Path to save the vector mask (GeoPackage or Shapefile).\n        custom_math (str): Math expression using b1, b2, ..., e.g., \"(b1 / (b4 + 1e-6)) &gt; 2\".\n        threshold (float): Threshold to convert result to a binary mask if expression is continuous.\n        debug_logs (bool): Print debug logs if True.\n    \"\"\"\n    # Resolve input path\n    path = input_images if isinstance(input_images, str) else input_images[0]\n    with rasterio.open(path) as src:\n        bands = [src.read(i + 1) for i in range(src.count)]\n        profile = src.profile\n        transform = src.transform\n        crs = src.crs\n\n    # Prepare band variables (b1, b2, ...) for eval\n    band_vars = {f\"b{i+1}\": band.astype(np.float32) for i, band in enumerate(bands)}\n\n    if debug_logs:\n        print(f\"Evaluating: {custom_math}\")\n\n    try:\n        result = eval(custom_math, {\"np\": np}, band_vars)\n    except Exception as e:\n        raise ValueError(f\"Failed to evaluate expression '{custom_math}': {e}\")\n\n    if result.dtype != bool:\n        result = result &gt; threshold\n\n    result = result.astype(np.uint8)\n\n    # Polygonize the mask\n    mask_shapes = (\n        (shape(geom), val)\n        for geom, val in shapes(result, mask=result == 1, transform=transform)\n    )\n\n    schema = {\"geometry\": \"Polygon\", \"properties\": {\"value\": \"int\"}}\n    os.makedirs(os.path.dirname(output_vector_mask), exist_ok=True)\n    with fiona.open(output_vector_mask, \"w\", driver=\"GPKG\", schema=schema, crs=crs) as dst:\n        for geom, val in mask_shapes:\n            dst.write({\"geometry\": mapping(geom), \"properties\": {\"value\": int(val)}})\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.mask.post_process_raster_cloud_mask_to_vector","title":"<code>post_process_raster_cloud_mask_to_vector(input_image_path, output_vector_path, minimum_mask_size_percentile=None, polygon_buffering_in_map_units=None, value_mapping=None)</code>","text":"<p>Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input cloud mask raster.</p> required <code>output_vector_path</code> <code>str</code> <p>Path to the output vector layer.</p> required <code>minimum_mask_size_percentile</code> <code>float</code> <p>Percentile threshold to filter small polygons by area.</p> <code>None</code> <code>polygon_buffering_in_map_units</code> <code>dict</code> <p>Mapping of raster values to buffer distances.</p> <code>None</code> <code>value_mapping</code> <code>dict</code> <p>Mapping of original raster values to new values before vectorization.</p> <code>None</code> Outputs <p>Saves a vector layer to the output path.</p> Source code in <code>spectralmatch/mask/mask.py</code> <pre><code>def post_process_raster_cloud_mask_to_vector(\n    input_image_path: str,\n    output_vector_path: str,\n    minimum_mask_size_percentile: float = None,\n    polygon_buffering_in_map_units: dict = None,\n    value_mapping: dict = None\n    ) -&gt; ogr.DataSource:\n    \"\"\"\n    Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.\n\n    Args:\n        input_image_path (str): Path to the input cloud mask raster.\n        output_vector_path (str): Path to the output vector layer.\n        minimum_mask_size_percentile (float, optional): Percentile threshold to filter small polygons by area.\n        polygon_buffering_in_map_units (dict, optional): Mapping of raster values to buffer distances.\n        value_mapping (dict, optional): Mapping of original raster values to new values before vectorization.\n\n    Outputs:\n        Saves a vector layer to the output path.\n    \"\"\"\n\n    print(\"Start post-processing raster cloud mask\")\n    with rasterio.open(input_image_path) as src:\n        raster_data = src.read(1)\n        transform = src.transform\n        crs = src.crs\n\n    if value_mapping is not None:\n        include_mask = np.full(raster_data.shape, True, dtype=bool)\n        mapped = np.copy(raster_data)\n        for orig_value, new_value in value_mapping.items():\n            if new_value is None:\n                include_mask &amp;= raster_data != orig_value  # Exclude from processing\n            else:\n                mapped[raster_data == orig_value] = new_value\n        raster_data = mapped\n    else:\n        include_mask = None\n\n    results = (\n        {'properties': {'value': v}, 'geometry': s}\n        for s, v in shapes(raster_data, mask=include_mask, transform=transform, connectivity=4)\n    )\n    features = list(results)\n    if not features:\n        print(\"No features were detected in the raster mask.\")\n        return None\n\n\n    gdf = gpd.GeoDataFrame.from_features(features, crs=crs)\n\n    gdf['area'] = gdf.geometry.area\n    if minimum_mask_size_percentile is not None:\n        area_threshold = np.percentile(gdf['area'], minimum_mask_size_percentile)\n        print(f\"Area threshold (at {minimum_mask_size_percentile}th percentile): {area_threshold:.2f}\")\n        gdf = gdf[gdf['area'] &gt;= area_threshold].copy()\n\n    if polygon_buffering_in_map_units is not None:\n        gdf['geometry'] = gdf.apply(\n            lambda row: row['geometry'].buffer(polygon_buffering_in_map_units.get(row['value'], 0))\n            if row['value'] in polygon_buffering_in_map_units else row['geometry'],\n            axis=1\n        )\n\n    merged_features = []\n    for val, group in gdf.groupby('value'):\n        # Use union_all() to merge the geometries within the group.\n        # (Requires Shapely 2.0 or later; otherwise use shapely.ops.unary_union on group.geometry.tolist())\n        union_geom = group.geometry.union_all()\n        # If the union produces a single Polygon, add it directly;\n        # if it produces a MultiPolygon, split it into individual features.\n        if union_geom.geom_type == 'Polygon':\n            merged_features.append({'value': val, 'geometry': union_geom})\n        elif union_geom.geom_type == 'MultiPolygon':\n            for geom in union_geom.geoms:\n                merged_features.append({'value': val, 'geometry': geom})\n        else:\n            # In case of unexpected geometry types, skip or handle accordingly.\n            print(f\"Unexpected geometry type for value {val}: {union_geom.geom_type}\")\n    # Create a new GeoDataFrame from merged features.\n    gdf = gpd.GeoDataFrame(merged_features, crs=gdf.crs)\n\n\n    ogr_driver = ogr.GetDriverByName(\"Memory\")\n    mem_ds = ogr_driver.CreateDataSource(\"in_memory\")\n\n    # Determine an appropriate OGR geometry type using the first feature.\n    first_geom = gdf.geometry.iloc[0]\n    if first_geom.geom_type == \"Polygon\":\n        ogr_geom_type = ogr.wkbPolygon\n    elif first_geom.geom_type == \"MultiPolygon\":\n        ogr_geom_type = ogr.wkbMultiPolygon\n    else:\n        ogr_geom_type = ogr.wkbUnknown\n\n    # Convert the CRS to OGR SpatialReference.\n    sr = osr.SpatialReference()\n    try:\n        sr.ImportFromWkt(crs.to_wkt())\n    except AttributeError:\n        sr.ImportFromEPSG(4326)\n\n    mem_layer = mem_ds.CreateLayer(\"post_processed\", sr, ogr_geom_type)\n\n    # Add attribute field for 'value' (and any other non-geometry columns if needed).\n    # Here we add 'value' for example.\n    field_defn = ogr.FieldDefn(\"value\", ogr.OFTInteger)\n    mem_layer.CreateField(field_defn)\n\n    # Add each row from the GeoDataFrame as an OGR feature.\n    for idx, row in gdf.iterrows():\n        feat = ogr.Feature(mem_layer.GetLayerDefn())\n        ogr_geom = ogr.CreateGeometryFromWkt(row['geometry'].wkt)\n        feat.SetGeometry(ogr_geom)\n        feat.SetField(\"value\", row['value'])\n        mem_layer.CreateFeature(feat)\n        feat = None\n\n    driver = ogr.GetDriverByName(\"GPKG\")\n    if os.path.exists(output_vector_path):\n        driver.DeleteDataSource(output_vector_path)\n    out_ds = driver.CreateDataSource(output_vector_path)\n    out_ds.CopyLayer(mem_layer, \"post_processed\")\n    out_ds = None\n\n    return output_vector_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.mask.post_process_threshold_to_vector","title":"<code>post_process_threshold_to_vector(input_image_path, output_vector_path, threshold_val, operator_str='&lt;=')</code>","text":"<p>Converts a thresholded raster mask to a vector layer using Rasterio and Fiona.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input single-band raster.</p> required <code>output_vector_path</code> <code>str</code> <p>Path to save the output vector file (GeoPackage).</p> required <code>threshold_val</code> <code>float | int</code> <p>Threshold value to apply.</p> required <code>operator_str</code> <code>str</code> <p>One of the comparison operators.</p> <code>'&lt;='</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the saved vector file.</p> Source code in <code>spectralmatch/mask/mask.py</code> <pre><code>def post_process_threshold_to_vector(\n    input_image_path: str,\n    output_vector_path: str,\n    threshold_val: float | int,\n    operator_str: Literal[\"=\", \"&lt;=\", \"&gt;\", \"&gt;=\", \"==\"] = \"&lt;=\",\n    ) -&gt; str:\n    \"\"\"\n    Converts a thresholded raster mask to a vector layer using Rasterio and Fiona.\n\n    Args:\n        input_image_path (str): Path to the input single-band raster.\n        output_vector_path (str): Path to save the output vector file (GeoPackage).\n        threshold_val (float | int): Threshold value to apply.\n        operator_str (str): One of the comparison operators.\n\n    Returns:\n        str: Path to the saved vector file.\n    \"\"\"\n    print(\"Start post process threshold\")\n\n    with rasterio.open(input_image_path) as src:\n        image = src.read(1)\n        transform = src.transform\n        crs = src.crs\n\n        # Apply threshold\n        if operator_str == \"&lt;\":\n            mask = image &lt; threshold_val\n        elif operator_str == \"&lt;=\":\n            mask = image &lt;= threshold_val\n        elif operator_str == \"&gt;\":\n            mask = image &gt; threshold_val\n        elif operator_str == \"&gt;=\":\n            mask = image &gt;= threshold_val\n        elif operator_str == \"==\":\n            mask = image == threshold_val\n        else:\n            raise ValueError(\"Unsupported operator_str\")\n\n        mask = mask.astype(np.uint8)\n\n        # Generate vector shapes\n        results = []\n        for s, v in shapes(mask, mask=mask, transform=transform):\n            if v != 1:\n                continue\n            geom = shape(s)\n            if isinstance(geom, Polygon):\n                results.append({\"properties\": {\"DN\": int(v)}, \"geometry\": mapping(geom)})\n            elif isinstance(geom, MultiPolygon):\n                for part in geom.geoms:\n                    results.append({\"properties\": {\"DN\": int(v)}, \"geometry\": mapping(part)})\n\n        schema = {\n            \"geometry\": \"Polygon\",\n            \"properties\": {\"DN\": \"int\"},\n        }\n\n        if os.path.exists(output_vector_path):\n            os.remove(output_vector_path)\n\n        with fiona.open(\n            output_vector_path, \"w\",\n            driver=\"GPKG\",\n            crs=crs,\n            schema=schema,\n            layer=\"mask\"\n        ) as dst:\n            for feat in results:\n                dst.write(feat)\n\n    return output_vector_path\n</code></pre>"},{"location":"api/match/","title":"Matching Algorithms","text":""},{"location":"api/match/#spectralmatch.match.global_regression.global_regression","title":"<code>global_regression(input_images, output_images, *, calculation_dtype='float32', output_dtype=None, vector_mask=None, debug_logs=False, custom_nodata_value=None, image_parallel_workers=None, window_parallel_workers=None, window_size=None, save_as_cog=False, specify_model_images=None, custom_mean_factor=1.0, custom_std_factor=1.0, save_adjustments=None, load_adjustments=None)</code>","text":"<p>Performs global radiometric normalization across overlapping images using least squares regression.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies the input images either as: - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). - A list of full file paths to individual input images.</p> required <code>output_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies how output filenames are generated or provided: - A tuple with an output folder and a filename template using \"\\(\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"\\)_GlobalMatch.tif\")). - A list of full output paths, which must match the number of input images.</p> required <code>calculation_dtype</code> <code>str</code> <p>Data type used for internal calculations. Defaults to \"float32\".</p> <code>'float32'</code> <code>output_dtype</code> <code>str | None</code> <p>Data type for output rasters. Defaults to input image dtype.</p> <code>None</code> <code>vector_mask</code> <code>Tuple[Literal['include', 'exclude'], str, Optional[str]] | None</code> <p>Mask to limit stats calculation to specific areas in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that includes (can be substring) input image name to filter geometry by. Loaded stats won't have this applied to them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>If True, prints debug information and constraint matrices. Defaults to False.</p> <code>False</code> <code>custom_nodata_value</code> <code>float | int | None</code> <p>Overrides detected NoData value. Defaults to None.</p> <code>None</code> <code>image_parallel_workers</code> <code>Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None</code> <p>Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.</p> <code>None</code> <code>window_parallel_workers</code> <code>Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None</code> <p>Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.</p> <code>None</code> <code>window_size</code> <code>int | Tuple[int, int] | Literal['internal'] | None</code> <p>Tile size for reading and writing: int for square tiles, tuple for (width, height), \"internal\" to use raster's native tiling, or None for full image. \"internal\" enables efficient streaming from COGs.</p> <code>None</code> <code>save_as_cog</code> <code>bool</code> <p>If True, saves output as a Cloud-Optimized GeoTIFF using proper band and block order.</p> <code>False</code> <code>specify_model_images</code> <code>Tuple[Literal['exclude', 'include'], List[str]] | None</code> <p>First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.</p> <code>None</code> <code>custom_mean_factor</code> <code>float</code> <p>Weight for mean constraints in regression. Defaults to 1.0.</p> <code>1.0</code> <code>custom_std_factor</code> <code>float</code> <p>Weight for standard deviation constraints in regression. Defaults to 1.0.</p> <code>1.0</code> <code>save_adjustments</code> <code>str | None</code> <p>The output path of a .json file to save adjustments parameters. Defaults to not saving.</p> <code>None</code> <code>load_adjustments</code> <code>str | None</code> <p>If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List[str]: Paths to the globally adjusted output raster images.</p> Source code in <code>spectralmatch/match/global_regression.py</code> <pre><code>def global_regression(\n    input_images: Universal.SearchFolderOrListFiles,\n    output_images: Universal.CreateInFolderOrListFiles,\n    *,\n    calculation_dtype: Universal.CalculationDtype = \"float32\",\n    output_dtype: Universal.OutputDtype = None,\n    vector_mask: Universal.VectorMask = None,\n    debug_logs: Universal.DebugLogs = False,\n    custom_nodata_value: Universal.CustomNodataValue = None,\n    image_parallel_workers: Universal.ImageParallelWorkers = None,\n    window_parallel_workers: Universal.WindowParallelWorkers = None,\n    window_size: Universal.WindowSize = None,\n    save_as_cog: Universal.SaveAsCog = False,\n    specify_model_images: Match.SpecifyModelImages = None,\n    custom_mean_factor: float = 1.0,\n    custom_std_factor: float = 1.0,\n    save_adjustments: str | None = None,\n    load_adjustments: str | None = None,\n    ) -&gt; list:\n    \"\"\"\n    Performs global radiometric normalization across overlapping images using least squares regression.\n\n    Args:\n        input_images (Tuple[str, str] | List[str]):\n            Specifies the input images either as:\n            - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n            - A list of full file paths to individual input images.\n        output_images (Tuple[str, str] | List[str]):\n            Specifies how output filenames are generated or provided:\n            - A tuple with an output folder and a filename template using \"$\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"$_GlobalMatch.tif\")).\n            - A list of full output paths, which must match the number of input images.\n        calculation_dtype (str, optional): Data type used for internal calculations. Defaults to \"float32\".\n        output_dtype (str | None, optional): Data type for output rasters. Defaults to input image dtype.\n        vector_mask (Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None): Mask to limit stats calculation to specific areas in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that *includes* (can be substring) input image name to filter geometry by. Loaded stats won't have this applied to them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.\n        debug_logs (bool, optional): If True, prints debug information and constraint matrices. Defaults to False.\n        custom_nodata_value (float | int | None, optional): Overrides detected NoData value. Defaults to None.\n        image_parallel_workers (Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.\n        window_parallel_workers (Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.\n        window_size (int | Tuple[int, int] | Literal[\"internal\"] | None): Tile size for reading and writing: int for square tiles, tuple for (width, height), \"internal\" to use raster's native tiling, or None for full image. \"internal\" enables efficient streaming from COGs.\n        save_as_cog (bool): If True, saves output as a Cloud-Optimized GeoTIFF using proper band and block order.\n        specify_model_images (Tuple[Literal[\"exclude\", \"include\"], List[str]] | None ): First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.\n        custom_mean_factor (float, optional): Weight for mean constraints in regression. Defaults to 1.0.\n        custom_std_factor (float, optional): Weight for standard deviation constraints in regression. Defaults to 1.0.\n        save_adjustments (str | None, optional): The output path of a .json file to save adjustments parameters. Defaults to not saving.\n        load_adjustments (str | None, optional): If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.\n\n    Returns:\n        List[str]: Paths to the globally adjusted output raster images.\n    \"\"\"\n\n    print(\"Start global regression\")\n\n    # Validate params\n    Universal.validate(\n        input_images=input_images,\n        output_images=output_images,\n        save_as_cog=save_as_cog,\n        debug_logs=debug_logs,\n        vector_mask=vector_mask,\n        window_size=window_size,\n        custom_nodata_value=custom_nodata_value,\n        image_parallel_workers=image_parallel_workers,\n        window_parallel_workers=window_parallel_workers,\n        calculation_dtype=calculation_dtype,\n        output_dtype=output_dtype,\n    )\n\n    Match.validate_match(\n        specify_model_images=specify_model_images,\n    )\n\n    Match.validate_global_regression(\n        custom_mean_factor=custom_mean_factor,\n        custom_std_factor=custom_std_factor,\n        save_adjustments=save_adjustments,\n        load_adjustments=load_adjustments,\n    )\n\n    # Input and output paths\n    input_image_paths = _resolve_paths(\"search\", input_images)\n    output_image_paths = _resolve_paths(\"create\", output_images, (input_image_paths,))\n\n    if debug_logs: print(f\"Input images: {input_image_paths}\")\n    if debug_logs: print(f\"Output images: {output_image_paths}\")\n\n    input_image_names = [os.path.splitext(os.path.basename(p))[0] for p in input_image_paths]\n    input_image_path_pairs = dict(zip(input_image_names, input_image_paths))\n    output_image_path_pairs = dict(zip(input_image_names, output_image_paths))\n\n    # Check raster requirements\n    _check_raster_requirements(input_image_paths, debug_logs, check_geotransform=True, check_crs=True, check_bands=True, check_nodata=True)\n\n    nodata_val = _get_nodata_value(list(input_image_path_pairs.values()), custom_nodata_value)\n\n    # Determine multiprocessing and worker count\n    image_parallel, image_backend, image_max_workers = _resolve_parallel_config(image_parallel_workers)\n    window_parallel, window_backend, window_max_workers = _resolve_parallel_config(window_parallel_workers)\n\n    # Find loaded and input files if load adjustments\n    loaded_model = {}\n    if load_adjustments:\n        with open(load_adjustments, \"r\") as f:\n            loaded_model = json.load(f)\n        _validate_adjustment_model_structure(loaded_model)\n        loaded_names = set(loaded_model.keys())\n        input_names = set(input_image_names)\n    else:\n        loaded_names = set([])\n        input_names = set(input_image_names)\n\n    matched = input_names &amp; loaded_names\n    only_loaded = loaded_names - input_names\n    only_input = input_names - loaded_names\n    if debug_logs:\n        print(f\"Total images: input images: {len(input_names)}, loaded images {len(loaded_names)}: \")\n        print(f\"    Matched adjustments (to override) ({len(matched)}):\", sorted(matched))\n        print(f\"    Only in loaded adjustments (to add) ({len(only_loaded)}):\", sorted(only_loaded))\n        print(f\"    Only in input (to calculate) ({len(only_input)}):\", sorted(only_input))\n\n    # Find images to include in model\n    included_names = list(matched | only_loaded | only_input)\n    if specify_model_images:\n        mode, names = specify_model_images\n        name_set = set(names)\n        if mode == \"include\":\n            included_names = [n for n in input_image_names if n in name_set]\n        elif mode == \"exclude\":\n            included_names = [n for n in input_image_names if n not in name_set]\n        excluded_names = [n for n in input_image_names if n not in included_names]\n    if debug_logs:\n        print(\"Images to influence the model:\")\n        print(f\"    Included in model ({len(included_names)}): {sorted(included_names)}\")\n        if specify_model_images: print(f\"    Excluded from model ({len(excluded_names)}): {sorted(excluded_names)}\")\n        else: print(f\"    Excluded from model (0): []\")\n\n    if debug_logs: print(\"Calculating statistics\")\n    with rasterio.open(list(input_image_path_pairs.values())[0]) as src: num_bands = src.count\n\n    # Get images bounds\n    all_bounds = {}\n    for name, path in input_image_path_pairs.items():\n        with rasterio.open(path) as ds:\n            all_bounds[name] = ds.bounds\n\n    # Overlap stats\n    overlapping_pairs = _find_overlaps(all_bounds)\n    all_overlap_stats = {}\n\n    # Load overlap stats\n    if load_adjustments:\n        for name_i, model_entry in loaded_model.items():\n            if name_i not in input_image_path_pairs:\n                continue\n\n            for name_j, bands in model_entry.get(\"overlap_stats\", {}).items():\n                if name_j not in input_image_path_pairs:\n                    continue\n\n                all_overlap_stats.setdefault(name_i, {})[name_j] = {\n                    int(k.split(\"_\")[1]): {\n                        \"mean\": bands[k][\"mean\"],\n                        \"std\": bands[k][\"std\"],\n                        \"size\": bands[k][\"size\"]\n                    } for k in bands\n                }\n\n    # Calculate overlap stats\n    parallel_args = [\n        (\n            window_parallel,\n            window_max_workers,\n            window_backend,\n            num_bands,\n            input_image_path_pairs[name_i],\n            input_image_path_pairs[name_j],\n            name_i,\n            name_j,\n            all_bounds[name_i],\n            all_bounds[name_j],\n            nodata_val,\n            nodata_val,\n            vector_mask,\n            window_size,\n            debug_logs,\n        )\n        for name_i, name_j in overlapping_pairs\n        if name_i not in loaded_model or name_j not in loaded_model.get(name_i, {}).get(\"overlap_stats\", {})\n    ]\n\n    if image_parallel:\n        with _get_executor(image_backend, image_max_workers) as executor:\n            futures = [executor.submit(_overlap_stats_process_image, *args) for args in parallel_args]\n            for future in as_completed(futures):\n                stats = future.result()\n                for outer, inner in stats.items():\n                    all_overlap_stats.setdefault(outer, {}).update(inner)\n    else:\n        for args in parallel_args:\n            stats = _overlap_stats_process_image(*args)\n            for outer, inner in stats.items():\n                all_overlap_stats.setdefault(outer, {}).update(inner)\n\n    # Load whole stats\n    all_whole_stats = {\n        name: {\n            int(k.split(\"_\")[1]): {\n                \"mean\": loaded_model[name][\"whole_stats\"][k][\"mean\"],\n                \"std\": loaded_model[name][\"whole_stats\"][k][\"std\"],\n                \"size\": loaded_model[name][\"whole_stats\"][k][\"size\"]\n            }\n            for k in loaded_model[name][\"whole_stats\"]\n        }\n        for name in input_image_path_pairs\n        if name in loaded_model\n    }\n\n    # Calculate whole stats\n    parallel_args = [\n        (\n            window_parallel,\n            window_max_workers,\n            window_backend,\n            image_path,\n            nodata_val,\n            num_bands,\n            image_name,\n            vector_mask,\n            window_size,\n            debug_logs,\n        )\n        for image_name, image_path in input_image_path_pairs.items()\n        if image_name not in loaded_model\n    ]\n\n    # Compute whole stats\n    if image_parallel:\n        with _get_executor(image_backend, image_max_workers) as executor:\n            futures = [executor.submit(_whole_stats_process_image, *args) for args in parallel_args]\n            for future in as_completed(futures):\n                result = future.result()\n                all_whole_stats.update(result)\n    else:\n        for args in parallel_args:\n            result = _whole_stats_process_image(*args)\n            all_whole_stats.update(result)\n\n    # Get image names\n    all_image_names = list(dict.fromkeys(input_image_names + list(loaded_model.keys())))\n    num_total = len(all_image_names)\n\n    # Print model sources\n    if debug_logs:\n        print(f\"\\nCreating model for {len(all_image_names)} total images from {len(included_names)} included:\")\n        print(f\"    {'ID':&lt;4}\\t{'Source':&lt;6}\\t{'Inclusion':&lt;8}\\tName\")\n        for i, name in enumerate(all_image_names):\n            source = \"load\" if name in (matched | only_loaded) else \"calc\"\n            included = \"incl\" if name in included_names else \"excl\"\n            print(f\"    {i:&lt;4}\\t{source:&lt;6}\\t{included:&lt;8}\\t{name}\")\n\n    # Build model\n    all_params = solve_global_model(\n        num_bands,\n        num_total,\n        all_image_names,\n        included_names,\n        input_image_names,\n        all_overlap_stats,\n        all_whole_stats,\n        custom_mean_factor,\n        custom_std_factor,\n        overlapping_pairs,\n        debug_logs,\n    )\n\n    # Save adjustments\n    if save_adjustments:\n        _save_adjustments(\n            save_path=save_adjustments,\n            input_image_names=list(input_image_path_pairs.keys()),\n            all_params=all_params,\n            all_whole_stats=all_whole_stats,\n            all_overlap_stats=all_overlap_stats,\n            num_bands=num_bands,\n            calculation_dtype=calculation_dtype\n        )\n\n    # Apply corrections\n    if debug_logs: print(f\"Apply adjustments and saving results for:\")\n    parallel_args = [\n        (\n            name,\n            img_path,\n            output_image_path_pairs[name],\n            np.array([all_params[b, 2 * idx, 0] for b in range(num_bands)]),\n            np.array([all_params[b, 2 * idx + 1, 0] for b in range(num_bands)]),\n            num_bands,\n            nodata_val,\n            window_size,\n            calculation_dtype,\n            output_dtype,\n            window_parallel,\n            window_backend,\n            window_max_workers,\n            debug_logs,\n        )\n        for idx, (name, img_path) in enumerate(input_image_path_pairs.items())\n    ]\n\n    if image_parallel:\n        with _get_executor(image_backend, image_max_workers) as executor:\n            futures = [executor.submit(_apply_adjustments_process_image, *args) for args in parallel_args]\n            for future in as_completed(futures):\n                future.result()\n    else:\n        for args in parallel_args:\n            _apply_adjustments_process_image(*args)\n\n    return output_image_paths\n</code></pre>"},{"location":"api/match/#spectralmatch.match.global_regression.solve_global_model","title":"<code>solve_global_model(num_bands, num_total, all_image_names, included_names, input_image_names, all_overlap_stats, all_whole_stats, custom_mean_factor, custom_std_factor, overlapping_pairs, debug_logs=False)</code>","text":"<p>Computes global radiometric normalization parameters (scale and offset) for each image and band using least squares regression.</p> <p>Parameters:</p> Name Type Description Default <code>num_bands</code> <code>int</code> <p>Number of image bands.</p> required <code>num_total</code> <code>int</code> <p>Total number of images (including loaded).</p> required <code>all_image_names</code> <code>list[str]</code> <p>Ordered list of all image names.</p> required <code>included_names</code> <code>list[str]</code> <p>Subset of images used to constrain the model.</p> required <code>input_image_names</code> <code>list[str]</code> <p>Names of input images to apply normalization to.</p> required <code>all_overlap_stats</code> <code>dict</code> <p>Pairwise overlap statistics per band.</p> required <code>all_whole_stats</code> <code>dict</code> <p>Whole-image stats (mean, std) per band.</p> required <code>custom_mean_factor</code> <code>float</code> <p>Weight for mean constraints.</p> required <code>custom_std_factor</code> <code>float</code> <p>Weight for std constraints.</p> required <code>overlapping_pairs</code> <code>tuple[tuple[str, str], ...]</code> <p>Pairs of overlapping images.</p> required <code>debug_logs</code> <code>bool</code> <p>If True, prints debug information.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Adjustment parameters of shape (bands, 2 * num_images, 1).</p> Source code in <code>spectralmatch/match/global_regression.py</code> <pre><code>def solve_global_model(\n    num_bands: int,\n    num_total: int,\n    all_image_names: list[str],\n    included_names: list[str],\n    input_image_names: list[str],\n    all_overlap_stats: dict,\n    all_whole_stats: dict,\n    custom_mean_factor: float,\n    custom_std_factor: float,\n    overlapping_pairs: tuple[tuple[str, str], ...],\n    debug_logs: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    Computes global radiometric normalization parameters (scale and offset) for each image and band using least squares regression.\n\n    Args:\n        num_bands: Number of image bands.\n        num_total: Total number of images (including loaded).\n        all_image_names: Ordered list of all image names.\n        included_names: Subset of images used to constrain the model.\n        input_image_names: Names of input images to apply normalization to.\n        all_overlap_stats: Pairwise overlap statistics per band.\n        all_whole_stats: Whole-image stats (mean, std) per band.\n        custom_mean_factor: Weight for mean constraints.\n        custom_std_factor: Weight for std constraints.\n        overlapping_pairs: Pairs of overlapping images.\n        debug_logs: If True, prints debug information.\n\n    Returns:\n        np.ndarray: Adjustment parameters of shape (bands, 2 * num_images, 1).\n    \"\"\"\n    all_params = np.zeros((num_bands, 2 * num_total, 1), dtype=float)\n    image_names_with_id = [(i, name) for i, name in enumerate(all_image_names)]\n    for b in range(num_bands):\n        if debug_logs: print(f\"\\nProcessing band {b}:\")\n\n        A, y, tot_overlap = [], [], 0\n        for i, name_i in image_names_with_id:\n            for j, name_j in image_names_with_id[i + 1:]:\n                stat = all_overlap_stats.get(name_i, {}).get(name_j)\n                if stat is None:\n                    continue\n\n                # This condition ensures that only overlaps involving at least one included image contribute constraints, allowing external images to be calibrated against the model without influencing it.\n                if name_i not in included_names and name_j not in included_names:\n                    continue\n\n                s = stat[b][\"size\"]\n                m1, v1 = stat[b][\"mean\"], stat[b][\"std\"]\n                m2, v2 = (\n                    all_overlap_stats[name_j][name_i][b][\"mean\"],\n                    all_overlap_stats[name_j][name_i][b][\"std\"],\n                )\n\n                row_m = [0] * (2 * num_total)\n                row_s = [0] * (2 * num_total)\n                row_m[2 * i: 2 * i + 2] = [m1, 1]\n                row_m[2 * j: 2 * j + 2] = [-m2, -1]\n                row_s[2 * i], row_s[2 * j] = v1, -v2\n\n                A.extend([\n                    [v * s * custom_mean_factor for v in row_m],\n                    [v * s * custom_std_factor for v in row_s],\n                ])\n                y.extend([0, 0])\n                tot_overlap += s\n\n        pjj = 1.0 if tot_overlap == 0 else tot_overlap / (2.0 * num_total)\n\n        for name in included_names:\n            mj = all_whole_stats[name][b][\"mean\"]\n            vj = all_whole_stats[name][b][\"std\"]\n            j_idx = all_image_names.index(name)\n            row_m = [0] * (2 * num_total)\n            row_s = [0] * (2 * num_total)\n            row_m[2 * j_idx: 2 * j_idx + 2] = [mj * pjj, 1 * pjj]\n            row_s[2 * j_idx] = vj * pjj\n            A.extend([row_m, row_s])\n            y.extend([mj * pjj, vj * pjj])\n\n        for name in input_image_names:\n            if name in included_names:\n                continue\n            row = [0] * (2 * num_total)\n            A.append(row.copy())\n            y.append(0)\n            A.append(row.copy())\n            y.append(0)\n\n        A_arr = np.asarray(A)\n        y_arr = np.asarray(y)\n        res = least_squares(lambda p: A_arr @ p - y_arr, [1, 0] * num_total)\n        all_params[b, :, 0] = res.x\n\n\n        if debug_logs:\n            _print_constraint_system(\n                constraint_matrix=A_arr,\n                adjustment_params=res.x,\n                observed_values_vector=y_arr,\n                overlap_pairs=overlapping_pairs,\n                image_names_with_id=image_names_with_id,\n\n            )\n    return all_params\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.get_bounding_rect_images_block_space","title":"<code>get_bounding_rect_images_block_space(block_local_means)</code>","text":"<p>Compute block-space bounding rectangles for each image based on valid block values.</p> <p>Parameters:</p> Name Type Description Default <code>block_local_means</code> <code>dict[str, ndarray]</code> <p>Per-image block means with shape (num_row, num_col, num_bands).</p> required <p>Returns:</p> Type Description <code>dict[str, tuple[int, int, int, int]]</code> <p>dict[str, tuple[int, int, int, int]]: Each entry maps image name to (min_row, min_col, max_row, max_col).</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def get_bounding_rect_images_block_space(\n    block_local_means: dict[str, np.ndarray]\n) -&gt; dict[str, tuple[int, int, int, int]]:\n    \"\"\"\n    Compute block-space bounding rectangles for each image based on valid block values.\n\n    Args:\n        block_local_means (dict[str, np.ndarray]): Per-image block means\n            with shape (num_row, num_col, num_bands).\n\n    Returns:\n        dict[str, tuple[int, int, int, int]]: Each entry maps image name to\n            (min_row, min_col, max_row, max_col).\n    \"\"\"\n    output = {}\n\n    for name, arr in block_local_means.items():\n        valid_mask = np.any(~np.isnan(arr), axis=2)\n        rows, cols = np.where(valid_mask)\n\n        if rows.size &gt; 0 and cols.size &gt; 0:\n            min_row, max_row = rows.min(), rows.max() + 1\n            min_col, max_col = cols.min(), cols.max() + 1\n        else:\n            min_row = max_row = min_col = max_col = 0\n\n        output[name] = (min_row, min_col, max_row, max_col)\n\n    return output\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.local_block_adjustment","title":"<code>local_block_adjustment(input_images, output_images, *, calculation_dtype='float32', output_dtype=None, vector_mask=None, debug_logs=False, custom_nodata_value=None, image_parallel_workers=None, window_parallel_workers=None, window_size=None, save_as_cog=False, number_of_blocks=100, alpha=1.0, correction_method='gamma', save_block_maps=None, load_block_maps=None, override_bounds_canvas_coords=None, block_valid_pixel_threshold=0.001)</code>","text":"<p>Performs local radiometric adjustment on a set of raster images using block-based statistics.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies the input images either as: - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). - A list of full file paths to individual input images.</p> required <code>output_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies how output filenames are generated or provided: - A tuple with an output folder and a filename template using \"\\(\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"\\)_LocalMatch.tif\")). - A list of full output paths, which must match the number of input images.</p> required <code>calculation_dtype</code> <code>str</code> <p>Precision for internal calculations. Defaults to \"float32\".</p> <code>'float32'</code> <code>output_dtype</code> <code>str | None</code> <p>Data type for output rasters. Defaults to input image dtype.</p> <code>None</code> <code>vector_mask</code> <code>Tuple[Literal['include', 'exclude'], str, Optional[str]] | None</code> <p>A mask limiting pixels to include when calculating stats for each block in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that includes (can be substring) input image name to filter geometry by. It is only applied when calculating local blocks, as the reference map is calculated as the mean of all local blocks. Loaded block maps won't have this applied unless it was used when calculating them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>If True, prints progress. Defaults to False.</p> <code>False</code> <code>custom_nodata_value</code> <code>float | int | None</code> <p>Overrides detected NoData value. Defaults to None.</p> <code>None</code> <code>image_parallel_workers</code> <code>Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None</code> <p>Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.</p> <code>None</code> <code>window_parallel_workers</code> <code>Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None</code> <p>Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.</p> <code>None</code> <code>window_size</code> <code>int | Tuple[int, int] | Literal['block'] | None</code> <p>Tile size for processing: int for square tiles, (width, height) for custom size, or \"block\" to set as the size of the block map, None for full image. Defaults to None.</p> <code>None</code> <code>save_as_cog</code> <code>bool</code> <p>If True, saves as COG. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int | tuple | Literal['coefficient_of_variation']</code> <p>int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.</p> <code>100</code> <code>alpha</code> <code>float</code> <p>Blending factor between reference and local means. Defaults to 1.0.</p> <code>1.0</code> <code>correction_method</code> <code>Literal['gamma', 'linear']</code> <p>Local correction method. Defaults to \"gamma\".</p> <code>'gamma'</code> <code>save_block_maps</code> <code>tuple(str, str) | None</code> <p>If enabled, saves block maps for review, to resume processing later, or to add additional images to the reference map. - First str is the path to save the global block map. - Second str is the path to save the local block maps, which must include \"$\" which will be replaced my the image name (because there are multiple local maps).</p> <code>None</code> <code>load_block_maps</code> <code>Tuple[str, List[str]] | Tuple[str, None] | Tuple[None, List[str]] | None</code> <p>Controls loading of precomputed block maps. Can be one of:     - Tuple[str, List[str]]: Load both reference and local block maps.     - Tuple[str, None]: Load only the reference block map.     - Tuple[None, List[str]]: Load only the local block maps.     - None: Do not load any block maps. This supports partial or full reuse of precomputed block maps:     - Local block maps will still be computed for each input image that is not linked to a local block map by the images name being included in the local block maps name (file name).     - The reference block map will only be calculated (mean of all local blocks) if not set.     - The reference map defines the reference block statistics and the local maps define per-image local block statistics.     - Both reference and local maps must have the same canvas extent and dimensions which will be used to set those values.</p> <code>None</code> <code>override_bounds_canvas_coords</code> <code>Tuple[float, float, float, float] | None</code> <p>Manually set (min_x, min_y, max_x, max_y) bounds to override the computed/loaded canvas extent. If you wish to have a larger extent than the current images, you can manually set this, along with setting a fixed number of blocks, to anticipate images will expand beyond the current extent.</p> <code>None</code> <code>block_valid_pixel_threshold</code> <code>float</code> <p>Minimum fraction of valid pixels required to include a block (0\u20131).</p> <code>0.001</code> <p>Returns:</p> Type Description <code>list</code> <p>List[str]: Paths to the locally adjusted output raster images.</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def local_block_adjustment(\n    input_images: Universal.SearchFolderOrListFiles,\n    output_images: Universal.CreateInFolderOrListFiles,\n    *,\n    calculation_dtype: Universal.CalculationDtype = \"float32\",\n    output_dtype: Universal.OutputDtype = None,\n    vector_mask: Universal.VectorMask = None,\n    debug_logs: Universal.DebugLogs = False,\n    custom_nodata_value: Universal.CustomNodataValue = None,\n    image_parallel_workers: Universal.ImageParallelWorkers = None,\n    window_parallel_workers: Universal.WindowParallelWorkers = None,\n    window_size: Universal.WindowSizeWithBlock = None,\n    save_as_cog: Universal.SaveAsCog = False,\n    number_of_blocks: int | Tuple[int, int] | Literal[\"coefficient_of_variation\"] = 100,\n    alpha: float = 1.0,\n    correction_method: Literal[\"gamma\", \"linear\"] = \"gamma\",\n    save_block_maps: Tuple[str, str] | None = None,\n    load_block_maps: Tuple[str, List[str]] | Tuple[str, None]| Tuple[None, List[str]] | None = None,\n    override_bounds_canvas_coords: Tuple[float, float, float, float] | None = None,\n    block_valid_pixel_threshold: float = 0.001,\n    )-&gt; list:\n    \"\"\"\n    Performs local radiometric adjustment on a set of raster images using block-based statistics.\n\n    Args:\n        input_images (Tuple[str, str] | List[str]):\n            Specifies the input images either as:\n            - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n            - A list of full file paths to individual input images.\n        output_images (Tuple[str, str] | List[str]):\n            Specifies how output filenames are generated or provided:\n            - A tuple with an output folder and a filename template using \"$\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"$_LocalMatch.tif\")).\n            - A list of full output paths, which must match the number of input images.\n        calculation_dtype (str, optional): Precision for internal calculations. Defaults to \"float32\".\n        output_dtype (str | None, optional): Data type for output rasters. Defaults to input image dtype.\n        vector_mask (Tuple[Literal[\"include\", \"exclude\"], str, Optional[str]] | None): A mask limiting pixels to include when calculating stats for each block in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that *includes* (can be substring) input image name to filter geometry by. It is only applied when calculating local blocks, as the reference map is calculated as the mean of all local blocks. Loaded block maps won't have this applied unless it was used when calculating them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.\n        debug_logs (bool, optional): If True, prints progress. Defaults to False.\n        custom_nodata_value (float | int | None, optional): Overrides detected NoData value. Defaults to None.\n        image_parallel_workers (Tuple[Literal[\"process\", \"thread\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the image level. Provide a tuple like (\"process\", \"cpu\") to use multiprocessing with all available cores. Threads are supported too. Set to None to disable.\n        window_parallel_workers (Tuple[Literal[\"process\"], Literal[\"cpu\"] | int] | None = None): Parallelization strategy at the window level within each image. Same format as image_parallel_workers. Threads are not supported. Set to None to disable.\n        window_size (int | Tuple[int, int] | Literal[\"block\"] | None): Tile size for processing: int for square tiles, (width, height) for custom size, or \"block\" to set as the size of the block map, None for full image. Defaults to None.\n        save_as_cog (bool, optional): If True, saves as COG. Defaults to False.\n        number_of_blocks (int | tuple | Literal[\"coefficient_of_variation\"]): int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.\n        alpha (float, optional): Blending factor between reference and local means. Defaults to 1.0.\n        correction_method (Literal[\"gamma\", \"linear\"], optional): Local correction method. Defaults to \"gamma\".\n        save_block_maps (tuple(str, str) | None): If enabled, saves block maps for review, to resume processing later, or to add additional images to the reference map.\n            - First str is the path to save the global block map.\n            - Second str is the path to save the local block maps, which must include \"$\" which will be replaced my the image name (because there are multiple local maps).\n        load_block_maps (Tuple[str, List[str]] | Tuple[str, None] | Tuple[None, List[str]] | None, optional):\n            Controls loading of precomputed block maps. Can be one of:\n                - Tuple[str, List[str]]: Load both reference and local block maps.\n                - Tuple[str, None]: Load only the reference block map.\n                - Tuple[None, List[str]]: Load only the local block maps.\n                - None: Do not load any block maps.\n            This supports partial or full reuse of precomputed block maps:\n                - Local block maps will still be computed for each input image that is not linked to a local block map by the images name being *included* in the local block maps name (file name).\n                - The reference block map will only be calculated (mean of all local blocks) if not set.\n                - The reference map defines the reference block statistics and the local maps define per-image local block statistics.\n                - Both reference and local maps must have the same canvas extent and dimensions which will be used to set those values.\n        override_bounds_canvas_coords (Tuple[float, float, float, float] | None): Manually set (min_x, min_y, max_x, max_y) bounds to override the computed/loaded canvas extent. If you wish to have a larger extent than the current images, you can manually set this, along with setting a fixed number of blocks, to anticipate images will expand beyond the current extent.\n        block_valid_pixel_threshold (float): Minimum fraction of valid pixels required to include a block (0\u20131).\n\n    Returns:\n        List[str]: Paths to the locally adjusted output raster images.\n    \"\"\"\n\n    print(\"Start local block adjustment\")\n\n    # Validate params\n    Universal.validate(\n        input_images=input_images,\n        output_images=output_images,\n        save_as_cog=save_as_cog,\n        debug_logs=debug_logs,\n        vector_mask=vector_mask,\n        window_size=window_size,\n        custom_nodata_value=custom_nodata_value,\n        image_parallel_workers=image_parallel_workers,\n        window_parallel_workers=window_parallel_workers,\n        calculation_dtype=calculation_dtype,\n        output_dtype=output_dtype,\n    )\n\n    Match.validate_local_block_adjustment(\n        number_of_blocks=number_of_blocks,\n        alpha=alpha,\n        correction_method=correction_method,\n        save_block_maps=save_block_maps,\n        load_block_maps=load_block_maps,\n        override_bounds_canvas_coords=override_bounds_canvas_coords,\n        block_valid_pixel_threshold=block_valid_pixel_threshold,\n    )\n\n    # Determine multiprocessing and worker count\n    image_parallel, image_backend, image_max_workers = _resolve_parallel_config(image_parallel_workers)\n    window_parallel, window_backend, window_max_workers = _resolve_parallel_config(window_parallel_workers)\n\n    input_image_paths = _resolve_paths(\"search\", input_images)\n    output_image_paths = _resolve_paths(\"create\", output_images, (input_image_paths,))\n\n    if debug_logs: print(f\"Input images: {input_image_paths}\")\n    if debug_logs: print(f\"Output images: {output_image_paths}\")\n\n    input_image_names = [os.path.splitext(os.path.basename(p))[0] for p in input_image_paths]\n    input_image_path_pairs = dict(zip(input_image_names, input_image_paths))\n    output_image_path_pairs = dict(zip(input_image_names, output_image_paths))\n\n    _check_raster_requirements(input_image_paths, debug_logs, check_geotransform=True, check_crs=True, check_bands=True, check_nodata=True)\n\n    if isinstance(window_size, int): window_size = (window_size, window_size)\n    nodata_val = _get_nodata_value(input_image_paths, custom_nodata_value)\n    projection = rasterio.open(input_image_paths[0]).crs\n    if debug_logs: print(f\"Global nodata value: {nodata_val}\")\n    with rasterio.open(input_image_paths[0]) as ds:num_bands = ds.count\n\n    # Load data from precomputed block maps if set\n    if load_block_maps:\n        loaded_block_local_means, loaded_block_reference_mean, loaded_num_row, loaded_num_col, loaded_bounds_canvas_coords = _get_pre_computed_block_maps(load_block_maps, calculation_dtype, debug_logs)\n        loaded_names = list(loaded_block_local_means.keys())\n        block_reference_mean = loaded_block_reference_mean\n\n        matched = list((soft_matches := {\n            input_name: loaded_name\n            for input_name in input_image_names\n            for loaded_name in loaded_names\n            if input_name in loaded_name\n        }).keys())\n        only_loaded = [l for l in loaded_names if not any(n in l for n in input_image_names)]\n        only_input = [n for n in input_image_names if not any(n in l for l in loaded_names)]\n\n    else:\n        only_input = input_image_names\n        matched = []\n        only_loaded = []\n        block_reference_mean = None\n\n    if debug_logs:\n        print(f\"Total images: input images: {len(input_image_names)}, loaded local block maps: {len(loaded_names) if load_block_maps else 0}:\")\n        print(f\"    Matched local block maps (to override) ({len(matched)}):\", sorted(matched))\n        print(f\"    Only in loaded local block maps (to use) ({len(only_loaded)}):\", sorted(only_loaded))\n        print(f\"    Only in input (to compute) ({len(only_input)}):\", sorted(only_input))\n\n    # Unpack path to save block maps\n    if save_block_maps:\n        reference_map_path, local_map_path = save_block_maps\n\n    # Create image bounds dict\n    bounds_images_coords = {\n        name: rasterio.open(path).bounds\n        for name, path in input_image_path_pairs.items()\n    }\n\n    # Get bounds canvas coords\n    if not override_bounds_canvas_coords:\n        if not load_block_maps:\n            bounds_canvas_coords = _get_bounding_rectangle(input_image_paths)\n        else:\n            bounds_canvas_coords = loaded_bounds_canvas_coords\n    else:\n        bounds_canvas_coords = override_bounds_canvas_coords\n        if load_block_maps:\n            if bounds_canvas_coords != loaded_bounds_canvas_coords:\n                raise ValueError(\"Override bounds canvas coordinates do not match loaded block maps bounds\")\n\n    # Calculate the number of blocks\n    if not load_block_maps:\n        if isinstance(number_of_blocks, int):\n            num_row, num_col = _compute_block_size(input_image_paths, number_of_blocks, bounds_canvas_coords)\n        elif isinstance(number_of_blocks, tuple):\n            num_row, num_col = number_of_blocks\n        elif isinstance(number_of_blocks, str):\n            num_row, num_col = _compute_mosaic_coefficient_of_variation(input_image_paths, nodata_val) # This is the approach from the paper to compute bock size\n    else:\n        num_row, num_col = loaded_num_row, loaded_num_col\n\n    if debug_logs: print(\"Computing local block maps:\")\n\n    # Compute local blocks\n    local_blocks_to_calculate = {k: v for k, v in input_image_path_pairs.items() if k in only_input}\n    local_blocks_to_load = {\n        **{k: loaded_block_local_means[soft_matches[k]] for k in matched},\n        **{k: loaded_block_local_means[k] for k in only_loaded},\n    }\n\n    if local_blocks_to_calculate:\n        args = [\n            (\n                name,\n                path,\n                bounds_canvas_coords,\n                num_row,\n                num_col,\n                num_bands,\n                window_size,\n                debug_logs,\n                nodata_val,\n                calculation_dtype,\n                vector_mask,\n                block_valid_pixel_threshold,\n                window_parallel,\n                window_backend,\n                window_max_workers,\n            )\n            for name, path in local_blocks_to_calculate.items()\n        ]\n\n        if image_parallel:\n            with _get_executor(image_backend, image_max_workers) as executor:\n                futures = [executor.submit(_calculate_block_process_image, *arg) for arg in args]\n                results = [f.result() for f in futures]\n        else:\n            results = [_calculate_block_process_image(*arg) for arg in args]\n\n        block_local_means = {name: mean for name, mean, _ in results}\n\n        overlap = set(block_local_means) &amp; set(local_blocks_to_load)\n        if overlap: raise ValueError(f\"Duplicate keys when merging loaded and computed blocks: {overlap}\")\n\n        block_local_means = {**block_local_means, **local_blocks_to_load}\n    else:\n        block_local_means = local_blocks_to_load\n\n    bounds_images_block_space = get_bounding_rect_images_block_space(block_local_means)\n\n    # Compute reference block\n    if debug_logs: print(\"Computing reference block map\")\n    if block_reference_mean is None:\n        block_reference_mean = _compute_reference_blocks(\n            block_local_means,\n            calculation_dtype,\n            )\n\n    if save_block_maps:\n        _download_block_map(\n            np.nan_to_num(block_reference_mean, nan=nodata_val),\n            bounds_canvas_coords,\n            reference_map_path,\n            projection,\n            calculation_dtype,\n            nodata_val,\n            num_col,\n            num_row,\n        )\n        for name, block_local_mean in block_local_means.items():\n            _download_block_map(\n                np.nan_to_num(block_local_mean, nan=nodata_val),\n                bounds_canvas_coords,\n                local_map_path.replace(\"$\", name),\n                projection,\n                calculation_dtype,\n                nodata_val,\n                num_col,\n                num_row,\n            )\n            # _download_block_map(\n            #     np.nan_to_num(block_local_count, nan=nodata_val),\n            #     bounds_canvas_coords,\n            #     os.path.join(output_image_folder, \"BlockLocalCount\", f\"{input_image_name}_BlockLocalCount.tif\"),\n            #     projection,\n            #     calculation_dtype,\n            #     nodata_val,\n            #     num_col,\n            #     num_row,\n            # )\n\n    # block_local_mean = _smooth_array(block_local_mean, nodata_value=global_nodata_value)\n\n    # Apply adjustments to images\n    if debug_logs: print(f\"Computing local correction, applying, and saving:\")\n    args = [\n        (\n            name,\n            input_image_path_pairs[name],\n            output_image_path_pairs[name],\n            num_bands,\n            block_reference_mean,\n            block_local_means[name],\n            bounds_images_block_space[name],\n            bounds_canvas_coords,\n            window_size,\n            num_row,\n            num_col,\n            nodata_val,\n            alpha,\n            correction_method,\n            calculation_dtype,\n            output_dtype,\n            debug_logs,\n            window_parallel,\n            window_backend,\n            window_max_workers,\n        )\n        for name in input_image_path_pairs\n    ]\n\n    if image_parallel:\n        with _get_executor(image_backend, image_max_workers) as executor:\n            futures = [executor.submit(_apply_adjustment_process_image, *arg) for arg in args]\n            for future in as_completed(futures):\n                future.result()\n    else:\n        for arg in args:\n            _apply_adjustment_process_image(*arg)\n\n    return output_image_paths\n</code></pre>"},{"location":"api/statistics/","title":"Creating Statistical Figures","text":""},{"location":"api/statistics/#spectralmatch.statistics.compare_image_spectral_profiles","title":"<code>compare_image_spectral_profiles(input_image_dict, output_figure_path, title, xlabel, ylabel)</code>","text":"<p>Compares spectral profiles of multiple images by plotting median and interquartile ranges.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_dict</code> <code>dict</code> <p>Mapping of labels to image file paths: { 'Image A': '/image/a.tif', 'Image B': '/image/b.tif' }</p> required <code>output_figure_path</code> <code>str</code> <p>Path to save the output plot.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>xlabel</code> <code>str</code> <p>Label for the x-axis.</p> required <code>ylabel</code> <code>str</code> <p>Label for the y-axis.</p> required Outputs <p>Saves a spectral profile comparison figure to the specified path.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_image_spectral_profiles(\n    input_image_dict,\n    output_figure_path,\n    title,\n    xlabel,\n    ylabel,\n):\n    \"\"\"\n    Compares spectral profiles of multiple images by plotting median and interquartile ranges.\n\n    Args:\n        input_image_dict (dict): Mapping of labels to image file paths:\n            {\n            'Image A': '/image/a.tif',\n            'Image B': '/image/b.tif'\n            }\n        output_figure_path (str): Path to save the output plot.\n        title (str): Title of the plot.\n        xlabel (str): Label for the x-axis.\n        ylabel (str): Label for the y-axis.\n\n    Outputs:\n        Saves a spectral profile comparison figure to the specified path.\n    \"\"\"\n    os.makedirs(os.path.dirname(output_figure_path), exist_ok=True)\n    plt.figure(figsize=(10, 6))\n    colors = itertools.cycle(plt.cm.tab10.colors)\n    spectral_profiles = []\n    labels = []\n\n    for label, image_path in input_image_dict.items():\n        try:\n            with rasterio.open(image_path) as src:\n                image_data = src.read()  # shape: (bands, height, width)\n        except Exception as e:\n            print(f\"Failed to open {image_path}: {e}\")\n            continue\n\n        bands, height, width = image_data.shape\n        reshaped = image_data.reshape(bands, -1)\n        median = np.median(reshaped, axis=1)\n        q25, q75 = np.percentile(reshaped, [25, 75], axis=1)\n        spectral_profiles.append((median, q25, q75))\n        labels.append(label)\n\n    for i, (median, q25, q75) in enumerate(spectral_profiles):\n        color = next(colors)\n        x = range(1, len(median) + 1)\n        plt.plot(x, median, color=color, label=labels[i])\n        plt.fill_between(x, q25, q75, color=color, alpha=0.3)\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(output_figure_path, dpi=300)\n    plt.close()\n    print(f\"Saved: {output_figure_path}\")\n</code></pre>"},{"location":"api/statistics/#spectralmatch.statistics.compare_image_spectral_profiles_pairs","title":"<code>compare_image_spectral_profiles_pairs(image_groups_dict, output_figure_path, title, xlabel, ylabel)</code>","text":"<p>Plots paired spectral profiles for before-and-after image comparisons.</p> <p>Parameters:</p> Name Type Description Default <code>image_groups_dict</code> <code>dict</code> <p>Mapping of labels to image path pairs (before, after): {'Image A': [     '/image/before/a.tif',     'image/after/a.tif' ], 'Image B': [     '/image/before/b.tif',     '/image/after/b.tif' ]}</p> required <code>output_figure_path</code> <code>str</code> <p>Path to save the resulting comparison figure.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>xlabel</code> <code>str</code> <p>X-axis label.</p> required <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> required Outputs <p>Saves a spectral comparison plot showing pre- and post-processing profiles.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_image_spectral_profiles_pairs(\n    image_groups_dict: dict,\n    output_figure_path: str,\n    title: str,\n    xlabel: str,\n    ylabel: str,\n    ):\n    \"\"\"\n    Plots paired spectral profiles for before-and-after image comparisons.\n\n    Args:\n        image_groups_dict (dict): Mapping of labels to image path pairs (before, after):\n            {'Image A': [\n                '/image/before/a.tif',\n                'image/after/a.tif'\n            ],\n            'Image B': [\n                '/image/before/b.tif',\n                '/image/after/b.tif'\n            ]}\n        output_figure_path (str): Path to save the resulting comparison figure.\n        title (str): Title of the plot.\n        xlabel (str): X-axis label.\n        ylabel (str): Y-axis label.\n\n    Outputs:\n        Saves a spectral comparison plot showing pre- and post-processing profiles.\n    \"\"\"\n\n    os.makedirs(os.path.dirname(output_figure_path), exist_ok=True)\n    plt.figure(figsize=(10, 6))\n    colors = itertools.cycle(plt.cm.tab10.colors)\n\n    for label, group in image_groups_dict.items():\n        if len(group) == 2:\n            image_path1, image_path2 = group\n            color = next(colors)\n\n            for i, image_path in enumerate([image_path1, image_path2]):\n                with rasterio.open(image_path) as src:\n                    img = src.read()\n                    num_bands = img.shape[0]\n                    img_reshaped = img.reshape(num_bands, -1)\n                    nodata = src.nodata\n                    if nodata is not None:\n                        img_reshaped = np.where(img_reshaped == nodata, np.nan, img_reshaped)\n                    mean_spectral = np.nanmean(img_reshaped, axis=1)\n                    bands = np.arange(1, num_bands + 1)\n                    linestyle = 'dashed' if i == 0 else 'solid'\n                    plt.plot(bands, mean_spectral, linestyle=linestyle, color=color,\n                             label=f\"{label} - {'Before' if i == 0 else 'After'}\")\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(output_figure_path, dpi=300)\n    plt.close()\n    print(f\"Saved: {output_figure_path}\")\n</code></pre>"},{"location":"api/statistics/#spectralmatch.statistics.compare_spatial_spectral_difference_band_average","title":"<code>compare_spatial_spectral_difference_band_average(input_images, output_image_path, title, diff_label, subtitle)</code>","text":"<p>Computes and visualizes the average per-band spectral difference between two coregistered, equal size images.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>list</code> <p>List of two image file paths to compare.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the resulting difference image (PNG).</p> required <code>title</code> <code>str</code> <p>Title for the plot.</p> required <code>diff_label</code> <code>str</code> <p>Label for the colorbar indicating the difference metric.</p> required <code>subtitle</code> <code>str</code> <p>Optional subtitle to display below the plot.</p> required Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_spatial_spectral_difference_band_average(\n    input_images: list,\n    output_image_path: str,\n    title: str,\n    diff_label: str,\n    subtitle: str,\n):\n    \"\"\"\n    Computes and visualizes the average per-band spectral difference between two coregistered, equal size images.\n\n    Args:\n        input_images (list): List of two image file paths to compare.\n        output_image_path (str): Path to save the resulting difference image (PNG).\n        title (str): Title for the plot.\n        diff_label (str): Label for the colorbar indicating the difference metric.\n        subtitle (str): Optional subtitle to display below the plot.\n    \"\"\"\n\n    if len(input_images) != 2:\n        raise ValueError(\"input_images must be a list of exactly two image paths.\")\n\n    path1, path2 = input_images\n    name1 = os.path.splitext(os.path.basename(path1))[0]\n    name2 = os.path.splitext(os.path.basename(path2))[0]\n\n    with rasterio.open(path1) as src1, rasterio.open(path2) as src2:\n        img1 = src1.read()\n        img2 = src2.read()\n        nodata = src1.nodata\n\n        if img1.shape != img2.shape:\n            raise ValueError(\"Images must have the same dimensions.\")\n\n        diff = np.abs(img2 - img1).astype(\"float32\")\n\n        if nodata is not None:\n            mask = img1[0] != nodata\n            for b in range(1, img1.shape[0]):\n                mask &amp;= img1[b] != nodata\n                mask &amp;= img2[b] != nodata\n            diff[:, ~mask] = np.nan\n\n        with np.errstate(invalid=\"ignore\"):\n            mean_diff = np.full(diff.shape[1:], np.nan)\n            valid_mask = ~np.all(np.isnan(diff), axis=0)\n            mean_diff[valid_mask] = np.nanmean(diff[:, valid_mask], axis=0)\n\n        fig, ax = plt.subplots(figsize=(10, 6), constrained_layout=True)\n        im = ax.imshow(mean_diff, cmap='coolwarm', interpolation='nearest')\n\n        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n        cbar.set_label(diff_label)\n\n        ax.set_title(title, fontsize=14, pad=12)\n        if subtitle:\n            ax.text(0.5, -0.1, subtitle, fontsize=10, ha='center', transform=ax.transAxes)\n\n        ax.axis(\"off\")\n        plt.savefig(output_image_path, dpi=300, bbox_inches='tight')\n        plt.close()\n\n        print(f\"Saved: {output_image_path}\")\n</code></pre>"},{"location":"examples/benchmark/","title":"Benchmark Multithreading","text":"In\u00a0[\u00a0]: Copied! <pre>import os, shutil, tempfile, time\nfrom pathlib import Path\n</pre> import os, shutil, tempfile, time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_origin\n</pre> import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.transform import from_origin In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import global_regression, local_block_adjustment\n</pre> from spectralmatch import global_regression, local_block_adjustment In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def make_fake_rasters(out_dir, n_images, width, height, nodata=0):\n    out_dir = Path(out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n    profile = dict(\n        driver=\"GTiff\",\n        width=width,\n        height=height,\n        count=8,\n        dtype=\"uint16\",\n        nodata=nodata,\n        crs=\"EPSG:3857\",\n        transform=from_origin(0, 0, 1, 1),\n        tiled=True,\n        blockxsize=512,\n        blockysize=512,\n        compress=\"LZW\",\n    )\n    rng = np.random.default_rng(seed=42)\n    paths = []\n    for i in range(n_images):\n        p = out_dir / f\"fake_{i+1}_{width}px.tif\"\n        with rasterio.open(p, \"w\", **profile) as dst:\n            for b in range(1, 9):\n                data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")\n                data[0, 0] = nodata\n                dst.write(data, indexes=b)\n        paths.append(str(p))\n    return paths\n</pre> def make_fake_rasters(out_dir, n_images, width, height, nodata=0):     out_dir = Path(out_dir)     out_dir.mkdir(parents=True, exist_ok=True)     profile = dict(         driver=\"GTiff\",         width=width,         height=height,         count=8,         dtype=\"uint16\",         nodata=nodata,         crs=\"EPSG:3857\",         transform=from_origin(0, 0, 1, 1),         tiled=True,         blockxsize=512,         blockysize=512,         compress=\"LZW\",     )     rng = np.random.default_rng(seed=42)     paths = []     for i in range(n_images):         p = out_dir / f\"fake_{i+1}_{width}px.tif\"         with rasterio.open(p, \"w\", **profile) as dst:             for b in range(1, 9):                 data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")                 data[0, 0] = nodata                 dst.write(data, indexes=b)         paths.append(str(p))     return paths In\u00a0[\u00a0]: Copied! <pre>SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288]\nNUM_IMAGES = 2\nTILE_SIZE = (1024, 1024)\nMAX_WORKERS = 32\n</pre> SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288] NUM_IMAGES = 2 TILE_SIZE = (1024, 1024) MAX_WORKERS = 32 In\u00a0[\u00a0]: Copied! <pre>WORK_DIR = Path(__file__).parent / \"bench_output\"\nWORK_DIR.mkdir(exist_ok=True)\n</pre> WORK_DIR = Path(__file__).parent / \"bench_output\" WORK_DIR.mkdir(exist_ok=True) In\u00a0[\u00a0]: Copied! <pre>SERIAL, PARALLEL = [], []\n</pre> SERIAL, PARALLEL = [], [] In\u00a0[\u00a0]: Copied! <pre>for sz in SIZES:\n    print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")\n    tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))\n    imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)\n\n    t0 = time.time()\n    g_dir = tmp / \"serial_g\"\n    l_dir = tmp / \"serial_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        window_size=TILE_SIZE,\n        parallel=False,\n        debug_logs=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        window_size=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=False,\n        debug_logs=False,\n    )\n    SERIAL.append(time.time() - t0)\n    print(f\"serial   : {SERIAL[-1]:.1f} s\")\n\n    t0 = time.time()\n    g_dir = tmp / \"parallel_g\"\n    l_dir = tmp / \"parallel_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        window_size=TILE_SIZE,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_logs=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        window_size=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_logs=False,\n    )\n    PARALLEL.append(time.time() - t0)\n    print(f\"parallel : {PARALLEL[-1]:.1f} s\")\n\n    shutil.rmtree(tmp, ignore_errors=True)\n</pre> for sz in SIZES:     print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")     tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))     imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)      t0 = time.time()     g_dir = tmp / \"serial_g\"     l_dir = tmp / \"serial_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         window_size=TILE_SIZE,         parallel=False,         debug_logs=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         window_size=TILE_SIZE,         custom_nodata_value=-9999,         parallel=False,         debug_logs=False,     )     SERIAL.append(time.time() - t0)     print(f\"serial   : {SERIAL[-1]:.1f} s\")      t0 = time.time()     g_dir = tmp / \"parallel_g\"     l_dir = tmp / \"parallel_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         window_size=TILE_SIZE,         parallel=True,         max_workers=MAX_WORKERS,         debug_logs=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         window_size=TILE_SIZE,         custom_nodata_value=-9999,         parallel=True,         max_workers=MAX_WORKERS,         debug_logs=False,     )     PARALLEL.append(time.time() - t0)     print(f\"parallel : {PARALLEL[-1]:.1f} s\")      shutil.rmtree(tmp, ignore_errors=True) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 5))\nplt.plot(SIZES, SERIAL, \"-o\", label=\"serial\")\nplt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\")\nplt.xlabel(\"Raster width = height (pixels)\")\nplt.ylabel(\"Total runtime: global + local (seconds)\")\nplt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(8, 5)) plt.plot(SIZES, SERIAL, \"-o\", label=\"serial\") plt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\") plt.xlabel(\"Raster width = height (pixels)\") plt.ylabel(\"Total runtime: global + local (seconds)\") plt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\") plt.grid(True) plt.legend() plt.tight_layout() plt.show()"},{"location":"examples/example_landsat_time_series/","title":"Landsat Time Series","text":"In\u00a0[\u00a0]: Copied! <pre># This notebook demonstrates how to preprocess Landsat 8-9 into a time series with spectralmatch.\n# Starting from 5 Landsat 8-9 OLI/TIRS C2 L1 images, the process includes clipping clouds with OmniCloudMask, masking high NDVI areas as Pseudo Invariant Features (PIFs), applying global regression Relative Radiometric Normalization, fine-tuning overlap areas with local block adjustment, and before vs after statistics.\n# This script is set up to perform matching on all tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif.\n</pre> # This notebook demonstrates how to preprocess Landsat 8-9 into a time series with spectralmatch. # Starting from 5 Landsat 8-9 OLI/TIRS C2 L1 images, the process includes clipping clouds with OmniCloudMask, masking high NDVI areas as Pseudo Invariant Features (PIFs), applying global regression Relative Radiometric Normalization, fine-tuning overlap areas with local block adjustment, and before vs after statistics. # This script is set up to perform matching on all tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. In\u00a0[\u00a0]: Copied! <pre>import os\nfrom spectralmatch import *\n\n# Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder\nworking_directory = os.path.join(os.getcwd(), \"data_landsat\")\nprint(working_directory)\n\ninput_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\nmask_cloud_folder = os.path.join(working_directory, \"MaskCloud\")\nmask_vegetation_folder = os.path.join(working_directory, \"MaskVegetation\")\nmasked_folder = os.path.join(working_directory, \"Masked\")\nstats_folder = os.path.join(working_directory, \"Stats\")\n\nwindow_size = 128\nnum_workers = 5\n</pre> import os from spectralmatch import *  # Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder working_directory = os.path.join(os.getcwd(), \"data_landsat\") print(working_directory)  input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"GlobalMatch\") local_folder = os.path.join(working_directory, \"LocalMatch\") mask_cloud_folder = os.path.join(working_directory, \"MaskCloud\") mask_vegetation_folder = os.path.join(working_directory, \"MaskVegetation\") masked_folder = os.path.join(working_directory, \"Masked\") stats_folder = os.path.join(working_directory, \"Stats\")  window_size = 128 num_workers = 5 In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\n\nfor path in input_image_paths:\n    create_cloud_mask_with_omnicloudmask(\n        path,\n        5,\n        3,\n        8,\n        os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.tif\"),\n        # down_sample_m=10\n    )\n\ninput_mask_rasters_paths = search_paths(mask_cloud_folder, \"*.tif\")\n\nfor path in input_mask_rasters_paths:\n    post_process_raster_cloud_mask_to_vector(\n        path,\n        os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}.gpkg\"),\n        None,\n        {1: 50},\n        {0: None, 1: 1, 2: 1, 3: 1}\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\")  for path in input_image_paths:     create_cloud_mask_with_omnicloudmask(         path,         5,         3,         8,         os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.tif\"),         # down_sample_m=10     )  input_mask_rasters_paths = search_paths(mask_cloud_folder, \"*.tif\")  for path in input_mask_rasters_paths:     post_process_raster_cloud_mask_to_vector(         path,         os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}.gpkg\"),         None,         {1: 50},         {0: None, 1: 1, 2: 1, 3: 1}     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\ninput_mask_vectors = search_paths(mask_cloud_folder, \"*.gpkg\", match_to_paths=(input_image_paths, r\"(.*)_CloudMask\\.gpkg$\"))\noutput_paths = create_paths(masked_folder, \"$_CloudMasked.tif\", input_image_paths)\n\nfor input_path, vector_path, output_path in zip(input_image_paths, input_mask_vectors, output_paths):\n    mask_rasters(\n        input_path,\n        vector_path,\n        output_path,\n        (\"include\", \"value\", 1),\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\") input_mask_vectors = search_paths(mask_cloud_folder, \"*.gpkg\", match_to_paths=(input_image_paths, r\"(.*)_CloudMask\\.gpkg$\")) output_paths = create_paths(masked_folder, \"$_CloudMasked.tif\", input_image_paths)  for input_path, vector_path, output_path in zip(input_image_paths, input_mask_vectors, output_paths):     mask_rasters(         input_path,         vector_path,         output_path,         (\"include\", \"value\", 1),     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\nraster_mask_paths = create_paths(mask_vegetation_folder, \"$_VegetationMask.tif\", input_image_paths)\nvector_mask_paths = create_paths(mask_vegetation_folder, \"$.gpkg\", input_image_paths)\n\nfor input_path, raster_path in zip(input_image_paths, raster_mask_paths):\n    create_ndvi_mask(\n        input_path,\n        raster_path,\n        5,\n        4,\n    )\n\nfor raster_path, vector_path in zip(raster_mask_paths, vector_mask_paths):\n    post_process_threshold_to_vector(\n        raster_path,\n        vector_path,\n        0.1,\n        \"&gt;=\",\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\") raster_mask_paths = create_paths(mask_vegetation_folder, \"$_VegetationMask.tif\", input_image_paths) vector_mask_paths = create_paths(mask_vegetation_folder, \"$.gpkg\", input_image_paths)  for input_path, raster_path in zip(input_image_paths, raster_mask_paths):     create_ndvi_mask(         input_path,         raster_path,         5,         4,     )  for raster_path, vector_path in zip(raster_mask_paths, vector_mask_paths):     post_process_threshold_to_vector(         raster_path,         vector_path,         0.1,         \"&gt;=\",     ) In\u00a0[\u00a0]: Copied! <pre># This is just a simple example of creating PIFs based on NDVI values, for a more robust methodology use other techniques to create a better mask vector file\n\ninput_vector_paths = search_paths(mask_vegetation_folder, \"*.gpkg\")\nmerged_vector_pif_path = os.path.join(working_directory, \"Pifs.gpkg\")\n\nmerge_vectors(\n    input_vector_paths,\n    merged_vector_pif_path,\n    create_name_attribute=(\"image\", \", \"),\n    method=\"intersection\",\n    # method=\"keep_all\", # Create a unique mask per image\n    )\n</pre> # This is just a simple example of creating PIFs based on NDVI values, for a more robust methodology use other techniques to create a better mask vector file  input_vector_paths = search_paths(mask_vegetation_folder, \"*.gpkg\") merged_vector_pif_path = os.path.join(working_directory, \"Pifs.gpkg\")  merge_vectors(     input_vector_paths,     merged_vector_pif_path,     create_name_attribute=(\"image\", \", \"),     method=\"intersection\",     # method=\"keep_all\", # Create a unique mask per image     ) In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")\n\nglobal_regression(\n    (masked_folder, \"*.tif\"),\n    (global_folder, \"$_GlobalMatch.tif\"),\n    vector_mask_path=(\"exclude\", vector_mask_path),\n    # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image\n    debug_logs=True,\n    )\n</pre> vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")  global_regression(     (masked_folder, \"*.tif\"),     (global_folder, \"$_GlobalMatch.tif\"),     vector_mask_path=(\"exclude\", vector_mask_path),     # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image     debug_logs=True,     ) In\u00a0[\u00a0]: Copied! <pre>global_regression(\n    (masked_folder, \"*.tif\"),\n    (global_folder, \"$_GlobalMatch.tif\"),\n    debug_logs=True,\n    save_as_cog=True,\n    )\n</pre>  global_regression(     (masked_folder, \"*.tif\"),     (global_folder, \"$_GlobalMatch.tif\"),     debug_logs=True,     save_as_cog=True,     ) In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")\n\nlocal_block_adjustment(\n    (global_folder, \"*.tif\"),\n    (local_folder, \"$_LocalMatch.tif\"),\n    number_of_blocks=100,\n    vector_mask_path=(\"exclude\", vector_mask_path),\n    # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image\n    window_size=window_size,\n    parallel_workers=num_workers,\n    debug_logs=True,\n    save_block_maps=(os.path.join(local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\"), os.path.join(local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\")),\n    )\n</pre> vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")  local_block_adjustment(     (global_folder, \"*.tif\"),     (local_folder, \"$_LocalMatch.tif\"),     number_of_blocks=100,     vector_mask_path=(\"exclude\", vector_mask_path),     # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image     window_size=window_size,     parallel_workers=num_workers,     debug_logs=True,     save_block_maps=(os.path.join(local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\"), os.path.join(local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\")),     ) In\u00a0[\u00a0]: Copied! <pre># Compare image spectral profiles\ncompare_image_spectral_profiles(\n    input_image_dict={\n        os.path.splitext(os.path.basename(p))[0]: p\n        for p in search_paths(local_folder, \"*.tif\")\n    },\n    output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n)\n\n# Compare image spectral profiles pairs\nbefore_paths = search_paths(input_folder, \"*.tif\")\nafter_paths = search_paths(local_folder, \"*.tif\")\n\nimage_pairs = {\n    os.path.splitext(os.path.basename(b))[0]: [b, a]\n    for b, a in zip(sorted(before_paths), sorted(after_paths))\n    }\n\ncompare_image_spectral_profiles_pairs(\n    image_pairs,\n    os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n    )\n\n# Compare spatial spectral difference band average\ninput_paths = search_paths(input_folder, \"*.tif\")\nlocal_paths = search_paths(local_folder, \"*.tif\")\nbefore_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))\n\ncompare_spatial_spectral_difference_band_average(\n    input_images=[before_path, after_path],\n    output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),\n    title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",\n    diff_label=\"Reflectance Difference (0\u201310,000)\",\n    subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\",\n)\n</pre>  # Compare image spectral profiles compare_image_spectral_profiles(     input_image_dict={         os.path.splitext(os.path.basename(p))[0]: p         for p in search_paths(local_folder, \"*.tif\")     },     output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles\",     xlabel='Band',     ylabel='Reflectance(0-10,000)', )  # Compare image spectral profiles pairs before_paths = search_paths(input_folder, \"*.tif\") after_paths = search_paths(local_folder, \"*.tif\")  image_pairs = {     os.path.splitext(os.path.basename(b))[0]: [b, a]     for b, a in zip(sorted(before_paths), sorted(after_paths))     }  compare_image_spectral_profiles_pairs(     image_pairs,     os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",     xlabel='Band',     ylabel='Reflectance(0-10,000)',     )  # Compare spatial spectral difference band average input_paths = search_paths(input_folder, \"*.tif\") local_paths = search_paths(local_folder, \"*.tif\") before_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))  compare_spatial_spectral_difference_band_average(     input_images=[before_path, after_path],     output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),     title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",     diff_label=\"Reflectance Difference (0\u201310,000)\",     subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\", )"},{"location":"examples/example_worldview_mosaic/","title":"WorldView Mosaic","text":"In\u00a0[\u00a0]: Copied! <pre># This file demonstrates how to preprocess Worldview3 imagery into a mosaic using spectralmatch.\n# Starting from two overlapping Worldview3 images in reflectance, the process includes global matching, local matching, starting from saved block maps (optional for demonstration purposes), generating seamlines, and marging images, and before vs after statistics.\n# This script is set up to perform matching on all .tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. The easiest way to process your own imagery is to move it inside that folder or change the working_directory to another folder with this structure, alternatively, you can pass in custom lists of image paths.\n</pre> # This file demonstrates how to preprocess Worldview3 imagery into a mosaic using spectralmatch. # Starting from two overlapping Worldview3 images in reflectance, the process includes global matching, local matching, starting from saved block maps (optional for demonstration purposes), generating seamlines, and marging images, and before vs after statistics. # This script is set up to perform matching on all .tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. The easiest way to process your own imagery is to move it inside that folder or change the working_directory to another folder with this structure, alternatively, you can pass in custom lists of image paths. In\u00a0[\u00a0]: Copied! <pre>import os\nfrom spectralmatch import *\n\n# Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder\nworking_directory = os.path.join(os.getcwd(), \"data_worldview\")\nprint(working_directory)\n\ninput_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\naligned_folder = os.path.join(working_directory, \"Aligned\")\nclipped_folder = os.path.join(working_directory, \"Clipped\")\nstats_folder = os.path.join(working_directory, \"Stats\")\n\n\nwindow_size = 128\nnum_image_workers = 5\nnum_window_workers = 5\n</pre> import os from spectralmatch import *  # Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder working_directory = os.path.join(os.getcwd(), \"data_worldview\") print(working_directory)  input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"GlobalMatch\") local_folder = os.path.join(working_directory, \"LocalMatch\") aligned_folder = os.path.join(working_directory, \"Aligned\") clipped_folder = os.path.join(working_directory, \"Clipped\") stats_folder = os.path.join(working_directory, \"Stats\")   window_size = 128 num_image_workers = 5 num_window_workers = 5 In\u00a0[\u00a0]: Copied! <pre>global_regression(\n    (input_folder, \"*.tif\"),\n    (global_folder, \"$_Global.tif\"),\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n    save_as_cog=True,\n    # specify_model_images=(\"include\", ['Worldview_2016-09-22']), # Global matching all input images to the spectral profile of any number of specified images (regression will still be based on overlapping areas, however, only the *included* images statistics will influence the solution)\n    # custom_mean_factor=3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together (applied when creating model)\n    custom_std_factor=3,\n    save_adjustments=os.path.join(global_folder, \"GlobalAdjustments.json\"), # Start from precomputed statistics for images whole and overlap stats\n    # load_adjustments=os.path.join(global_folder, \"GlobalAdjustments.json\"), # Load Statistics\n    )\n</pre>  global_regression(     (input_folder, \"*.tif\"),     (global_folder, \"$_Global.tif\"),     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers),     save_as_cog=True,     # specify_model_images=(\"include\", ['Worldview_2016-09-22']), # Global matching all input images to the spectral profile of any number of specified images (regression will still be based on overlapping areas, however, only the *included* images statistics will influence the solution)     # custom_mean_factor=3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together (applied when creating model)     custom_std_factor=3,     save_adjustments=os.path.join(global_folder, \"GlobalAdjustments.json\"), # Start from precomputed statistics for images whole and overlap stats     # load_adjustments=os.path.join(global_folder, \"GlobalAdjustments.json\"), # Load Statistics     ) In\u00a0[\u00a0]: Copied! <pre>reference_map_path = os.path.join(local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\")\nlocal_maps_path = os.path.join(local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\")\nsearched_paths = search_paths(os.path.join(local_folder, \"LocalBlockMap\"), \"*.tif\")\n\nlocal_block_adjustment(\n    (global_folder, \"*.tif\"),\n    (local_folder, \"$_Local.tif\"),\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n    save_as_cog=True,\n    number_of_blocks=\"coefficient_of_variation\", # Target number of blocks\n    # override_bounds_canvas_coords = (193011.1444011169369332, 2184419.3597142999060452, 205679.2836037494416814, 2198309.8632259583100677), # Local match with a larger canvas than images bounds (perhaps to anticipate adding additional imagery so you don't have to recalculate local block maps each rematch)\n    save_block_maps=(reference_map_path, local_maps_path),\n    # load_block_maps=(reference_map_path, searched_paths), # Local match from saved block maps (this code just passes in local maps, but if a reference map is passed in, it will match images to the reference map without recomputing it)\n    )\n</pre> reference_map_path = os.path.join(local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\") local_maps_path = os.path.join(local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\") searched_paths = search_paths(os.path.join(local_folder, \"LocalBlockMap\"), \"*.tif\")  local_block_adjustment(     (global_folder, \"*.tif\"),     (local_folder, \"$_Local.tif\"),     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers),     save_as_cog=True,     number_of_blocks=\"coefficient_of_variation\", # Target number of blocks     # override_bounds_canvas_coords = (193011.1444011169369332, 2184419.3597142999060452, 205679.2836037494416814, 2198309.8632259583100677), # Local match with a larger canvas than images bounds (perhaps to anticipate adding additional imagery so you don't have to recalculate local block maps each rematch)     save_block_maps=(reference_map_path, local_maps_path),     # load_block_maps=(reference_map_path, searched_paths), # Local match from saved block maps (this code just passes in local maps, but if a reference map is passed in, it will match images to the reference map without recomputing it)     ) In\u00a0[\u00a0]: Copied! <pre>align_rasters(\n    (local_folder, \"*.tif\"),\n    (aligned_folder, \"$_Aligned.tif\"),\n    tap=True,\n    resolution='lowest',\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n    )\n</pre>  align_rasters(     (local_folder, \"*.tif\"),     (aligned_folder, \"$_Aligned.tif\"),     tap=True,     resolution='lowest',     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers),     ) In\u00a0[\u00a0]: Copied! <pre>output_vector_mask = os.path.join(working_directory, \"ImageMasks.gpkg\")\ndebug_vectors_path = os.path.join(working_directory, \"DebugVectors.gpkg\")\n\nvoronoi_center_seamline(\n    (aligned_folder, \"*.tif\"),\n    output_vector_mask,\n    image_field_name='image',\n    debug_logs=True,\n    debug_vectors_path=debug_vectors_path,\n    )\n</pre> output_vector_mask = os.path.join(working_directory, \"ImageMasks.gpkg\") debug_vectors_path = os.path.join(working_directory, \"DebugVectors.gpkg\")  voronoi_center_seamline(     (aligned_folder, \"*.tif\"),     output_vector_mask,     image_field_name='image',     debug_logs=True,     debug_vectors_path=debug_vectors_path,     ) In\u00a0[\u00a0]: Copied! <pre>input_mask_path = os.path.join(working_directory, \"ImageMasks.gpkg\")\n\nmask_rasters(\n    (aligned_folder, \"*.tif\"),\n    (clipped_folder, \"$_Clipped.tif\"),\n    vector_mask=(\"include\", input_mask_path, \"image\"),\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n    )\n</pre> input_mask_path = os.path.join(working_directory, \"ImageMasks.gpkg\")  mask_rasters(     (aligned_folder, \"*.tif\"),     (clipped_folder, \"$_Clipped.tif\"),     vector_mask=(\"include\", input_mask_path, \"image\"),     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers),     ) In\u00a0[\u00a0]: Copied! <pre>output_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")\n\nmerge_rasters(\n    (clipped_folder, \"*.tif\"),\n    output_merged_image_path,\n    debug_logs=True,\n    window_size=window_size,\n    image_parallel_workers=(\"process\", num_image_workers),\n    window_parallel_workers=(\"process\", num_window_workers),\n)\n</pre> output_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")  merge_rasters(     (clipped_folder, \"*.tif\"),     output_merged_image_path,     debug_logs=True,     window_size=window_size,     image_parallel_workers=(\"process\", num_image_workers),     window_parallel_workers=(\"process\", num_window_workers), ) In\u00a0[\u00a0]: Copied! <pre># Compare image spectral profiles\ncompare_image_spectral_profiles(\n    input_image_dict={\n        os.path.splitext(os.path.basename(p))[0]: p\n        for p in search_paths(local_folder, \"*.tif\")\n    },\n    output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n)\n\n# Compare image spectral profiles pairs\nbefore_paths = search_paths(input_folder, \"*.tif\")\nafter_paths = search_paths(local_folder, \"*.tif\")\n\nimage_pairs = {\n    os.path.splitext(os.path.basename(b))[0]: [b, a]\n    for b, a in zip(sorted(before_paths), sorted(after_paths))\n    }\n\ncompare_image_spectral_profiles_pairs(\n    image_pairs,\n    os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n    )\n\n# Compare spatial spectral difference band average\ninput_paths = search_paths(input_folder, \"*.tif\")\nlocal_paths = search_paths(local_folder, \"*.tif\")\nbefore_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))\n\ncompare_spatial_spectral_difference_band_average(\n    input_images=[before_path, after_path],\n    output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),\n    title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",\n    diff_label=\"Reflectance Difference (0\u201310,000)\",\n    subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\",\n)\n</pre>  # Compare image spectral profiles compare_image_spectral_profiles(     input_image_dict={         os.path.splitext(os.path.basename(p))[0]: p         for p in search_paths(local_folder, \"*.tif\")     },     output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles\",     xlabel='Band',     ylabel='Reflectance(0-10,000)', )  # Compare image spectral profiles pairs before_paths = search_paths(input_folder, \"*.tif\") after_paths = search_paths(local_folder, \"*.tif\")  image_pairs = {     os.path.splitext(os.path.basename(b))[0]: [b, a]     for b, a in zip(sorted(before_paths), sorted(after_paths))     }  compare_image_spectral_profiles_pairs(     image_pairs,     os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",     xlabel='Band',     ylabel='Reflectance(0-10,000)',     )  # Compare spatial spectral difference band average input_paths = search_paths(input_folder, \"*.tif\") local_paths = search_paths(local_folder, \"*.tif\") before_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))  compare_spatial_spectral_difference_band_average(     input_images=[before_path, after_path],     output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),     title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",     diff_label=\"Reflectance Difference (0\u201310,000)\",     subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\", )"},{"location":"examples/temp/","title":"Temp","text":"In\u00a0[\u00a0]: Copied! <pre>import os\n\nfrom spectralmatch import *\n\n# Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder\nworking_directory = '/Users/kanoalindiwe/Downloads/Projects/spectralmatch/docs/examples/data_worldview'\nprint(working_directory)\n\ninput_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\naligned_folder = os.path.join(working_directory, \"Aligned\")\nclipped_folder = os.path.join(working_directory, \"Clipped\")\nstats_folder = os.path.join(working_directory, \"Stats\")\nnew_global_folder = os.path.join(working_directory, \"GlobalMatch_New\")\n\nwindow_size = 128\nnum_workers = 5\n</pre> import os  from spectralmatch import *  # Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview folder working_directory = '/Users/kanoalindiwe/Downloads/Projects/spectralmatch/docs/examples/data_worldview' print(working_directory)  input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"GlobalMatch\") local_folder = os.path.join(working_directory, \"LocalMatch\") aligned_folder = os.path.join(working_directory, \"Aligned\") clipped_folder = os.path.join(working_directory, \"Clipped\") stats_folder = os.path.join(working_directory, \"Stats\") new_global_folder = os.path.join(working_directory, \"GlobalMatch_New\")  window_size = 128 num_workers = 5 In\u00a0[\u00a0]: Copied! <pre># global_regression(\n#     (input_folder, \"*.tif\"),\n#     (global_folder, \"$_Global.tif\"),\n#     debug_logs=True,\n#     window_size=window_size,\n#     image_parallel_workers=(\"process\", num_workers),\n#     window_parallel_workers=(\"process\", num_workers),\n#     )\n#\n# # %% Local matching\n# local_block_adjustment(\n#     (global_folder, \"*.tif\"),\n#     (local_folder, \"$_Local.tif\"),\n#     number_of_blocks=100,\n#     debug_logs=True,\n#     window_size=window_size,\n#     image_parallel_workers=(\"process\", num_workers),\n#     window_parallel_workers=(\"process\", num_workers),\n#     )\n</pre>  # global_regression( #     (input_folder, \"*.tif\"), #     (global_folder, \"$_Global.tif\"), #     debug_logs=True, #     window_size=window_size, #     image_parallel_workers=(\"process\", num_workers), #     window_parallel_workers=(\"process\", num_workers), #     ) # # # %% Local matching # local_block_adjustment( #     (global_folder, \"*.tif\"), #     (local_folder, \"$_Local.tif\"), #     number_of_blocks=100, #     debug_logs=True, #     window_size=window_size, #     image_parallel_workers=(\"process\", num_workers), #     window_parallel_workers=(\"process\", num_workers), #     ) In\u00a0[\u00a0]: Copied! <pre># align_rasters(\n#     (input_folder, \"*.tif\"),\n#     (aligned_folder, \"$_Aligned.tif\"),\n#     tap=True,\n#     resolution='highest',\n#     debug_logs=True,\n#     window_size=window_size,\n#     image_parallel_workers=(\"process\", num_workers),\n#     window_parallel_workers=(\"process\", num_workers),\n#     )\n\n\n# mask_rasters(\n#     (aligned_folder, \"*.tif\"),\n#     (clipped_folder, \"$_Clipped.tif\"),\n#     vector_mask=(\"include\", os.path.join(working_directory, \"ImageMasks.gpkg\"), \"image\"),\n#     debug_logs=True,\n#     window_size=window_size,\n#     image_parallel_workers=(\"process\", num_workers),\n#     window_parallel_workers=(\"process\", num_workers),\n#     )\n\n\noutput_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")\n\nmerge_rasters(\n    (clipped_folder, \"*.tif\"),\n    output_merged_image_path,\n    window_size=window_size,\n    debug_logs=True,\n    image_parallel_workers=(\"process\", num_workers),\n)\n</pre>  # align_rasters( #     (input_folder, \"*.tif\"), #     (aligned_folder, \"$_Aligned.tif\"), #     tap=True, #     resolution='highest', #     debug_logs=True, #     window_size=window_size, #     image_parallel_workers=(\"process\", num_workers), #     window_parallel_workers=(\"process\", num_workers), #     )   # mask_rasters( #     (aligned_folder, \"*.tif\"), #     (clipped_folder, \"$_Clipped.tif\"), #     vector_mask=(\"include\", os.path.join(working_directory, \"ImageMasks.gpkg\"), \"image\"), #     debug_logs=True, #     window_size=window_size, #     image_parallel_workers=(\"process\", num_workers), #     window_parallel_workers=(\"process\", num_workers), #     )   output_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")  merge_rasters(     (clipped_folder, \"*.tif\"),     output_merged_image_path,     window_size=window_size,     debug_logs=True,     image_parallel_workers=(\"process\", num_workers), )"}]}