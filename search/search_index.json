{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"spectralmatch: A toolkit to perform Relative Radiometric Normalization, with utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, and statistics","text":"<p>[!IMPORTANT] This library is experimental and still under heavy development.</p>"},{"location":"#overview","title":"Overview","text":"<p>spectralmatch provides a Python library and QGIS plugin with multiple algorythms to perform Relative Radiometric Normalization (RRN). It also includes utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, statistics, preprocessing, and more.</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p>Automated: Works without manual intervention, making it ideal for large-scale applications.</p> </li> <li> <p>Consistent Multi-Image Analysis: Ensures uniformity across images by applying systematic corrections with minimal spectral distortion.</p> </li> <li> <p>Seamlessly Blended: Creates smooth transitions between images without visible seams.</p> </li> <li> <p>Unit Agnostic: Works with any pixel unit and preserves the spectral information for accurate analysis. This inlcludes negative numbers and reflectance.</p> </li> <li> <p>Better Input for Machine Learning Models: Provides high-quality, unbiased data for AI and analytical workflows.</p> </li> <li> <p>Minimizes Color Bias: Avoids excessive color normalization and does not rely on a strict reference image.</p> </li> <li> <p>Sensor Agnostic: Works with all optical sensors. In addition, images from differnt sensors can be combined for multisensor analysis.</p> </li> <li> <p>Parallel Processing: Optimized for modern CPUs to handle large datasets efficiently.</p> </li> <li> <p>Large-Scale Mosaics: Designed to process and blend vast image collections effectively.</p> </li> <li>Time Series: Normalize images across time with to compare spectral changes.</li> </ul>"},{"location":"#current-matching-algorithms","title":"Current Matching Algorithms","text":""},{"location":"#global-to-local-matching","title":"Global to local matching","text":"<p>This technique is derived from 'An auto-adapting global-to-local color balancing method for optical imagery mosaic' by Yu et al., 2017 (DOI: 10.1016/j.isprsjprs.2017.08.002). It is particularly useful for very high-resolution imagery (satellite or otherwise) and works in a two phase process. First, this method applies least squares regression to estimate scale and offset parameters that align the histograms of all images toward a shared spectral center. This is achieved by constructing a global model based on the overlapping areas of adjacent images, where the spectral relationships are defined. This global model ensures that each image conforms to a consistent radiometric baseline while preserving overall color fidelity. However, global correction alone cannot capture intra-image variability so a second local adjustment phase is performed. The overlap areas are divided into smaller blocks, and each block\u2019s mean is used to fine-tune the color correction. This block-wise tuning helps maintain local contrast and reduces visible seams, resulting in seamless and spectrally consistent mosaics with minimal distortion.</p> <p> Shows the average spectral profile of two WorldView 3 images before and after global to local matching.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<ul> <li> <p>Consistent Spectral Profile: The true spectral response of overlapping areas remains the same throughout the images.</p> </li> <li> <p>Least Squares Modeling: A least squares approach can effectively model and fit all images' spectral profiles.</p> </li> <li> <p>Scale and Offset Adjustment: Applying scale and offset corrections can effectively harmonize images.</p> </li> <li> <p>Minimized Color Differences: The best color correction is achieved when color differences are minimized.</p> </li> <li> <p>Geometric Alignment: Images are assumed to be geometrically aligned with known relative positions.</p> </li> <li> <p>Global Consistency: Overlapping color differences are consistent across the entire image.</p> </li> <li> <p>Local Adjustments: Block-level color differences result from the global application of adjustments.</p> </li> </ul>"},{"location":"#quick-installation-detailed-instructions-are-in-the-docs","title":"Quick Installation (Detailed instructions are in the docs)","text":""},{"location":"#installation-as-a-qgis-plugin","title":"Installation as a QGIS Plugin","text":"<p>Install the spectralmatch plugin in QGIS and use it in the Processing Toolbox.</p>"},{"location":"#installation-as-a-python-library","title":"Installation as a Python Library","text":"<p>Before installing, ensure you have the following system-level prerequisites: <code>Python \u2265 3.10</code>, <code>pip</code>, <code>PROJ \u2265 9.3</code>, and <code>GDAL = 3.10.2</code>. Use this command to install the library:</p> <pre><code>pip install spectralmatch\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at spectralmatch.github.io/spectralmatch/.</p>"},{"location":"#contributing-guide","title":"Contributing Guide","text":"<p>Contributing Guide is available at spectralmatch.github.io/spectralmatch/contributing.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See LICENSE for details.</p>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>This project includes a Makefile to streamline development tasks. Makefiles allow you to automate and organize common tasks, in this case to help serve and deploy documentation, manage version tags, format and lint code, and run tests.</p> <p>Installation instructions are on their own page</p>"},{"location":"contributing/#collaboration-instructions","title":"Collaboration Instructions","text":"<p>We welcome all contributions the project! Please be respectful and work towards improving the library. To get started:</p> <ol> <li> <p>Create an issue describing the feature or bug or just to ask a question. Provide relevant context, desired timeline, any assistance needed, who will be responsible for the work, anticipated results, and any other details.</p> </li> <li> <p>Fork the repository and create a new feature branch.</p> </li> <li> <p>Make your changes and add any necessary tests.</p> </li> <li> <p>Open a Pull Request against the main repository.</p> </li> </ol>"},{"location":"contributing/#design-guidelines-and-philosophy","title":"Design Guidelines and Philosophy","text":""},{"location":"contributing/#remember-to","title":"Remember to:","text":"<ul> <li>Keep code concise and simple</li> <li>Adapt code for large datasets with windows, multiprocessing, progressive computations, etc</li> <li>Keep code modular and have descriptive names</li> <li>Use PEP 8 code formatting</li> <li>Use functions that are already created when possible</li> </ul>"},{"location":"contributing/#when-building-a-function","title":"When building a function:","text":"<ul> <li>Combine similar params into one multi-value parameter</li> <li>Start functions by printing \"Start {process}\"</li> <li>Use similar naming convention and input parameter format as other functions. For example: vector_mask_path, window_size, debug_logs, custom_nodata_value, parallel_workers, calculation_dtype, etc.</li> <li>If True, debug_logs param should be used to enable printing info about the process</li> <li>Create docstrings (Google style), tests, and update the docs for new functionality</li> </ul>"},{"location":"contributing/#file-cleanup","title":"File Cleanup","text":"<p>Temporary generated files can be deleted once they are no longer needed via this command: <pre><code>make clean\n</code></pre></p>"},{"location":"contributing/#docs","title":"Docs","text":""},{"location":"contributing/#serve-docs-locally","title":"Serve docs locally","text":"<p>Runs a local dev server at http://localhost:8000. <pre><code>make docs-serve\n</code></pre></p>"},{"location":"contributing/#build-static-site","title":"Build static site","text":"<p>Generates the static site into the site/ folder.</p> <pre><code>make docs-build\n</code></pre>"},{"location":"contributing/#deploy-to-github-pages","title":"Deploy to GitHub Pages","text":"<p>Deploys built site using mkdocs gh-deploy. <pre><code>make docs-deploy\n</code></pre></p>"},{"location":"contributing/#versioning","title":"Versioning","text":"<p>Uses git tag to create annotated version tags and push them. This also syncs to Pypi. New versions will be released when the maintainer determines sufficient new functionality has been added. <pre><code>make tag version=1.2.3\n</code></pre></p>"},{"location":"contributing/#code-formatting","title":"Code Formatting","text":"<p>This project uses black for code formatting and ruff for linting.</p>"},{"location":"contributing/#set-up-pre-commit-hooks-recommended","title":"Set Up Pre-commit Hooks (Recommended)","text":"<p>To maintain code consistency use this hook to check and correct code formatting automatically:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>"},{"location":"contributing/#manual-formatting","title":"Manual Formatting","text":"<p>Format code: Automatically formats all Python files with black.</p> <pre><code>make format\n</code></pre> <p>Check formatting: Checks that all code is formatted (non-zero exit code if not). <pre><code>make check-format\n</code></pre></p> <p>Lint code: Runs ruff to catch style and quality issues. <pre><code>make lint\n</code></pre></p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>pytest is used for testing. Tests will automatically be run when merging into main but they can also be run locally via: <pre><code>make test\n</code></pre></p> <p>To test a individual folder or file: <pre><code>make test-file path=path/to/folder_or_file\n</code></pre></p>"},{"location":"formats_and_requirements/","title":"File Formats and Input Requirements","text":""},{"location":"formats_and_requirements/#input-raster-requirements","title":"Input Raster Requirements","text":"<p>Input rasters must meet specific criteria to ensure compatibility during processing. These are checked by _check_raster_requirements():</p> <ul> <li>Have a valid geotransform</li> <li>Share the same coordinate reference system (CRS)</li> <li>Have an identical number of bands</li> <li>Use consistent nodata values</li> </ul> <p>Additionally, all rasters should:</p> <ul> <li>Be a <code>.tif</code> file</li> <li>Have overlap which represents the same data in each raster</li> <li>Have a consistent spectral profile </li> </ul>"},{"location":"formats_and_requirements/#regression-parameters-file","title":"Regression Parameters File","text":"<p>Regression parameters can be stored in a <code>json</code> file which includes:</p> <ul> <li>Adjustments: Per-band scale and offset values applied to each image.</li> <li>Whole Stats: Per-band mean, std, and size representing overall image statistics.</li> <li>Overlap Stats: Per-image pair mean, std, and size for overlapping geometry regions.</li> </ul> <p>The structure is a dictionary keyed by images basenames (no extension) with the following format:</p> <p><pre><code>{\n  \"image_name\": {\n    \"adjustments\": {\n      \"band_0\": {\"scale\": float, \"offset\": float},\n      ...\n    },\n    \"whole_stats\": {\n      \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n      ...\n    },\n    \"overlap_stats\": {\n      \"other_image\": {\n        \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n        ...\n      },\n      ...\n    }\n  },\n  ...\n}\n</code></pre> This format represents the following: For each image_name there are adjustment, whole_stats and overlap_stats. For each adjustments, for each band, there is scale and offset. For each whole_stats and overlap_stats, for each band, there is mean, std, and size (number of pixels). Each band key follows the format band_0, band_1, etc. Mean and std are floats and size is an integer.</p> <p>This structure is validated by <code>_validate_adjustment_model_structure()</code> before use to ensure consistency and completeness across images and bands. Global regression does not actually use 'adjustments' field because they are recalculated every run.</p>"},{"location":"formats_and_requirements/#block-maps-file","title":"Block Maps File","text":"<p>Block maps are spatial summaries of raster data, where each block represents the mean values of a group of pixels over a fixed region. They are used to reduce image resolution while preserving local radiometric characteristics, enabling efficient comparison and adjustment across images. Each map is structured as a grid of blocks with values for each spectral band. They can be saved as regular <code>geotif</code> files and together store this information: block_local_means, block_reference_mean, num_row, num_col, bounds_canvas_coords. </p> <p>There are two types of block maps, although their format is exactly the same:</p> <ul> <li>Local Block Map: Each block stores the mean value of all pixels within its boundary for a single image.</li> <li>Reference Block Map: Each block is the mean of all images means for its boundary; simply the mean of all local block maps.</li> </ul> <p>Both block maps have the shape: <code>num_row, num_col, num_bands</code>, however, there are multiple (one for each image) local block maps and only one reference block map. Once a reference block map is created it is unique to its input images and cannot be accurately modified to add additional images. However, images can be 'brought' to a reference block map even if they were not involved in its creation as long as it covers that image.</p>"},{"location":"installation/","title":"Installation Methods","text":""},{"location":"installation/#installation-as-qgis-plugin-for-easy-gui-interface","title":"Installation as QGIS Plugin for Easy GUI Interface","text":""},{"location":"installation/#1-download-and-install-qgis","title":"1. Download and install QGIS","text":""},{"location":"installation/#2-open-qgis","title":"2.  Open QGIS","text":""},{"location":"installation/#3-go-to-plugins-manage-and-install-plugins","title":"3.  Go to Plugins \u2192 Manage and Install Plugins\u2026","text":""},{"location":"installation/#4-find-spectralmatch-in-the-list-install-and-enable-it","title":"4.  Find spectralmatch in the list, install, and enable it","text":""},{"location":"installation/#5-find-the-plugin-in-the-processing-toolbox","title":"5.  Find the plugin in the Processing Toolbox","text":""},{"location":"installation/#installation-as-a-python-library-for-use-in-code-recommended","title":"Installation as a Python Library for use in Code (Recommended)","text":""},{"location":"installation/#1-system-requirements","title":"1. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL \u2265 3.6</li> <li>pip</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python=3.10 \"gdal&gt;=3.6\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"installation/#2-install-spectralmatch","title":"2. Install spectralmatch","text":"<p>You can automatically install the library via PyPI. (this method installs only the core code as a library):</p> <pre><code>pip install spectralmatch\n</code></pre>"},{"location":"installation/#3-run-an-example-and-modify-for-your-use-optional","title":"3. Run an example and modify for your use (optional)","text":"<p>Example scripts are provided to verify a successful installation and help you get started quickly in the repository at <code>/docs/examples</code> and downloadable via this <code>link</code>.</p>"},{"location":"installation/#installation-as-python-code-for-development-and-customization","title":"Installation as Python Code for Development and Customization","text":""},{"location":"installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\n</code></pre> <p>Assuming you have Make installed, you can then run <code>make install-setup</code> to automatically complete the remaining setup steps.</p>"},{"location":"installation/#2-system-requirements","title":"2. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL \u2265 3.6</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python=3.10 \"gdal=3.10.2\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"installation/#3-install-dependancies-optional-dev-and-docs-dependancies","title":"3. Install Dependancies (Optional Dev and Docs Dependancies)","text":"<p>The <code>pyproject.toml</code> defines core dependancies to run the library and optional dev, and docs dependancies.</p> <pre><code>pip install . # normal dependencies\npip install -e \".[dev]\"   # developer dependencies\npip install -e \".[docs]\"  # documentation dependencies\n</code></pre>"},{"location":"installation/#4-read-the-contributing-guide-if-you-aim-to-contribute","title":"4. Read the Contributing Guide if you aim to contribute","text":""},{"location":"rrn_methods/","title":"Dimensions of Relative Radiometric Normalization (RRN) Methods","text":"<p>RRN methods differ not only in the algorithms used to adjust image values but also in the requirements images must have and other techniques that can be used in conjunction. The following taxonomy summarizes the core dimensions along which RRN techniques vary:</p> <ul> <li>Matching algorithm: The core transformation applied to align radiometry between images.</li> <li>Geometric alignment required: The level of spatial alignment necessary for the method.</li> <li>PIF/RCS selection strategies: How pseudo-invariant features/control sets are identified.</li> <li>Adjustment scope: How corrections are applied to the images.</li> <li>Overlap: Whether the method requires overlapping pixels.</li> <li>Pixel units: The radiometric units the method is able to operate on.</li> <li>Bands: Whether bands relationships are preserved.</li> <li>Target reference: What the target image is normalized to.</li> </ul>"},{"location":"rrn_methods/#the-dimensions","title":"The dimensions","text":"<ul> <li>Matching algorithm:<ul> <li>Histogram Matching (HM) (lookup table)</li> <li>Minimum\u2013Maximum Normalization (min-max)</li> <li>Mean\u2013Standard Deviation Normalization (gain-offset)</li> <li>CCA/KCCA-Based Normalization (matrix)</li> <li>Global Linear Regression (gain-offset)</li> <li>Gamma correction (power function)</li> <li>Dodging (low-pass brightness correction)</li> <li>Illumination Equalization (modeled lighting correction)</li> </ul> </li> <li>Minimum geometric alignment:<ul> <li>None (no spatial info)</li> <li>Moderate (A few pixels)</li> <li>Co-registration (pixel-wise)</li> </ul> </li> <li>Pseudo-Invariant Feature (PIFs)/Radiometric Control Sets (RCS) selection strategies:<ul> <li>None<ul> <li>Whole image</li> <li>Overlapping area</li> </ul> </li> <li>Manual<ul> <li>Manual polygons or pixels</li> <li>Manual threshold</li> </ul> </li> <li>Statistical<ul> <li>Dark/Bright Set (DB)</li> <li>Band indexes</li> <li>No-change  Scattergrams\u00a0(NC)</li> <li>Multivariate Alteration Detection (MAD)</li> <li>Iteratively Reweighted MAD (IR-MAD)</li> <li>Multi-Rule-Based Normalization</li> </ul> </li> <li>Geometric<ul> <li>Feature-Based (Keypoint) RRN</li> <li>Location-Independent RRN (LIRRN)</li> </ul> </li> </ul> </li> <li>Adjustment scope:<ul> <li>Global</li> <li>Blocks/interpolated blocks</li> <li>CCA space</li> <li>Blur</li> <li>Surface model</li> </ul> </li> <li>Overlap:<ul> <li>Required</li> <li>Not required</li> </ul> </li> <li>Pixel units:<ul> <li>Any</li> <li>Reflectance</li> <li>Radiance</li> <li>DN</li> </ul> </li> <li>Bands:<ul> <li>Independent</li> <li>Correlated</li> </ul> </li> <li>Target reference:<ul> <li>Single image</li> <li>Virtual central tendency</li> <li>Learned distribution</li> </ul> </li> </ul>"},{"location":"api/handlers/","title":"Data Handlers for IO","text":""},{"location":"api/handlers/#spectralmatch.handlers.create_paths","title":"<code>create_paths(output_folder, template, paths_or_bases, debug_logs=False, replace_symbol='$', create_folders=False)</code>","text":"<p>Create output paths using a filename template and a list of reference paths or names.</p> <p>Parameters:</p> Name Type Description Default <code>output_folder</code> <code>str</code> <p>Directory to store output files.</p> required <code>template</code> <code>str</code> <p>Filename template using replace_symbol as placeholder (e.g., \"$_processed.tif\").</p> required <code>paths_or_bases</code> <code>List[str]</code> <p>List of full paths or bare names to derive replace_symbol from. Inclusion of '/' or '' indicates a path.</p> required <code>debug_logs</code> <code>bool</code> <p>Whether to print the created paths.</p> <code>False</code> <code>replace_symbol</code> <code>str</code> <p>Symbol to replace in the template.</p> <code>'$'</code> <code>create_folders</code> <code>bool</code> <p>Whether to create output folders if they don't exist.'</p> <code>False</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of constructed file paths.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def create_paths(\n    output_folder: str,\n    template: str,\n    paths_or_bases: List[str],\n    debug_logs: bool = False,\n    replace_symbol: str = \"$\",\n    create_folders: bool = False,\n    ) -&gt; List[str]:\n    \"\"\"\n    Create output paths using a filename template and a list of reference paths or names.\n\n    Args:\n        output_folder (str): Directory to store output files.\n        template (str): Filename template using replace_symbol as placeholder (e.g., \"$_processed.tif\").\n        paths_or_bases (List[str]): List of full paths or bare names to derive replace_symbol from. Inclusion of '/' or '\\' indicates a path.\n        debug_logs (bool): Whether to print the created paths.\n        replace_symbol (str): Symbol to replace in the template.\n        create_folders (bool): Whether to create output folders if they don't exist.'\n\n    Returns:\n        List[str]: List of constructed file paths.\n    \"\"\"\n    output_paths = []\n    for ref in paths_or_bases:\n        base = os.path.splitext(os.path.basename(ref))[0] if ('/' in ref or '\\\\' in ref) else os.path.splitext(ref)[0]\n        filename = template.replace(replace_symbol, base)\n        path = os.path.join(output_folder, filename)\n        output_paths.append(path)\n\n    if create_folders:\n        for path in output_paths:\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n    return output_paths\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.match_paths","title":"<code>match_paths(input_match_paths, reference_paths, match_regex, debug_logs=False)</code>","text":"<p>Match <code>reference_paths</code> to <code>input_match_paths</code> using a regex applied to the basenames of <code>input_match_paths</code>. The extracted key must be a substring of the reference filename.</p> <p>Parameters:</p> Name Type Description Default <code>input_match_paths</code> <code>List[str]</code> <p>List of candidate paths to extract keys from.</p> required <code>reference_paths</code> <code>List[str]</code> <p>List of reference paths to align to.</p> required <code>match_regex</code> <code>str</code> <p>Regex applied to basenames of input_match_paths to extract a key to match via inclusion in reference_paths (e.g. r\"(.*)_LocalMatch.gpkg$\").</p> required <code>debug_logs</code> <code>bool</code> <p>If True, print matched and unmatched file basenames.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[Optional[str]]</code> <p>List[Optional[str]]: A list the same length as <code>reference_paths</code> where each</p> <code>List[Optional[str]]</code> <p>element is the matched path from <code>input_match_paths</code> or None.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If output list length does not match reference_paths length.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def match_paths(\n    input_match_paths: List[str],\n    reference_paths: List[str],\n    match_regex: str,\n    debug_logs: bool = False,\n    ) -&gt; List[Optional[str]]:\n    \"\"\"\n    Match `reference_paths` to `input_match_paths` using a regex applied to the basenames of `input_match_paths`. The extracted key must be a substring of the reference filename.\n\n    Args:\n        input_match_paths (List[str]): List of candidate paths to extract keys from.\n        reference_paths (List[str]): List of reference paths to align to.\n        match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via *inclusion* in reference_paths (e.g. r\"(.*)_LocalMatch\\.gpkg$\").\n        debug_logs (bool): If True, print matched and unmatched file basenames.\n\n    Returns:\n        List[Optional[str]]: A list the same length as `reference_paths` where each\n        element is the matched path from `input_match_paths` or None.\n\n    Raises:\n        ValueError: If output list length does not match reference_paths length.\n    \"\"\"\n    pattern = re.compile(match_regex)\n    match_keys = {}\n    used_matches = set()\n\n    # Extract keys from input_match_paths\n    for mpath in input_match_paths:\n        basename = os.path.basename(mpath)\n        match = pattern.search(basename)\n        if not match:\n            continue\n        key = match.group(1) if match.groups() else match.group(0)\n        match_keys[key] = mpath\n\n    # Match each reference path\n    matched_list: List[Optional[str]] = []\n    for rpath in reference_paths:\n        rbase = os.path.basename(rpath)\n        matched = None\n        for key, mpath in match_keys.items():\n            if key in rbase:\n                matched = mpath\n                used_matches.add(mpath)\n                break\n        matched_list.append(matched)\n\n    # Validate output length\n    if len(matched_list) != len(reference_paths):\n        raise ValueError(\"Matched list length does not match reference_paths length.\")\n\n    return matched_list\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.merge_rasters","title":"<code>merge_rasters(input_image_paths, output_image_path, window_size=None, debug_logs=False, output_dtype=None)</code>","text":"<p>Merges multiple input rasters into a single mosaic file by aligning each image geospatially and writing them in the correct location using tiling.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_paths</code> <code>List[str]</code> <p>Paths to input raster images.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the merged output raster.</p> required <code>window_size</code> <code>int | Tuple[int, int] | None</code> <p>Tile size for memory-efficient processing.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <code>output_dtype</code> <code>str | None</code> <p>Output dtype for output raster. None will default to input raster type.</p> <code>None</code> Output <p>A geospatially aligned, merged raster is saved to <code>output_image_path</code>.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def merge_rasters(\n    input_image_paths: List[str],\n    output_image_path: str,\n    window_size: Optional[int | Tuple[int, int]] = None,\n    debug_logs: bool = False,\n    output_dtype: str | None = None,\n    ) -&gt; None:\n    \"\"\"\n    Merges multiple input rasters into a single mosaic file by aligning each image geospatially and writing them in the correct location using tiling.\n\n    Args:\n        input_image_paths (List[str]): Paths to input raster images.\n        output_image_path (str): Path to save the merged output raster.\n        window_size (int | Tuple[int, int] | None, optional): Tile size for memory-efficient processing.\n        debug_logs (bool, optional): Enable debug logging.\n        output_dtype (str | None, optional): Output dtype for output raster. None will default to input raster type.\n\n    Output:\n        A geospatially aligned, merged raster is saved to `output_image_path`.\n    \"\"\"\n    if debug_logs: print('Start merging')\n    if not os.path.exists(os.path.dirname(output_image_path)):\n        os.makedirs(os.path.dirname(output_image_path))\n\n    if isinstance(window_size, int):\n        window_size = (window_size, window_size)\n\n    # Read metadata and calculate combined bounds and resolution\n    all_bounds = []\n    all_res = []\n    crs = None\n    dtype = None\n    count = None\n\n    for path in input_image_paths:\n        with rasterio.open(path) as src:\n            nodata_value = src.nodata\n\n    for path in input_image_paths:\n        with rasterio.open(path) as src:\n            all_bounds.append(src.bounds)\n            all_res.append(src.res)\n            if crs is None:\n                crs = src.crs\n                dtype = output_dtype or src.dtypes[0]\n                count = src.count\n\n    minx = min(b.left for b in all_bounds)\n    miny = min(b.bottom for b in all_bounds)\n    maxx = max(b.right for b in all_bounds)\n    maxy = max(b.top for b in all_bounds)\n\n    res_x, res_y = all_res[0]  # Assume same resolution across rasters\n    width = int(np.ceil((maxx - minx) / res_x))\n    height = int(np.ceil((maxy - miny) / res_y))\n    transform = from_origin(minx, maxy, res_x, res_y)\n\n    if window_size:\n        windows = list(_create_windows(width, height, *window_size))\n    else:\n        windows = [Window(0, 0, width, height)]\n\n    profile = {\n        \"driver\": \"GTiff\",\n        \"height\": height,\n        \"width\": width,\n        \"count\": count,\n        \"dtype\": dtype,\n        \"crs\": crs,\n        \"transform\": transform,\n        \"nodata\": nodata_value or None\n    }\n    # if debug_logs: print(f\"xStart:yStart xSizeXySize ({len(windows)} windows): \", end=\"\")\n    with rasterio.open(output_image_path, 'w', **profile) as dst:\n        for window in windows:\n            win_transform = rasterio.windows.transform(window, transform)\n            win_bounds = BoundingBox(*rasterio.windows.bounds(window, transform))\n            merged_data = np.zeros((count, window.height, window.width), dtype=dtype)\n\n            for path in input_image_paths:\n                with rasterio.open(path) as src:\n                    src_bounds = src.bounds\n                    if (\n                            src_bounds.right &lt;= win_bounds.left or\n                            src_bounds.left &gt;= win_bounds.right or\n                            src_bounds.top &lt;= win_bounds.bottom or\n                            src_bounds.bottom &gt;= win_bounds.top\n                    ):\n                        continue\n                    try:\n                        src_window = rasterio.windows.from_bounds(\n                            *win_bounds,\n                            transform=src.transform\n                        )\n                        src_data = src.read(\n                            window=src_window,\n                            out_shape=(count, window.height, window.width),\n                            resampling=Resampling.nearest\n                        )\n\n                        nodata_val = src.nodata\n                        if nodata_val is not None:\n                            mask = ~(np.isclose(src_data, nodata_val))\n                        else:\n                            mask = (src_data != 0)\n\n                        merged_data = np.where(mask, src_data, merged_data)\n\n                    except Exception as e:\n                        if debug_logs:\n                            print(f\"Skipping {path} in window {window} due to error: {e}\")\n\n            dst.write(merged_data, window=window)\n            # if debug_logs: print(f\"{window.col_off}:{window.row_off} {window.width}x{window.height}, \", end=\"\", flush=True)\n    if debug_logs:\n        print(\"Done merging\")\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.merge_vectors","title":"<code>merge_vectors(input_vector_paths, merged_vector_path, method, debug_logs=False, create_name_attribute=None)</code>","text":"<p>Merge multiple vector files using the specified geometric method.</p> <p>Parameters:</p> Name Type Description Default <code>input_vector_paths</code> <code>List[str]</code> <p>Paths to input vector files.</p> required <code>merged_vector_path</code> <code>str</code> <p>Path to save merged output.</p> required <code>method</code> <code>Literal['intersection', 'union', 'keep_all']</code> <p>Merge strategy.</p> required <code>debug_logs</code> <code>bool</code> <p>If True, print debug information.</p> <code>False</code> <code>create_name_attribute</code> <code>Optional[Tuple[str, str]]</code> <p>Tuple of (field_name, separator). If set, adds a field with all input filenames (no extension), joined by separator.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def merge_vectors(\n        input_vector_paths: List[str],\n        merged_vector_path: str,\n        method: Literal[\"intersection\", \"union\", \"keep_all\"],\n        debug_logs: bool = False,\n        create_name_attribute: Optional[Tuple[str, str]] = None,\n) -&gt; None:\n    \"\"\"\n    Merge multiple vector files using the specified geometric method.\n\n    Args:\n        input_vector_paths (List[str]): Paths to input vector files.\n        merged_vector_path (str): Path to save merged output.\n        method (Literal[\"intersection\", \"union\", \"keep_all\"]): Merge strategy.\n        debug_logs (bool): If True, print debug information.\n        create_name_attribute (Optional[Tuple[str, str]]): Tuple of (field_name, separator).\n            If set, adds a field with all input filenames (no extension), joined by separator.\n\n    Returns:\n        None\n    \"\"\"\n    print(f\"Start vector merge\")\n\n    os.makedirs(os.path.dirname(merged_vector_path), exist_ok=True)\n\n    geoms = []\n    input_names = []\n\n    for path in input_vector_paths:\n        gdf = gpd.read_file(path)\n        if create_name_attribute:\n            name = os.path.splitext(os.path.basename(path))[0]\n            input_names.append(name)\n        geoms.append(gdf)\n\n    # Prepare the full combined name value once\n    combined_name_value = None\n    if create_name_attribute:\n        field_name, sep = create_name_attribute\n        combined_name_value = sep.join(input_names)\n\n    if method == \"keep_all\":\n        merged = gpd.GeoDataFrame(pd.concat(geoms, ignore_index=True), crs=geoms[0].crs)\n        if create_name_attribute:\n            merged[field_name] = combined_name_value\n\n    elif method == \"union\":\n        merged = gpd.GeoDataFrame(pd.concat(geoms, ignore_index=True), crs=geoms[0].crs)\n        if create_name_attribute:\n            merged[field_name] = combined_name_value\n\n    elif method == \"intersection\":\n        merged = geoms[0]\n        for gdf in geoms[1:]:\n            shared_cols = set(merged.columns).intersection(gdf.columns) - {\"geometry\"}\n            gdf = gdf.drop(columns=shared_cols)\n            merged = gpd.overlay(merged, gdf, how=\"intersection\", keep_geom_type=True)\n        if create_name_attribute:\n            merged[field_name] = combined_name_value\n\n    else:\n        raise ValueError(f\"Unsupported merge method: {method}\")\n\n    merged.to_file(merged_vector_path)\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.process_rasters","title":"<code>process_rasters(input_image_paths, output_image_paths, vector_mask_path=None, split_mask_by_attribute=None, resampling_method='nearest', tap=False, resolution='highest', window_size=None, debug_logs=False, include_touched_pixels=False)</code>","text":"<p>Masks rasters using vector geometries. If <code>split_mask_by_attribute</code> is set, geometries are filtered by the raster's basename (excluding extension) to allow per-image masking with specific matching features. If no vector is provided, rasters are processed without masking.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_paths</code> <code>List[str]</code> <p>Paths to input rasters.</p> required <code>output_image_paths</code> <code>List[str]</code> <p>Corresponding output raster paths.</p> required <code>vector_mask_path</code> <code>str | None</code> <p>Path to vector mask file (.shp, .gpkg, etc.). If None, no masking is applied.</p> <code>None</code> <code>split_mask_by_attribute</code> <code>Optional[str]</code> <p>Attribute to match raster basenames.</p> <code>None</code> <code>resampling_method</code> <code>Literal['nearest', 'bilinear', 'cubic']</code> <p>Resampling algorithm.</p> <code>'nearest'</code> <code>tap</code> <code>bool</code> <p>Snap output bounds to target-aligned pixels.</p> <code>False</code> <code>resolution</code> <code>Literal['highest', 'average', 'lowest']</code> <p>Strategy to determine target resolution.</p> <code>'highest'</code> <code>window_size</code> <code>Optional[int | Tuple[int, int]]</code> <p>Optional tile size for processing.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Print debug information if True.</p> <code>False</code> <code>include_touched_pixels</code> <code>bool</code> <p>If True, include touched pixels in output raster.</p> <code>False</code> Outputs <p>Saved masked raster files to output_image_paths.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def process_rasters(\n    input_image_paths: List[str],\n    output_image_paths: List[str],\n    vector_mask_path: str | None = None,\n    split_mask_by_attribute: Optional[str] = None,\n    resampling_method: Literal[\"nearest\", \"bilinear\", \"cubic\"] = \"nearest\",\n    tap: bool = False,\n    resolution: Literal[\"highest\", \"average\", \"lowest\"] = \"highest\",\n    window_size: int | Tuple[int, int] | None = None,\n    debug_logs: bool = False,\n    include_touched_pixels: bool = False,\n) -&gt; None:\n    \"\"\"\n    Masks rasters using vector geometries. If `split_mask_by_attribute` is set,\n    geometries are filtered by the raster's basename (excluding extension) to allow\n    per-image masking with specific matching features. If no vector is provided,\n    rasters are processed without masking.\n\n    Args:\n        input_image_paths (List[str]): Paths to input rasters.\n        output_image_paths (List[str]): Corresponding output raster paths.\n        vector_mask_path (str | None, optional): Path to vector mask file (.shp, .gpkg, etc.). If None, no masking is applied.\n        split_mask_by_attribute (Optional[str]): Attribute to match raster basenames.\n        resampling_method (Literal[\"nearest\", \"bilinear\", \"cubic\"]): Resampling algorithm.\n        tap (bool): Snap output bounds to target-aligned pixels.\n        resolution (Literal[\"highest\", \"average\", \"lowest\"]): Strategy to determine target resolution.\n        window_size (Optional[int | Tuple[int, int]]): Optional tile size for processing.\n        debug_logs (bool): Print debug information if True.\n        include_touched_pixels (bool): If True, include touched pixels in output raster.\n\n    Outputs:\n        Saved masked raster files to output_image_paths.\n    \"\"\"\n    if debug_logs: print(f'Masking {len(input_image_paths)} rasters')\n\n    gdf = gpd.read_file(vector_mask_path) if vector_mask_path else None\n\n    if isinstance(window_size, int): window_size = (window_size, window_size)\n\n    resolutions = []\n    bounds_list = []\n    crs_set = set()\n\n    for path in input_image_paths:\n        with rasterio.open(path) as src:\n            res_x, res_y = src.res\n            resolutions.append((res_x, res_y))\n            bounds_list.append(src.bounds)\n            crs_set.add(src.crs)\n\n    if len(crs_set) &gt; 1:\n        raise ValueError(\"Input rasters must have the same CRS.\")\n\n    resolutions_array = np.array(resolutions)\n    if resolution == \"highest\":\n        target_res = resolutions_array.min(axis=0)\n    elif resolution == \"lowest\":\n        target_res = resolutions_array.max(axis=0)\n    else:\n        target_res = resolutions_array.mean(axis=0)\n    if debug_logs: print(f'Resolution: {target_res}')\n\n    temp_dir = tempfile.mkdtemp()\n    tapped_paths = []\n\n    for in_path in input_image_paths:\n        raster_name = os.path.splitext(os.path.basename(in_path))[0]\n        with rasterio.open(in_path) as src:\n            profile = src.profile.copy()\n\n            if tap:\n                res_x, res_y = target_res\n                minx = np.floor(src.bounds.left / res_x) * res_x\n                miny = np.floor(src.bounds.bottom / res_y) * res_y\n                maxx = np.ceil(src.bounds.right / res_x) * res_x\n                maxy = np.ceil(src.bounds.top / res_y) * res_y\n\n                dst_width = int((maxx - minx) / res_x)\n                dst_height = int((maxy - miny) / res_y)\n                dst_transform = rasterio.transform.from_origin(minx, maxy, res_x, res_y)\n\n                profile.update({\n                    \"height\": dst_height,\n                    \"width\": dst_width,\n                    \"transform\": dst_transform\n                })\n\n                temp_path = os.path.join(temp_dir, f\"{raster_name}_tapped.tif\")\n                tapped_paths.append(temp_path)\n\n                src_windows = list(_create_windows(src.width, src.height, *window_size)) if window_size else [Window(0, 0, src.width, src.height)]\n                dst_windows = list(_create_windows(dst_width, dst_height, *window_size)) if window_size else [Window(0, 0, dst_width, dst_height)]\n\n                with rasterio.open(temp_path, \"w\", **profile) as dst:\n                    for src_win, dst_win in zip(src_windows, dst_windows):\n                        reproject(\n                            source=rasterio.band(src, list(range(1, src.count + 1))),\n                            destination=rasterio.band(dst, list(range(1, src.count + 1))),\n                            src_transform=src.window_transform(src_win),\n                            src_crs=src.crs,\n                            dst_transform=dst_transform,\n                            dst_crs=src.crs,\n                            src_nodata=src.nodata,\n                            dst_nodata=src.nodata,\n                            resampling=Resampling[resampling_method],\n                            src_window=src_win,\n                            dst_window=dst_win\n                        )\n            else:\n                tapped_paths.append(in_path)\n\n    for in_path, out_path in zip(tapped_paths, output_image_paths):\n        raster_name = os.path.splitext(os.path.basename(in_path))[0].replace('_tapped', '')\n        if debug_logs: print(f'Processing: {raster_name}')\n        with rasterio.open(in_path) as src:\n            profile = src.profile.copy()\n            os.makedirs(os.path.dirname(out_path), exist_ok=True)\n\n            if window_size:\n                windows = list(_create_windows(src.width, src.height, *window_size))\n            else:\n                windows = [Window(0, 0, src.width, src.height)]\n\n            with rasterio.open(out_path, \"w\", **profile) as dst:\n                for window in windows:\n                    data = src.read(window=window)\n                    if gdf is not None:\n                        transform = src.window_transform(window)\n\n                        if split_mask_by_attribute:\n                            filtered_gdf = gdf[gdf[split_mask_by_attribute].str.strip() == raster_name.strip()]\n                            if filtered_gdf.empty:\n                                if debug_logs: print(f\"No matching features for {raster_name}\")\n                                dst.write(data, window=window)\n                                continue\n                            geometries = filtered_gdf.geometry.values\n                        else:\n                            geometries = gdf.geometry.values\n\n                        mask_array = geometry_mask(\n                            geometries,\n                            out_shape=(data.shape[1], data.shape[2]),\n                            transform=transform,\n                            invert=True,\n                            all_touched=include_touched_pixels\n                        )\n\n                        data = np.where(mask_array, data, src.nodata)\n\n                    dst.write(data, window=window)\n\n    if tap:\n        shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.search_paths","title":"<code>search_paths(folder_path, pattern, recursive=False, match_to_paths=None, debug_logs=False)</code>","text":"<p>Search for files in a folder using a glob pattern.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>The root folder to search in.</p> required <code>pattern</code> <code>str</code> <p>A glob pattern (e.g., \".tif\", \"/.jpg\").</p> required <code>recursive</code> <code>bool</code> <p>Whether to search for files recursively.</p> <code>False</code> <code>match_to_paths</code> <code>Tuple[List[str], str]</code> <p>If provided, match <code>reference_paths</code> to <code>input_match_paths</code> using a regex applied to the basenames of <code>input_match_paths</code>. The extracted key must be a substring of the reference filename. - reference_paths (List[str]): List of reference paths to align to. - match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via inclusion in reference_paths (e.g. r\"(.*)_LocalMatch.gpkg$\").</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Whether to print the matched file paths.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: Sorted list of matched file paths.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def search_paths(\n    folder_path: str,\n    pattern: str,\n    recursive: bool = False,\n    match_to_paths: Tuple[List[str], str] | None = None,\n    debug_logs: bool = False,\n    ) -&gt; List[str]:\n    \"\"\"\n    Search for files in a folder using a glob pattern.\n\n    Args:\n        folder_path (str): The root folder to search in.\n        pattern (str): A glob pattern (e.g., \"*.tif\", \"**/*.jpg\").\n        recursive (bool, optional): Whether to search for files recursively.\n        match_to_paths (Tuple[List[str], str], optional): If provided, match `reference_paths` to `input_match_paths` using a regex applied to the basenames of `input_match_paths`. The extracted key must be a substring of the reference filename.\n         - reference_paths (List[str]): List of reference paths to align to.\n         - match_regex (str): Regex applied to basenames of input_match_paths to extract a key to match via *inclusion* in reference_paths (e.g. r\"(.*)_LocalMatch\\.gpkg$\").\n        debug_logs (bool, optional): Whether to print the matched file paths.\n\n    Returns:\n        List[str]: Sorted list of matched file paths.\n    \"\"\"\n    input_paths =  sorted(glob.glob(os.path.join(folder_path, pattern), recursive=recursive))\n\n    if match_to_paths:\n        input_paths = match_paths(input_paths, *match_to_paths)\n\n    return input_paths\n</code></pre>"},{"location":"api/mask/","title":"Create Mask and Pseudo-Invariant Features","text":""},{"location":"api/mask/#spectralmatch.mask.create_cloud_mask_with_omnicloudmask","title":"<code>create_cloud_mask_with_omnicloudmask(input_image_path, red_band_index, green_band_index, nir_band_index, output_mask_path, down_sample_m=None, debug_logs=False, **omnicloud_kwargs)</code>","text":"<p>Generates a cloud mask using OmniCloudMask from a multi-band image.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input image.</p> required <code>red_band_index</code> <code>int</code> <p>Index of the red band.</p> required <code>green_band_index</code> <code>int</code> <p>Index of the green band.</p> required <code>nir_band_index</code> <code>int</code> <p>Index of the NIR (or substitute blue) band.</p> required <code>output_mask_path</code> <code>str</code> <p>Path to save the output cloud mask GeoTIFF.</p> required <code>down_sample_m</code> <code>float</code> <p>Target resolution (in meters) to downsample the input before processing.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Debug logs to console.</p> <code>False</code> <code>omnicloud_kwargs</code> <p>Forwards key word args to OmniCloudMask predict_from_array() function. Repo here: https://github.com/DPIRD-DMA/OmniCloudMask.</p> <code>{}</code> Outputs <p>Saves a single-band cloud mask GeoTIFF at the specified path.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def create_cloud_mask_with_omnicloudmask(\n    input_image_path,\n    red_band_index,\n    green_band_index,\n    nir_band_index, # Blue band can work if nir isnt available\n    output_mask_path,\n    down_sample_m=None, # Down sample to 10 m if imagery has a spatial resolution &lt; 10 m\n    debug_logs: bool = False,\n    **omnicloud_kwargs,\n    ):\n    \"\"\"\n    Generates a cloud mask using OmniCloudMask from a multi-band image.\n\n    Args:\n        input_image_path (str): Path to the input image.\n        red_band_index (int): Index of the red band.\n        green_band_index (int): Index of the green band.\n        nir_band_index (int): Index of the NIR (or substitute blue) band.\n        output_mask_path (str): Path to save the output cloud mask GeoTIFF.\n        down_sample_m (float, optional): Target resolution (in meters) to downsample the input before processing.\n        debug_logs (bool, optional): Debug logs to console.\n        omnicloud_kwargs: Forwards key word args to OmniCloudMask predict_from_array() function. Repo here: https://github.com/DPIRD-DMA/OmniCloudMask.\n\n    Outputs:\n        Saves a single-band cloud mask GeoTIFF at the specified path.\n    \"\"\"\n\n    print(\"Start create omnicloudmask\")\n    if not os.path.exists(os.path.dirname(output_mask_path)): os.makedirs(os.path.dirname(output_mask_path), exist_ok=True)\n    with rasterio.open(input_image_path) as src:\n        if down_sample_m is not None:\n            # Compute new dimensions based on the image bounds and the desired resolution.\n            left, bottom, right, top = src.bounds\n            new_width = int((right - left) / down_sample_m)\n            new_height = int((top - bottom) / down_sample_m)\n            new_transform = from_origin(left, top, down_sample_m, down_sample_m)\n            # Read the bands with resampling to the new size.\n            red   = src.read(red_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            green = src.read(green_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            nir   = src.read(nir_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            meta = src.meta.copy()\n            meta.update({\n                'width': new_width,\n                'height': new_height,\n                'transform': new_transform,\n            })\n        else:\n            # Read without resampling.\n            red   = src.read(red_band_index)\n            green = src.read(green_band_index)\n            nir   = src.read(nir_band_index)\n            meta = src.meta.copy()\n\n        # Stack bands into an array of shape (3, height, width).\n        band_array = np.stack([red, green, nir], axis=0)\n\n    # Predict the mask (expected shape: (1, height, width))\n    pred_mask = predict_from_array(band_array, **omnicloud_kwargs)\n    pred_mask = np.squeeze(pred_mask)\n\n    # Update metadata for a single-band output.\n    meta.update({\n        'driver': 'GTiff',\n        'count': 1,\n        'dtype': pred_mask.dtype,\n        'nodata': 0,\n    })\n\n    # Write the predicted mask to a GeoTIFF file.\n    with rasterio.open(output_mask_path, 'w', **meta) as dst:\n        dst.write(pred_mask, 1)\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.create_ndvi_mask","title":"<code>create_ndvi_mask(input_image_path, output_image_path, nir_band, red_band)</code>","text":"<p>Computes NDVI from a multi-band image and saves the result as a GeoTIFF.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input image with NIR and red bands.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the NDVI output GeoTIFF.</p> required <code>nir_band</code> <code>int</code> <p>Band index for NIR (1-based).</p> required <code>red_band</code> <code>int</code> <p>Band index for red (1-based).</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the saved NDVI output.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def create_ndvi_mask(\n    input_image_path: str,\n    output_image_path: str,\n    nir_band: int,\n    red_band: int,\n    ) -&gt; str:\n    \"\"\"\n    Computes NDVI from a multi-band image and saves the result as a GeoTIFF.\n\n    Args:\n        input_image_path (str): Path to the input image with NIR and red bands.\n        output_image_path (str): Path to save the NDVI output GeoTIFF.\n        nir_band (int): Band index for NIR (1-based).\n        red_band (int): Band index for red (1-based).\n\n    Returns:\n        str: Path to the saved NDVI output.\n    \"\"\"\n\n    print(\"Start ndvi computation\")\n    if not os.path.exists(os.path.dirname(output_image_path)): os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n\n    with rasterio.open(input_image_path) as src:\n        nir = src.read(nir_band).astype(np.float32)\n        red = src.read(red_band).astype(np.float32)\n        ndvi = (nir - red) / (nir + red + 1e-9)\n\n        print(\"NIR min/max:\", np.nanmin(nir), np.nanmax(nir))\n        print(\"Red min/max:\", np.nanmin(red), np.nanmax(red))\n        print(\"NDVI min/max:\", np.nanmin(ndvi), np.nanmax(ndvi))\n\n        profile = src.profile\n        profile.update(dtype=rasterio.float32, count=1)\n\n        with rasterio.open(output_image_path, 'w', **profile) as dst:\n            dst.write(ndvi, 1)\n\n    return output_image_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.mask_image_with_vector","title":"<code>mask_image_with_vector(input_image_path, input_vector_path, output_image_path, select_features=None)</code>","text":"<p>Masks a raster using vector geometries that match a specific filter.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to input raster.</p> required <code>input_vector_path</code> <code>str | None</code> <p>Path to vector file (e.g., .shp, .gpkg), or None to skip masking.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save masked raster.</p> required <code>select_features</code> <code>Tuple[Literal['include', 'exclude'], str, any] | None</code> <p>Optional tuple: - (\"include\", field, value): Keep only pixels covered by features where field == value. - (\"exclude\", field, value): Mask out pixels covered by features where field == value. - None: Use all features and mask out covered pixels.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the masked raster file.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def mask_image_with_vector(\n    input_image_path: str,\n    input_vector_path: str | None,\n    output_image_path: str,\n    select_features: Tuple[Literal[\"include\", \"exclude\"], str, any] | None = None,\n) -&gt; str:\n    \"\"\"\n    Masks a raster using vector geometries that match a specific filter.\n\n    Args:\n        input_image_path: Path to input raster.\n        input_vector_path: Path to vector file (e.g., .shp, .gpkg), or None to skip masking.\n        output_image_path: Path to save masked raster.\n        select_features: Optional tuple:\n            - (\"include\", field, value): Keep only pixels covered by features where field == value.\n            - (\"exclude\", field, value): Mask out pixels covered by features where field == value.\n            - None: Use all features and mask out covered pixels.\n\n    Returns:\n        Path to the masked raster file.\n    \"\"\"\n    print(\"Start mask image with vector\")\n\n    os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n\n    with rasterio.open(input_image_path) as src:\n        if input_vector_path is None:\n            print(\"No vector path provided \u2014 writing unmasked copy.\")\n            with rasterio.open(output_image_path, 'w', **src.meta) as dst:\n                dst.write(src.read())\n            return output_image_path\n\n        with fiona.open(input_vector_path, 'r') as vector:\n            selected_geoms = []\n\n            for feature in vector:\n                include = True\n                if select_features:\n                    mode, field, value = select_features\n                    attr_val = feature[\"properties\"].get(field)\n                    include = attr_val == value\n\n                if include:\n                    selected_geoms.append(shape(feature[\"geometry\"]))\n\n        if not selected_geoms:\n            print(\"No matching geometries found \u2014 writing unmasked copy.\")\n            with rasterio.open(output_image_path, 'w', **src.meta) as dst:\n                dst.write(src.read())\n            return output_image_path\n\n        invert = select_features[0] == \"include\" if select_features else False\n\n        geom_union = unary_union(selected_geoms)\n        geometries = [geom_union.__geo_interface__]\n\n        mask, transform, window = raster_geometry_mask(\n            src,\n            geometries,\n            invert=invert,\n            crop=False,\n            pad=False,\n            all_touched=False,\n        )\n\n        data = src.read()\n        data[:, mask] = src.nodata if src.nodata is not None else 0\n\n        with rasterio.open(output_image_path, 'w', **src.meta) as dst:\n            dst.write(data)\n\n    return output_image_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.post_process_raster_cloud_mask_to_vector","title":"<code>post_process_raster_cloud_mask_to_vector(input_image_path, output_vector_path, minimum_mask_size_percentile=None, polygon_buffering_in_map_units=None, value_mapping=None)</code>","text":"<p>Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input cloud mask raster.</p> required <code>output_vector_path</code> <code>str</code> <p>Path to the output vector layer.</p> required <code>minimum_mask_size_percentile</code> <code>float</code> <p>Percentile threshold to filter small polygons by area.</p> <code>None</code> <code>polygon_buffering_in_map_units</code> <code>dict</code> <p>Mapping of raster values to buffer distances.</p> <code>None</code> <code>value_mapping</code> <code>dict</code> <p>Mapping of original raster values to new values before vectorization.</p> <code>None</code> Outputs <p>Saves a vector layer to the output path.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def post_process_raster_cloud_mask_to_vector(\n    input_image_path: str,\n    output_vector_path: str,\n    minimum_mask_size_percentile: float = None,\n    polygon_buffering_in_map_units: dict = None,\n    value_mapping: dict = None\n    ) -&gt; ogr.DataSource:\n    \"\"\"\n    Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.\n\n    Args:\n        input_image_path (str): Path to the input cloud mask raster.\n        output_vector_path (str): Path to the output vector layer.\n        minimum_mask_size_percentile (float, optional): Percentile threshold to filter small polygons by area.\n        polygon_buffering_in_map_units (dict, optional): Mapping of raster values to buffer distances.\n        value_mapping (dict, optional): Mapping of original raster values to new values before vectorization.\n\n    Outputs:\n        Saves a vector layer to the output path.\n    \"\"\"\n\n    print(\"Start post-processing raster cloud mask\")\n    with rasterio.open(input_image_path) as src:\n        raster_data = src.read(1)\n        transform = src.transform\n        crs = src.crs\n\n    if value_mapping is not None:\n        include_mask = np.full(raster_data.shape, True, dtype=bool)\n        mapped = np.copy(raster_data)\n        for orig_value, new_value in value_mapping.items():\n            if new_value is None:\n                include_mask &amp;= raster_data != orig_value  # Exclude from processing\n            else:\n                mapped[raster_data == orig_value] = new_value\n        raster_data = mapped\n    else:\n        include_mask = None\n\n    results = (\n        {'properties': {'value': v}, 'geometry': s}\n        for s, v in shapes(raster_data, mask=include_mask, transform=transform, connectivity=4)\n    )\n    features = list(results)\n    if not features:\n        print(\"No features were detected in the raster mask.\")\n        return None\n\n\n    gdf = gpd.GeoDataFrame.from_features(features, crs=crs)\n\n    gdf['area'] = gdf.geometry.area\n    if minimum_mask_size_percentile is not None:\n        area_threshold = np.percentile(gdf['area'], minimum_mask_size_percentile)\n        print(f\"Area threshold (at {minimum_mask_size_percentile}th percentile): {area_threshold:.2f}\")\n        gdf = gdf[gdf['area'] &gt;= area_threshold].copy()\n\n    if polygon_buffering_in_map_units is not None:\n        gdf['geometry'] = gdf.apply(\n            lambda row: row['geometry'].buffer(polygon_buffering_in_map_units.get(row['value'], 0))\n            if row['value'] in polygon_buffering_in_map_units else row['geometry'],\n            axis=1\n        )\n\n    merged_features = []\n    for val, group in gdf.groupby('value'):\n        # Use union_all() to merge the geometries within the group.\n        # (Requires Shapely 2.0 or later; otherwise use shapely.ops.unary_union on group.geometry.tolist())\n        union_geom = group.geometry.union_all()\n        # If the union produces a single Polygon, add it directly;\n        # if it produces a MultiPolygon, split it into individual features.\n        if union_geom.geom_type == 'Polygon':\n            merged_features.append({'value': val, 'geometry': union_geom})\n        elif union_geom.geom_type == 'MultiPolygon':\n            for geom in union_geom.geoms:\n                merged_features.append({'value': val, 'geometry': geom})\n        else:\n            # In case of unexpected geometry types, skip or handle accordingly.\n            print(f\"Unexpected geometry type for value {val}: {union_geom.geom_type}\")\n    # Create a new GeoDataFrame from merged features.\n    gdf = gpd.GeoDataFrame(merged_features, crs=gdf.crs)\n\n\n    ogr_driver = ogr.GetDriverByName(\"Memory\")\n    mem_ds = ogr_driver.CreateDataSource(\"in_memory\")\n\n    # Determine an appropriate OGR geometry type using the first feature.\n    first_geom = gdf.geometry.iloc[0]\n    if first_geom.geom_type == \"Polygon\":\n        ogr_geom_type = ogr.wkbPolygon\n    elif first_geom.geom_type == \"MultiPolygon\":\n        ogr_geom_type = ogr.wkbMultiPolygon\n    else:\n        ogr_geom_type = ogr.wkbUnknown\n\n    # Convert the CRS to OGR SpatialReference.\n    sr = osr.SpatialReference()\n    try:\n        sr.ImportFromWkt(crs.to_wkt())\n    except AttributeError:\n        sr.ImportFromEPSG(4326)\n\n    mem_layer = mem_ds.CreateLayer(\"post_processed\", sr, ogr_geom_type)\n\n    # Add attribute field for 'value' (and any other non-geometry columns if needed).\n    # Here we add 'value' for example.\n    field_defn = ogr.FieldDefn(\"value\", ogr.OFTInteger)\n    mem_layer.CreateField(field_defn)\n\n    # Add each row from the GeoDataFrame as an OGR feature.\n    for idx, row in gdf.iterrows():\n        feat = ogr.Feature(mem_layer.GetLayerDefn())\n        ogr_geom = ogr.CreateGeometryFromWkt(row['geometry'].wkt)\n        feat.SetGeometry(ogr_geom)\n        feat.SetField(\"value\", row['value'])\n        mem_layer.CreateFeature(feat)\n        feat = None\n\n    _write_vector(mem_ds, output_vector_path)\n\n    return output_vector_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.post_process_threshold_to_vector","title":"<code>post_process_threshold_to_vector(input_image_path, output_vector_path, threshold_val, operator_str='&lt;=')</code>","text":"<p>Converts a thresholded raster mask to a vector layer using Rasterio and Fiona.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input single-band raster.</p> required <code>output_vector_path</code> <code>str</code> <p>Path to save the output vector file (GeoPackage).</p> required <code>threshold_val</code> <code>float | int</code> <p>Threshold value to apply.</p> required <code>operator_str</code> <code>str</code> <p>One of the comparison operators.</p> <code>'&lt;='</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the saved vector file.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def post_process_threshold_to_vector(\n    input_image_path: str,\n    output_vector_path: str,\n    threshold_val: float | int,\n    operator_str: Literal[\"=\", \"&lt;=\", \"&gt;\", \"&gt;=\", \"==\"] = \"&lt;=\",\n    ) -&gt; str:\n    \"\"\"\n    Converts a thresholded raster mask to a vector layer using Rasterio and Fiona.\n\n    Args:\n        input_image_path (str): Path to the input single-band raster.\n        output_vector_path (str): Path to save the output vector file (GeoPackage).\n        threshold_val (float | int): Threshold value to apply.\n        operator_str (str): One of the comparison operators.\n\n    Returns:\n        str: Path to the saved vector file.\n    \"\"\"\n    print(\"Start post process threshold\")\n\n    with rasterio.open(input_image_path) as src:\n        image = src.read(1)\n        transform = src.transform\n        crs = src.crs\n\n        # Apply threshold\n        if operator_str == \"&lt;\":\n            mask = image &lt; threshold_val\n        elif operator_str == \"&lt;=\":\n            mask = image &lt;= threshold_val\n        elif operator_str == \"&gt;\":\n            mask = image &gt; threshold_val\n        elif operator_str == \"&gt;=\":\n            mask = image &gt;= threshold_val\n        elif operator_str == \"==\":\n            mask = image == threshold_val\n        else:\n            raise ValueError(\"Unsupported operator_str\")\n\n        mask = mask.astype(np.uint8)\n\n        # Generate vector shapes\n        results = []\n        for s, v in shapes(mask, mask=mask, transform=transform):\n            if v != 1:\n                continue\n            geom = shape(s)\n            if isinstance(geom, Polygon):\n                results.append({\"properties\": {\"DN\": int(v)}, \"geometry\": mapping(geom)})\n            elif isinstance(geom, MultiPolygon):\n                for part in geom.geoms:\n                    results.append({\"properties\": {\"DN\": int(v)}, \"geometry\": mapping(part)})\n\n        schema = {\n            \"geometry\": \"Polygon\",\n            \"properties\": {\"DN\": \"int\"},\n        }\n\n        if os.path.exists(output_vector_path):\n            os.remove(output_vector_path)\n\n        with fiona.open(\n            output_vector_path, \"w\",\n            driver=\"GPKG\",\n            crs=crs,\n            schema=schema,\n            layer=\"mask\"\n        ) as dst:\n            for feat in results:\n                dst.write(feat)\n\n    return output_vector_path\n</code></pre>"},{"location":"api/match/","title":"Matching Algorithms","text":""},{"location":"api/match/#spectralmatch.match.global_regression.global_regression","title":"<code>global_regression(input_images, output_images, *, custom_mean_factor=1.0, custom_std_factor=1.0, vector_mask_path=None, window_size=None, debug_logs=False, custom_nodata_value=None, parallel_workers=None, calculation_dtype='float32', output_dtype=None, specify_model_images=None, save_adjustments=None, load_adjustments=None)</code>","text":"<p>Performs global radiometric normalization across overlapping images using least squares regression.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies the input images either as: - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). - A list of full file paths to individual input images.</p> required <code>output_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies how output filenames are generated or provided: - A tuple with an output folder and a filename template using \"\\(\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"\\)_GlobalMatch.tif\")). - A list of full output paths, which must match the number of input images.</p> required <code>custom_mean_factor</code> <code>float</code> <p>Weight for mean constraints in regression. Defaults to 1.0.</p> <code>1.0</code> <code>custom_std_factor</code> <code>float</code> <p>Weight for standard deviation constraints in regression. Defaults to 1.0.</p> <code>1.0</code> <code>vector_mask_path</code> <code>Tuple[Literal['include', 'exclude'], str] | Tuple[Literal['include', 'exclude'], str, str] | None</code> <p>Mask to limit stats calculation to specific areas in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that includes (can be substring) input image name to filter geometry by. Loaded stats won't have this applied to them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.</p> <code>None</code> <code>window_size</code> <code>int | Tuple[int, int] | None</code> <p>Tile size for processing: int for square tiles, (width, height) for custom size, or None for full image. Defaults to None.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>If True, prints debug information and constraint matrices. Defaults to False.</p> <code>False</code> <code>custom_nodata_value</code> <code>float | int | None</code> <p>Overrides detected NoData value. Defaults to None.</p> <code>None</code> <code>parallel_workers</code> <code>Literal['cpu'] | int | None</code> <p>If set, enables multiprocessing. \"cpu\" = all cores, int = specific count, None = no parallel processing. Defaults to None.</p> <code>None</code> <code>calculation_dtype</code> <code>str</code> <p>Data type used for internal calculations. Defaults to \"float32\".</p> <code>'float32'</code> <code>output_dtype</code> <code>str | None</code> <p>Data type for output rasters. Defaults to input image dtype.</p> <code>None</code> <code>specify_model_images</code> <code>Tuple[Literal['exclude', 'include'], List[str]] | None</code> <p>First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.</p> <code>None</code> <code>save_adjustments</code> <code>str | None</code> <p>The output path of a .json file to save adjustments parameters. Defaults to not saving.</p> <code>None</code> <code>load_adjustments</code> <code>str | None</code> <p>If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List[str]: Paths to the globally adjusted output raster images.</p> Source code in <code>spectralmatch/match/global_regression.py</code> <pre><code>def global_regression(\n    input_images: Tuple[str, str] | List[str],\n    output_images: Tuple[str, str] | List[str],\n    *,\n    custom_mean_factor: float = 1.0,\n    custom_std_factor: float = 1.0,\n    vector_mask_path: Tuple[Literal[\"include\", \"exclude\"], str] | Tuple[Literal[\"include\", \"exclude\"], str, str] | None = None,\n    window_size: int | Tuple[int, int] | None = None,\n    debug_logs: bool = False,\n    custom_nodata_value: float | int | None = None,\n    parallel_workers: Literal[\"cpu\"] | int | None = None,\n    calculation_dtype: str = \"float32\",\n    output_dtype: str | None = None,\n    specify_model_images: Tuple[Literal[\"exclude\", \"include\"], List[str]] | None = None,\n    save_adjustments: str | None = None,\n    load_adjustments: str | None = None,\n    ) -&gt; list:\n    \"\"\"\n    Performs global radiometric normalization across overlapping images using least squares regression.\n\n    Args:\n        input_images (Tuple[str, str] | List[str]):\n            Specifies the input images either as:\n            - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n            - A list of full file paths to individual input images.\n        output_images (Tuple[str, str] | List[str]):\n            Specifies how output filenames are generated or provided:\n            - A tuple with an output folder and a filename template using \"$\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"$_GlobalMatch.tif\")).\n            - A list of full output paths, which must match the number of input images.\n        custom_mean_factor (float, optional): Weight for mean constraints in regression. Defaults to 1.0.\n        custom_std_factor (float, optional): Weight for standard deviation constraints in regression. Defaults to 1.0.\n        vector_mask_path (Tuple[Literal[\"include\", \"exclude\"], str] | Tuple[Literal[\"include\", \"exclude\"], str, str] | None): Mask to limit stats calculation to specific areas in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that *includes* (can be substring) input image name to filter geometry by. Loaded stats won't have this applied to them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.\n        window_size (int | Tuple[int, int] | None): Tile size for processing: int for square tiles, (width, height) for custom size, or None for full image. Defaults to None.\n        debug_logs (bool, optional): If True, prints debug information and constraint matrices. Defaults to False.\n        custom_nodata_value (float | int | None, optional): Overrides detected NoData value. Defaults to None.\n        parallel_workers (Literal[\"cpu\"] | int | None): If set, enables multiprocessing. \"cpu\" = all cores, int = specific count, None = no parallel processing. Defaults to None.\n        calculation_dtype (str, optional): Data type used for internal calculations. Defaults to \"float32\".\n        output_dtype (str | None, optional): Data type for output rasters. Defaults to input image dtype.\n        specify_model_images (Tuple[Literal[\"exclude\", \"include\"], List[str]] | None ): First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.\n        save_adjustments (str | None, optional): The output path of a .json file to save adjustments parameters. Defaults to not saving.\n        load_adjustments (str | None, optional): If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.\n\n    Returns:\n        List[str]: Paths to the globally adjusted output raster images.\n    \"\"\"\n\n    print(\"Start global regression\")\n\n    _validate_input_params(\n        input_images,\n        output_images,\n        custom_mean_factor,\n        custom_std_factor,\n        vector_mask_path,\n        window_size,\n        debug_logs,\n        custom_nodata_value,\n        parallel_workers,\n        calculation_dtype,\n        output_dtype,\n        specify_model_images,\n        save_adjustments,\n        load_adjustments,\n    )\n\n    if isinstance(input_images, tuple): input_images = search_paths(*input_images)\n    if isinstance(output_images, tuple): output_images = create_paths(*output_images, input_images, create_folders=True)\n\n    if debug_logs: print(f\"Input images: {input_images}\")\n    if debug_logs: print(f\"Output images: {output_images}\")\n\n    input_image_names = [os.path.splitext(os.path.basename(p))[0] for p in input_images]\n    input_image_paths = dict(zip(input_image_names, input_images))\n    output_image_paths = dict(zip(input_image_names, output_images))\n\n    _check_raster_requirements(list(input_image_paths.values()), debug_logs)\n\n    if isinstance(window_size, int): window_size = (window_size, window_size)\n    nodata_val = _get_nodata_value(list(input_image_paths.values()), custom_nodata_value)\n\n    # Find loaded and input files if load adjustments\n    loaded_model = {}\n    if load_adjustments:\n        with open(load_adjustments, \"r\") as f:\n            loaded_model = json.load(f)\n        _validate_adjustment_model_structure(loaded_model)\n        loaded_names = set(loaded_model.keys())\n        input_names = set(input_image_names)\n    else:\n        loaded_names = set([])\n        input_names = set(input_image_names)\n\n    matched = input_names &amp; loaded_names\n    only_loaded = loaded_names - input_names\n    only_input = input_names - loaded_names\n    if debug_logs:\n        print(f\"Total images: input images: {len(input_names)}, loaded images {len(loaded_names)}: \")\n        print(f\"    Matched adjustments (to override) ({len(matched)}):\", sorted(matched))\n        print(f\"    Only in loaded adjustments (to add) ({len(only_loaded)}):\", sorted(only_loaded))\n        print(f\"    Only in input (to calculate) ({len(only_input)}):\", sorted(only_input))\n\n    # Find images to include in model\n    included_names = list(matched | only_loaded | only_input)\n    if specify_model_images:\n        mode, names = specify_model_images\n        name_set = set(names)\n        if mode == \"include\":\n            included_names = [n for n in input_image_names if n in name_set]\n        elif mode == \"exclude\":\n            included_names = [n for n in input_image_names if n not in name_set]\n        excluded_names = [n for n in input_image_names if n not in included_names]\n    if debug_logs:\n        print(\"Images to influence the model:\")\n        print(f\"    Included in model ({len(included_names)}): {sorted(included_names)}\")\n        if specify_model_images: print(f\"    Excluded from model ({len(excluded_names)}): {sorted(excluded_names)}\")\n        else: print(f\"    Excluded from model (0): []\")\n\n    # Calculate stats\n    if debug_logs: print(\"Calculating statistics\")\n    with rasterio.open(list(input_image_paths.values())[0]) as src: num_bands = src.count\n\n    # Get images bounds\n    all_bounds = {}\n    for name, path in input_image_paths.items():\n        with rasterio.open(path) as ds:\n            all_bounds[name] = ds.bounds\n\n    # Calculate overlap stats\n    overlapping_pairs = _find_overlaps(all_bounds)\n\n    all_overlap_stats = {}\n    for name_i, name_j in overlapping_pairs:\n\n        if name_i in loaded_model and name_j in loaded_model[name_i].get(\"overlap_stats\", {}):\n            continue\n\n        stats = _calculate_overlap_stats(\n            num_bands,\n            input_image_paths[name_i],\n            input_image_paths[name_j],\n            name_i,\n            name_j,\n            all_bounds[name_i],\n            all_bounds[name_j],\n            nodata_val,\n            nodata_val,\n            vector_mask_path=vector_mask_path,\n            window_size=window_size,\n            debug_logs=debug_logs,\n        )\n\n        for k_i, v in stats.items():\n            all_overlap_stats[k_i] = {\n                **all_overlap_stats.get(k_i, {}),\n                **{\n                    k_j: {**all_overlap_stats.get(k_i, {}).get(k_j, {}), **s}\n                    for k_j, s in v.items()\n                },\n            }\n\n\n    # Add loaded image stats to model\n    if load_adjustments:\n        for name_i, model_entry in loaded_model.items():\n            if name_i not in input_image_paths:\n                continue\n\n            for name_j, bands in model_entry.get(\"overlap_stats\", {}).items():\n                if name_j not in input_image_paths:\n                    continue\n\n                all_overlap_stats.setdefault(name_i, {})[name_j] = {\n                    int(k.split(\"_\")[1]): {\n                        \"mean\": bands[k][\"mean\"],\n                        \"std\": bands[k][\"std\"],\n                        \"size\": bands[k][\"size\"]\n                    } for k in bands\n                }\n\n    # Calculate whole stats\n    all_whole_stats = {}\n    for name, path in input_image_paths.items():\n        if name in loaded_model:\n            all_whole_stats[name] = {\n                int(k.split(\"_\")[1]): {\n                    \"mean\": loaded_model[name][\"whole_stats\"][k][\"mean\"],\n                    \"std\": loaded_model[name][\"whole_stats\"][k][\"std\"],\n                    \"size\": loaded_model[name][\"whole_stats\"][k][\"size\"]\n                }\n                for k in loaded_model[name][\"whole_stats\"]\n            }\n        else:\n            all_whole_stats.update(\n                _calculate_whole_stats(\n                    input_image_path=path,\n                    nodata=nodata_val,\n                    num_bands=num_bands,\n                    image_name=name,\n                    vector_mask_path=vector_mask_path,\n                    window_size=window_size,\n                    debug_logs=debug_logs\n                )\n            )\n\n    all_image_names = list(dict.fromkeys(input_image_names + list(loaded_model.keys())))\n    num_total = len(all_image_names)\n\n    # Print model sources\n    if debug_logs:\n        print(f\"\\nCreating model for {len(all_image_names)} total images from {len(included_names)} included:\")\n        print(f\"    {'ID':&lt;4}\\t{'Source':&lt;6}\\t{'Inclusion':&lt;8}\\tName\")\n        for i, name in enumerate(all_image_names):\n            source = \"load\" if name in (matched | only_loaded) else \"calc\"\n            included = \"incl\" if name in included_names else \"excl\"\n            print(f\"    {i:&lt;4}\\t{source:&lt;6}\\t{included:&lt;8}\\t{name}\")\n\n    # Build model\n    all_params = np.zeros((num_bands, 2 * num_total, 1), dtype=float)\n    image_names_with_id = [(i, name) for i, name in enumerate(all_image_names)]\n    for b in range(num_bands):\n        if debug_logs: print(f\"\\nProcessing band {b}:\")\n\n        A, y, tot_overlap = [], [], 0\n        for i, name_i in image_names_with_id:\n            for j, name_j in image_names_with_id[i + 1:]:\n                stat = all_overlap_stats.get(name_i, {}).get(name_j)\n                if stat is None:\n                    continue\n\n                # This condition ensures that only overlaps involving at least one included image contribute constraints, allowing external images to be calibrated against the model without influencing it.\n                if name_i not in included_names and name_j not in included_names:\n                    continue\n\n                s = stat[b][\"size\"]\n                m1, v1 = stat[b][\"mean\"], stat[b][\"std\"]\n                m2, v2 = (\n                    all_overlap_stats[name_j][name_i][b][\"mean\"],\n                    all_overlap_stats[name_j][name_i][b][\"std\"],\n                )\n\n                row_m = [0] * (2 * num_total)\n                row_s = [0] * (2 * num_total)\n                row_m[2 * i: 2 * i + 2] = [m1, 1]\n                row_m[2 * j: 2 * j + 2] = [-m2, -1]\n                row_s[2 * i], row_s[2 * j] = v1, -v2\n\n                A.extend([\n                    [v * s * custom_mean_factor for v in row_m],\n                    [v * s * custom_std_factor for v in row_s],\n                ])\n                y.extend([0, 0])\n                tot_overlap += s\n\n        pjj = 1.0 if tot_overlap == 0 else tot_overlap / (2.0 * num_total)\n\n        for name in included_names:\n            mj = all_whole_stats[name][b][\"mean\"]\n            vj = all_whole_stats[name][b][\"std\"]\n            j_idx = all_image_names.index(name)\n            row_m = [0] * (2 * num_total)\n            row_s = [0] * (2 * num_total)\n            row_m[2 * j_idx: 2 * j_idx + 2] = [mj * pjj, 1 * pjj]\n            row_s[2 * j_idx] = vj * pjj\n            A.extend([row_m, row_s])\n            y.extend([mj * pjj, vj * pjj])\n\n        for name in input_image_names:\n            if name in included_names:\n                continue\n            row = [0] * (2 * num_total)\n            A.append(row.copy())\n            y.append(0)\n            A.append(row.copy())\n            y.append(0)\n\n        A_arr = np.asarray(A)\n        y_arr = np.asarray(y)\n        res = least_squares(lambda p: A_arr @ p - y_arr, [1, 0] * num_total)\n\n        if debug_logs:\n            _print_constraint_system(\n                constraint_matrix=A_arr,\n                adjustment_params=res.x,\n                observed_values_vector=y_arr,\n                overlap_pairs=overlapping_pairs,\n                image_names_with_id=image_names_with_id,\n\n            )\n\n        all_params[b] = res.x.reshape((2 * num_total, 1))\n\n    # Save adjustments\n    if save_adjustments:\n        _save_adjustments(\n            save_path=save_adjustments,\n            input_image_names=list(input_image_paths.keys()),\n            all_params=all_params,\n            all_whole_stats=all_whole_stats,\n            all_overlap_stats=all_overlap_stats,\n            num_bands=num_bands,\n            calculation_dtype=calculation_dtype\n        )\n\n    if parallel_workers == \"cpu\":\n        parallel = True\n        max_workers = mp.cpu_count()\n    elif isinstance(parallel_workers, int) and parallel_workers &gt; 0:\n        parallel = True\n        max_workers = parallel_workers\n    else:\n        parallel = False\n        max_workers = None\n\n    if debug_logs: print(f\"Apply adjustments and saving results for:\")\n    out_paths: List[str] = []\n    for idx, (name, img_path) in enumerate(input_image_paths.items()):\n        if debug_logs: print(f\"    {name}\")\n\n        out_path = output_image_paths[name]\n        out_paths.append(out_path)\n        with rasterio.open(img_path) as src:\n            meta = src.meta.copy()\n            meta.update({\"count\": num_bands, \"dtype\": output_dtype or src.dtypes[0], \"nodata\": nodata_val})\n            with rasterio.open(out_path, \"w\", **meta) as dst:\n\n                if window_size:\n                    tw, th = window_size\n                    windows = list(_create_windows(src.width, src.height, tw, th))\n                else:\n                    windows = [Window(0, 0, src.width, src.height)]\n\n                if parallel:\n                    ctx = _choose_context(prefer_fork=True)\n                    pool = ProcessPoolExecutor(\n                        max_workers=max_workers,\n                        mp_context=ctx,\n                        initializer=_init_worker,\n                        initargs=(img_path,),\n                    )\n\n                for b in range(num_bands):\n                    a = float(all_params[b, 2 * idx, 0])\n                    b0 = float(all_params[b, 2 * idx + 1, 0])\n\n                    if parallel:\n                        futs = [\n                            pool.submit(_process_tile_global,\n                                        w,\n                                        b,\n                                        a,\n                                        b0,\n                                        nodata_val,\n                                        calculation_dtype,\n                                        debug_logs,\n                                        )\n                            for w in windows\n                        ]\n                        for fut in as_completed(futs):\n                            win, buf = fut.result()\n                            dst.write(buf.astype(meta[\"dtype\"]), b + 1, window=win)\n                    else:\n                        for win in windows:\n                            _, buf = _process_tile_global(\n                                win,\n                                b,\n                                a,\n                                b0,\n                                nodata_val,\n                                debug_logs,\n                            )\n                            dst.write(buf.astype(meta[\"dtype\"]), b + 1, window=win)\n                if parallel:\n                    pool.shutdown()\n    return out_paths\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.get_bounding_rect_images_block_space","title":"<code>get_bounding_rect_images_block_space(block_local_means)</code>","text":"<p>Compute block-space bounding rectangles for each image based on valid block values.</p> <p>Parameters:</p> Name Type Description Default <code>block_local_means</code> <code>dict[str, ndarray]</code> <p>Per-image block means with shape (num_row, num_col, num_bands).</p> required <p>Returns:</p> Type Description <code>dict[str, tuple[int, int, int, int]]</code> <p>dict[str, tuple[int, int, int, int]]: Each entry maps image name to (min_row, min_col, max_row, max_col).</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def get_bounding_rect_images_block_space(\n    block_local_means: dict[str, np.ndarray]\n) -&gt; dict[str, tuple[int, int, int, int]]:\n    \"\"\"\n    Compute block-space bounding rectangles for each image based on valid block values.\n\n    Args:\n        block_local_means (dict[str, np.ndarray]): Per-image block means\n            with shape (num_row, num_col, num_bands).\n\n    Returns:\n        dict[str, tuple[int, int, int, int]]: Each entry maps image name to\n            (min_row, min_col, max_row, max_col).\n    \"\"\"\n    output = {}\n\n    for name, arr in block_local_means.items():\n        valid_mask = np.any(~np.isnan(arr), axis=2)\n        rows, cols = np.where(valid_mask)\n\n        if rows.size &gt; 0 and cols.size &gt; 0:\n            min_row, max_row = rows.min(), rows.max() + 1\n            min_col, max_col = cols.min(), cols.max() + 1\n        else:\n            min_row = max_row = min_col = max_col = 0\n\n        output[name] = (min_row, min_col, max_row, max_col)\n\n    return output\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.local_block_adjustment","title":"<code>local_block_adjustment(input_images, output_images, *, custom_nodata_value=None, number_of_blocks=100, alpha=1.0, calculation_dtype='float32', output_dtype=None, debug_logs=False, window_size=None, correction_method='gamma', parallel_workers=None, save_block_maps=None, load_block_maps=None, override_bounds_canvas_coords=None, vector_mask_path=None, block_valid_pixel_threshold=0.001)</code>","text":"<p>Performs local radiometric adjustment on a set of raster images using block-based statistics.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies the input images either as: - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")). - A list of full file paths to individual input images.</p> required <code>output_images</code> <code>Tuple[str, str] | List[str]</code> <p>Specifies how output filenames are generated or provided: - A tuple with an output folder and a filename template using \"\\(\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"\\)_LocalMatch.tif\")). - A list of full output paths, which must match the number of input images.</p> required <code>custom_nodata_value</code> <code>float | int | None</code> <p>Overrides detected NoData value. Defaults to None.</p> <code>None</code> <code>number_of_blocks</code> <code>int | tuple | Literal['coefficient_of_variation']</code> <p>int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.</p> <code>100</code> <code>alpha</code> <code>float</code> <p>Blending factor between reference and local means. Defaults to 1.0.</p> <code>1.0</code> <code>calculation_dtype</code> <code>str</code> <p>Precision for internal calculations. Defaults to \"float32\".</p> <code>'float32'</code> <code>output_dtype</code> <code>str | None</code> <p>Data type for output rasters. Defaults to input image dtype.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>If True, prints progress. Defaults to False.</p> <code>False</code> <code>window_size</code> <code>int | Tuple[int, int] | Literal['block'] | None</code> <p>Tile size for processing: int for square tiles, (width, height) for custom size, or \"block\" to set as the size of the block map, None for full image. Defaults to None.</p> <code>None</code> <code>correction_method</code> <code>Literal['gamma', 'linear']</code> <p>Local correction method. Defaults to \"gamma\".</p> <code>'gamma'</code> <code>parallel_workers</code> <code>Literal['cpu'] | int | None</code> <p>If set, enables multiprocessing. \"cpu\" = all cores, int = specific count, None = no parallel processing. Defaults to None.</p> <code>None</code> <code>save_block_maps</code> <code>tuple(str, str) | None</code> <p>If enabled, saves block maps for review, to resume processing later, or to add additional images to the reference map. - First str is the path to save the global block map. - Second str is the path to save the local block maps, which must include \"$\" which will be replaced my the image name (because there are multiple local maps).</p> <code>None</code> <code>load_block_maps</code> <code>Tuple[str, List[str]] | Tuple[str, None] | Tuple[None, List[str]] | None</code> <p>Controls loading of precomputed block maps. Can be one of:     - Tuple[str, List[str]]: Load both reference and local block maps.     - Tuple[str, None]: Load only the reference block map.     - Tuple[None, List[str]]: Load only the local block maps.     - None: Do not load any block maps. This supports partial or full reuse of precomputed block maps:     - Local block maps will still be computed for each input image that is not linked to a local block map by the images name being included in the local block maps name (file name).     - The reference block map will only be calculated (mean of all local blocks) if not set.     - The reference map defines the reference block statistics and the local maps define per-image local block statistics.     - Both reference and local maps must have the same canvas extent and dimensions which will be used to set those values.</p> <code>None</code> <code>override_bounds_canvas_coords</code> <code>Tuple[float, float, float, float] | None</code> <p>Manually set (min_x, min_y, max_x, max_y) bounds to override the computed/loaded canvas extent. If you wish to have a larger extent than the current images, you can manually set this, along with setting a fixed number of blocks, to anticipate images will expand beyond the current extent.</p> <code>None</code> <code>vector_mask_path</code> <code>Tuple[Literal['include', 'exclude'], str] | Tuple[Literal['include', 'exclude'], str, str] | None</code> <p>A mask limiting pixels to include when calculating stats for each block in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that includes (can be substring) input image name to filter geometry by. It is only applied when calculating local blocks, as the reference map is calculated as the mean of all local blocks. Loaded block maps won't have this applied unless it was used when calculating them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.</p> <code>None</code> <code>block_valid_pixel_threshold</code> <code>float</code> <p>Minimum fraction of valid pixels required to include a block (0\u20131).</p> <code>0.001</code> <p>Returns:</p> Type Description <code>list</code> <p>List[str]: Paths to the locally adjusted output raster images.</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def local_block_adjustment(\n    input_images: Tuple[str, str] | List[str],\n    output_images: Tuple[str, str] | List[str],\n    *,\n    custom_nodata_value: float | int | None = None,\n    number_of_blocks: int | Tuple[int, int] | Literal[\"coefficient_of_variation\"] = 100,\n    alpha: float = 1.0,\n    calculation_dtype: str = \"float32\",\n    output_dtype: str | None = None,\n    debug_logs: bool = False,\n    window_size: int | Tuple[int, int] | Literal[\"block\"] | None = None,\n    correction_method: Literal[\"gamma\", \"linear\"] = \"gamma\",\n    parallel_workers: Literal[\"cpu\"] | int | None = None,\n    save_block_maps: Tuple[str, str] | None = None,\n    load_block_maps: Tuple[str, List[str]] | Tuple[str, None]| Tuple[None, List[str]] | None = None,\n    override_bounds_canvas_coords: Tuple[float, float, float, float] | None = None,\n    vector_mask_path: Tuple[Literal[\"include\", \"exclude\"], str] | Tuple[Literal[\"include\", \"exclude\"], str, str] | None = None,\n    block_valid_pixel_threshold: float = 0.001,\n    )-&gt; list:\n    \"\"\"\n    Performs local radiometric adjustment on a set of raster images using block-based statistics.\n\n    Args:\n        input_images (Tuple[str, str] | List[str]):\n            Specifies the input images either as:\n            - A tuple with a folder path and glob pattern to search for files (e.g., (\"/input/folder\", \"*.tif\")).\n            - A list of full file paths to individual input images.\n        output_images (Tuple[str, str] | List[str]):\n            Specifies how output filenames are generated or provided:\n            - A tuple with an output folder and a filename template using \"$\" as a placeholder for each input image's basename (e.g., (\"/output/folder\", \"$_LocalMatch.tif\")).\n            - A list of full output paths, which must match the number of input images.\n        custom_nodata_value (float | int | None, optional): Overrides detected NoData value. Defaults to None.\n        number_of_blocks (int | tuple | Literal[\"coefficient_of_variation\"]): int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.\n        alpha (float, optional): Blending factor between reference and local means. Defaults to 1.0.\n        calculation_dtype (str, optional): Precision for internal calculations. Defaults to \"float32\".\n        output_dtype (str | None, optional): Data type for output rasters. Defaults to input image dtype.\n        debug_logs (bool, optional): If True, prints progress. Defaults to False.\n        window_size (int | Tuple[int, int] | Literal[\"block\"] | None): Tile size for processing: int for square tiles, (width, height) for custom size, or \"block\" to set as the size of the block map, None for full image. Defaults to None.\n        correction_method (Literal[\"gamma\", \"linear\"], optional): Local correction method. Defaults to \"gamma\".\n        parallel_workers (Literal[\"cpu\"] | int | None): If set, enables multiprocessing. \"cpu\" = all cores, int = specific count, None = no parallel processing. Defaults to None.\n        save_block_maps (tuple(str, str) | None): If enabled, saves block maps for review, to resume processing later, or to add additional images to the reference map.\n            - First str is the path to save the global block map.\n            - Second str is the path to save the local block maps, which must include \"$\" which will be replaced my the image name (because there are multiple local maps).\n        load_block_maps (Tuple[str, List[str]] | Tuple[str, None] | Tuple[None, List[str]] | None, optional):\n            Controls loading of precomputed block maps. Can be one of:\n                - Tuple[str, List[str]]: Load both reference and local block maps.\n                - Tuple[str, None]: Load only the reference block map.\n                - Tuple[None, List[str]]: Load only the local block maps.\n                - None: Do not load any block maps.\n            This supports partial or full reuse of precomputed block maps:\n                - Local block maps will still be computed for each input image that is not linked to a local block map by the images name being *included* in the local block maps name (file name).\n                - The reference block map will only be calculated (mean of all local blocks) if not set.\n                - The reference map defines the reference block statistics and the local maps define per-image local block statistics.\n                - Both reference and local maps must have the same canvas extent and dimensions which will be used to set those values.\n        override_bounds_canvas_coords (Tuple[float, float, float, float] | None): Manually set (min_x, min_y, max_x, max_y) bounds to override the computed/loaded canvas extent. If you wish to have a larger extent than the current images, you can manually set this, along with setting a fixed number of blocks, to anticipate images will expand beyond the current extent.\n        vector_mask_path (Tuple[Literal[\"include\", \"exclude\"], str] | Tuple[Literal[\"include\", \"exclude\"], str, str] | None): A mask limiting pixels to include when calculating stats for each block in the format of a tuple with two or three items: literal \"include\" or \"exclude\" the mask area, str path to the vector file, optional str of field name in vector file that *includes* (can be substring) input image name to filter geometry by. It is only applied when calculating local blocks, as the reference map is calculated as the mean of all local blocks. Loaded block maps won't have this applied unless it was used when calculating them. The matching solution is still applied to these areas in the output. Defaults to None for no mask.\n        block_valid_pixel_threshold (float): Minimum fraction of valid pixels required to include a block (0\u20131).\n\n    Returns:\n        List[str]: Paths to the locally adjusted output raster images.\n    \"\"\"\n\n    print(\"Start local block adjustment\")\n\n    _validate_input_params(\n        input_images,\n        output_images,\n        custom_nodata_value,\n        number_of_blocks,\n        alpha,\n        calculation_dtype,\n        output_dtype,\n        debug_logs,\n        window_size,\n        correction_method,\n        parallel_workers,\n        save_block_maps,\n        load_block_maps,\n        override_bounds_canvas_coords,\n        vector_mask_path,\n        block_valid_pixel_threshold,\n    )\n\n    if isinstance(input_images, tuple): input_images = search_paths(*input_images)\n    if isinstance(output_images, tuple): output_images = create_paths(*output_images, input_images, create_folders=True)\n\n    if debug_logs: print(f\"Input images: {input_images}\")\n    if debug_logs: print(f\"Output images: {output_images}\")\n\n    input_image_paths = input_images\n    input_image_names = [os.path.splitext(os.path.basename(p))[0] for p in input_images]\n    input_image_pairs = dict(zip(input_image_names, input_images))\n    output_image_pairs = dict(zip(input_image_names, output_images))\n\n    _check_raster_requirements(input_image_paths, debug_logs)\n\n    if isinstance(window_size, int): window_size = (window_size, window_size)\n    nodata_val = _get_nodata_value(input_image_paths, custom_nodata_value)\n    projection = rasterio.open(input_image_paths[0]).crs\n    if debug_logs: print(f\"Global nodata value: {nodata_val}\")\n    with rasterio.open(input_image_paths[0]) as ds:num_bands = ds.count\n\n    # Load data from precomputed block maps if set\n    if load_block_maps:\n        loaded_block_local_means, loaded_block_reference_mean, loaded_num_row, loaded_num_col, loaded_bounds_canvas_coords = _get_pre_computed_block_maps(load_block_maps, calculation_dtype, debug_logs)\n        loaded_names = list(loaded_block_local_means.keys())\n        block_reference_mean = loaded_block_reference_mean\n\n        matched = list((soft_matches := {\n            input_name: loaded_name\n            for input_name in input_image_names\n            for loaded_name in loaded_names\n            if input_name in loaded_name\n        }).keys())\n        only_loaded = [l for l in loaded_names if not any(n in l for n in input_image_names)]\n        only_input = [n for n in input_image_names if not any(n in l for l in loaded_names)]\n\n    else:\n        only_input = input_image_names\n        matched = []\n        only_loaded = []\n        block_reference_mean = None\n\n    if debug_logs:\n        print(f\"Total images: input images: {len(input_image_names)}, loaded local block maps: {len(loaded_names) if load_block_maps else 0}:\")\n        print(f\"    Matched local block maps (to override) ({len(matched)}):\", sorted(matched))\n        print(f\"    Only in loaded local block maps (to use) ({len(only_loaded)}):\", sorted(only_loaded))\n        print(f\"    Only in input (to compute) ({len(only_input)}):\", sorted(only_input))\n\n    # Unpack path to save block maps\n    if save_block_maps:\n        reference_map_path, local_map_path = save_block_maps\n\n    # Create image bounds dict\n    bounds_images_coords = {\n        name: rasterio.open(path).bounds\n        for name, path in input_image_pairs.items()\n    }\n\n    # Get bounds canvas coords\n    if not override_bounds_canvas_coords:\n        if not load_block_maps:\n            bounds_canvas_coords = _get_bounding_rectangle(input_image_paths)\n        else:\n            bounds_canvas_coords = loaded_bounds_canvas_coords\n    else:\n        bounds_canvas_coords = override_bounds_canvas_coords\n        if load_block_maps:\n            if bounds_canvas_coords != loaded_bounds_canvas_coords:\n                raise ValueError(\"Override bounds canvas coordinates do not match loaded block maps bounds\")\n\n    # Calculate the number of blocks\n    if not load_block_maps:\n        if isinstance(number_of_blocks, int):\n            num_row, num_col = _compute_block_size(input_image_paths, number_of_blocks, bounds_canvas_coords)\n        elif isinstance(number_of_blocks, tuple):\n            num_row, num_col = number_of_blocks\n        elif isinstance(number_of_blocks, str):\n            num_row, num_col = _compute_mosaic_coefficient_of_variation(input_image_paths, nodata_val) # This is the approach from the paper to compute bock size\n    else:\n        num_row, num_col = loaded_num_row, loaded_num_col\n\n    if debug_logs: print(\"Computing local block maps:\")\n\n    # Compute local blocks\n    local_blocks_to_calculate = {k: v for k, v in input_image_pairs.items() if k in only_input}\n    local_blocks_to_load = {\n        **{k: loaded_block_local_means[soft_matches[k]] for k in matched},\n        **{k: loaded_block_local_means[k] for k in only_loaded},\n    }\n\n    if local_blocks_to_calculate:\n        block_local_means, block_local_counts = _compute_local_blocks(\n            local_blocks_to_calculate,\n            bounds_canvas_coords,\n            num_row,\n            num_col,\n            num_bands,\n            window_size,\n            debug_logs,\n            nodata_val,\n            calculation_dtype,\n            vector_mask_path,\n            block_valid_pixel_threshold,\n        )\n        overlap = set(block_local_means) &amp; set(local_blocks_to_load)\n        if overlap:\n            raise ValueError(f\"Duplicate keys when merging loaded and computed blocks: {overlap}\")\n\n        block_local_means = {**block_local_means, **local_blocks_to_load}\n    else:\n        block_local_means = local_blocks_to_load\n\n\n    bounds_images_block_space = get_bounding_rect_images_block_space(block_local_means)\n\n    # Compute reference block\n    if debug_logs: print(\"Computing reference block map\")\n    if block_reference_mean is None:\n        block_reference_mean = _compute_reference_blocks(\n            block_local_means,\n            calculation_dtype,\n            )\n\n    if save_block_maps:\n        _download_block_map(\n            np.nan_to_num(block_reference_mean, nan=nodata_val),\n            bounds_canvas_coords,\n            reference_map_path,\n            projection,\n            calculation_dtype,\n            nodata_val,\n            num_col,\n            num_row,\n        )\n        for name, block_local_mean in block_local_means.items():\n            _download_block_map(\n                np.nan_to_num(block_local_mean, nan=nodata_val),\n                bounds_canvas_coords,\n                local_map_path.replace(\"$\", name),\n                projection,\n                calculation_dtype,\n                nodata_val,\n                num_col,\n                num_row,\n            )\n            # _download_block_map(\n            #     np.nan_to_num(block_local_count, nan=nodata_val),\n            #     bounds_canvas_coords,\n            #     os.path.join(output_image_folder, \"BlockLocalCount\", f\"{input_image_name}_BlockLocalCount.tif\"),\n            #     projection,\n            #     calculation_dtype,\n            #     nodata_val,\n            #     num_col,\n            #     num_row,\n            # )\n\n    # block_local_mean = _smooth_array(block_local_mean, nodata_value=global_nodata_value)\n\n    if parallel_workers == \"cpu\":\n        parallel = True\n        max_workers = mp.cpu_count()\n    elif isinstance(parallel_workers, int) and parallel_workers &gt; 0:\n        parallel = True\n        max_workers = parallel_workers\n    else:\n        parallel = False\n        max_workers = None\n\n    if debug_logs: print(f\"Computing local correction, applying, and saving:\")\n    out_paths: List[str] = []\n    for name, img_path in input_image_pairs.items():\n        in_name = os.path.splitext(os.path.basename(img_path))[0]\n        out_path = output_image_pairs[name]\n        out_name = os.path.splitext(os.path.basename(out_path))[0]\n        out_paths.append(str(out_path))\n\n        if debug_logs: print(f\"    {in_name}\")\n        with rasterio.open(img_path) as src:\n            meta = src.meta.copy()\n            meta.update({\"count\": num_bands, \"dtype\": output_dtype or src.dtypes[0], \"nodata\": nodata_val})\n            block_reference_mean_masked = np.where(\n                (np.arange(block_reference_mean.shape[0])[:, None, None] &gt;= bounds_images_block_space[name][0]) &amp;\n                (np.arange(block_reference_mean.shape[0])[:, None, None] &lt; bounds_images_block_space[name][2]) &amp;\n                (np.arange(block_reference_mean.shape[1])[None, :, None] &gt;= bounds_images_block_space[name][1]) &amp;\n                (np.arange(block_reference_mean.shape[1])[None, :, None] &lt; bounds_images_block_space[name][3]),\n                block_reference_mean,\n                np.nan\n            )\n\n            if isinstance(window_size, tuple):\n                tw, th = window_size\n                windows = list(_create_windows(src.width, src.height, tw, th))\n            elif window_size == \"block\":\n                block_width_geo = (bounds_canvas_coords[2] - bounds_canvas_coords[0]) / num_col\n                block_height_geo = (bounds_canvas_coords[3] - bounds_canvas_coords[1]) / num_row\n                res_x = abs(src.transform.a)\n                res_y = abs(src.transform.e)\n                tile_width = max(1, int(round(block_width_geo / res_x)))\n                tile_height = max(1, int(round(block_height_geo / res_y)))\n                windows = list(_create_windows(src.width, src.height, tile_width, tile_height))\n            elif window_size is None:\n                windows = [Window(0, 0, src.width, src.height)]\n\n            if parallel:\n                ctx = _choose_context(prefer_fork=True)\n\n                ref_shm = shared_memory.SharedMemory(create=True, size=block_reference_mean.nbytes)\n                ref_array = np.ndarray(block_reference_mean.shape, dtype=block_reference_mean.dtype, buffer=ref_shm.buf)\n                ref_array[:] = block_reference_mean[:]\n\n                loc_shm = shared_memory.SharedMemory(create=True, size=block_local_means[name].nbytes)\n                loc_array = np.ndarray(block_local_means[name].shape, dtype=block_local_means[name].dtype,\n                                       buffer=loc_shm.buf)\n                loc_array[:] = block_local_means[name][:]\n\n                pool = ProcessPoolExecutor(\n                    max_workers=max_workers,\n                    mp_context=ctx,\n                    initializer=_init_worker,\n                    initargs=(\n                    img_path, ref_shm.name, loc_shm.name, block_reference_mean.shape, block_local_means[name].shape,\n                    block_reference_mean.dtype.name),\n                )\n\n                try:\n                    with rasterio.open(out_path, \"w\", **meta) as dst:\n                        futures = [\n                            pool.submit(_compute_tile_local,\n                                        w,\n                                        b,\n                                        num_row,\n                                        num_col,\n                                        bounds_canvas_coords,\n                                        nodata_val,\n                                        alpha,\n                                        correction_method,\n                                        calculation_dtype,\n                                        )\n                            for b in range(num_bands)\n                            for w_id, w in enumerate(windows)\n                        ]\n                        for fut in as_completed(futures):\n                            win, b_idx, buf = fut.result()\n                            dst.write(np.nan_to_num(buf, nan=nodata_val).astype(output_dtype), b_idx + 1, window=win)\n                            del buf, win\n                finally:\n                    pool.shutdown(wait=True)\n                    ref_shm.close()\n                    loc_shm.close()\n                    ref_shm.unlink()\n                    loc_shm.unlink()\n            else:\n                with rasterio.open(out_path, \"w\", **meta) as dst:\n                    _worker_dataset_cache[\"ds\"] = rasterio.open(img_path, \"r\")\n                    _worker_dataset_cache[\"block_ref_mean\"] = block_reference_mean\n                    _worker_dataset_cache[\"block_loc_mean\"] = block_local_means[name]\n\n                    for b in range(num_bands):\n                        for w_id, win in enumerate(windows):\n                            win_, b_idx, buf = _compute_tile_local(\n                                win,\n                                b,\n                                num_row,\n                                num_col,\n                                bounds_canvas_coords,\n                                nodata_val,\n                                alpha,\n                                correction_method,\n                                calculation_dtype,\n                            )\n                            dst.write(buf.astype(output_dtype), b_idx + 1, window=win_)\n                            del buf, win_\n            if not parallel:\n                if \"ds\" in _worker_dataset_cache:\n                    _worker_dataset_cache[\"ds\"].close()\n                    del _worker_dataset_cache[\"ds\"]\n                _worker_dataset_cache.pop(\"block_ref_mean\", None)\n                _worker_dataset_cache.pop(\"block_loc_mean\", None)\n\n            del block_reference_mean_masked, windows\n            gc.collect()\n    return out_paths\n</code></pre>"},{"location":"api/statistics/","title":"Creating Statistical Figures","text":""},{"location":"api/statistics/#spectralmatch.statistics.compare_image_spectral_profiles","title":"<code>compare_image_spectral_profiles(input_image_dict, output_figure_path, title, xlabel, ylabel)</code>","text":"<p>Compares spectral profiles of multiple images by plotting median and interquartile ranges.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_dict</code> <code>dict</code> <p>Mapping of labels to image file paths: { 'Image A': '/image/a.tif', 'Image B': '/image/b.tif' }</p> required <code>output_figure_path</code> <code>str</code> <p>Path to save the output plot.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>xlabel</code> <code>str</code> <p>Label for the x-axis.</p> required <code>ylabel</code> <code>str</code> <p>Label for the y-axis.</p> required Outputs <p>Saves a spectral profile comparison figure to the specified path.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_image_spectral_profiles(\n    input_image_dict,\n    output_figure_path,\n    title,\n    xlabel,\n    ylabel,\n):\n    \"\"\"\n    Compares spectral profiles of multiple images by plotting median and interquartile ranges.\n\n    Args:\n        input_image_dict (dict): Mapping of labels to image file paths:\n            {\n            'Image A': '/image/a.tif',\n            'Image B': '/image/b.tif'\n            }\n        output_figure_path (str): Path to save the output plot.\n        title (str): Title of the plot.\n        xlabel (str): Label for the x-axis.\n        ylabel (str): Label for the y-axis.\n\n    Outputs:\n        Saves a spectral profile comparison figure to the specified path.\n    \"\"\"\n    os.makedirs(os.path.dirname(output_figure_path), exist_ok=True)\n    plt.figure(figsize=(10, 6))\n    colors = itertools.cycle(plt.cm.tab10.colors)\n    spectral_profiles = []\n    labels = []\n\n    for label, image_path in input_image_dict.items():\n        try:\n            with rasterio.open(image_path) as src:\n                image_data = src.read()  # shape: (bands, height, width)\n        except Exception as e:\n            print(f\"Failed to open {image_path}: {e}\")\n            continue\n\n        bands, height, width = image_data.shape\n        reshaped = image_data.reshape(bands, -1)\n        median = np.median(reshaped, axis=1)\n        q25, q75 = np.percentile(reshaped, [25, 75], axis=1)\n        spectral_profiles.append((median, q25, q75))\n        labels.append(label)\n\n    for i, (median, q25, q75) in enumerate(spectral_profiles):\n        color = next(colors)\n        x = range(1, len(median) + 1)\n        plt.plot(x, median, color=color, label=labels[i])\n        plt.fill_between(x, q25, q75, color=color, alpha=0.3)\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(output_figure_path, dpi=300)\n    plt.close()\n    print(f\"Figure saved to: {output_figure_path}\")\n</code></pre>"},{"location":"api/statistics/#spectralmatch.statistics.compare_image_spectral_profiles_pairs","title":"<code>compare_image_spectral_profiles_pairs(image_groups_dict, output_figure_path, title, xlabel, ylabel)</code>","text":"<p>Plots paired spectral profiles for before-and-after image comparisons.</p> <p>Parameters:</p> Name Type Description Default <code>image_groups_dict</code> <code>dict</code> <p>Mapping of labels to image path pairs (before, after): {'Image A': [     '/image/before/a.tif',     'image/after/a.tif' ], 'Image B': [     '/image/before/b.tif',     '/image/after/b.tif' ]}</p> required <code>output_figure_path</code> <code>str</code> <p>Path to save the resulting comparison figure.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>xlabel</code> <code>str</code> <p>X-axis label.</p> required <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> required Outputs <p>Saves a spectral comparison plot showing pre- and post-processing profiles.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_image_spectral_profiles_pairs(\n    image_groups_dict: dict,\n    output_figure_path: str,\n    title: str,\n    xlabel: str,\n    ylabel: str,\n    ):\n    \"\"\"\n    Plots paired spectral profiles for before-and-after image comparisons.\n\n    Args:\n        image_groups_dict (dict): Mapping of labels to image path pairs (before, after):\n            {'Image A': [\n                '/image/before/a.tif',\n                'image/after/a.tif'\n            ],\n            'Image B': [\n                '/image/before/b.tif',\n                '/image/after/b.tif'\n            ]}\n        output_figure_path (str): Path to save the resulting comparison figure.\n        title (str): Title of the plot.\n        xlabel (str): X-axis label.\n        ylabel (str): Y-axis label.\n\n    Outputs:\n        Saves a spectral comparison plot showing pre- and post-processing profiles.\n    \"\"\"\n\n    os.makedirs(os.path.dirname(output_figure_path), exist_ok=True)\n    plt.figure(figsize=(10, 6))\n    colors = itertools.cycle(plt.cm.tab10.colors)\n\n    for label, group in image_groups_dict.items():\n        if len(group) == 2:\n            image_path1, image_path2 = group\n            color = next(colors)\n\n            for i, image_path in enumerate([image_path1, image_path2]):\n                with rasterio.open(image_path) as src:\n                    img = src.read()\n                    num_bands = img.shape[0]\n                    img_reshaped = img.reshape(num_bands, -1)\n                    nodata = src.nodata\n                    if nodata is not None:\n                        img_reshaped = np.where(img_reshaped == nodata, np.nan, img_reshaped)\n                    mean_spectral = np.nanmean(img_reshaped, axis=1)\n                    bands = np.arange(1, num_bands + 1)\n                    linestyle = 'dashed' if i == 0 else 'solid'\n                    plt.plot(bands, mean_spectral, linestyle=linestyle, color=color,\n                             label=f\"{label} - {'Before' if i == 0 else 'After'}\")\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(output_figure_path, dpi=300)\n    plt.close()\n    print(f\"Figure saved to: {output_figure_path}\")\n</code></pre>"},{"location":"examples/benchmark/","title":"Benchmark Multithreading","text":"In\u00a0[\u00a0]: Copied! <pre>import os, shutil, tempfile, time\nfrom pathlib import Path\n</pre> import os, shutil, tempfile, time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_origin\n</pre> import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.transform import from_origin In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import global_regression, local_block_adjustment\n</pre> from spectralmatch import global_regression, local_block_adjustment In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def make_fake_rasters(out_dir, n_images, width, height, nodata=0):\n    out_dir = Path(out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n    profile = dict(\n        driver=\"GTiff\",\n        width=width,\n        height=height,\n        count=8,\n        dtype=\"uint16\",\n        nodata=nodata,\n        crs=\"EPSG:3857\",\n        transform=from_origin(0, 0, 1, 1),\n        tiled=True,\n        blockxsize=512,\n        blockysize=512,\n        compress=\"LZW\",\n    )\n    rng = np.random.default_rng(seed=42)\n    paths = []\n    for i in range(n_images):\n        p = out_dir / f\"fake_{i+1}_{width}px.tif\"\n        with rasterio.open(p, \"w\", **profile) as dst:\n            for b in range(1, 9):\n                data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")\n                data[0, 0] = nodata\n                dst.write(data, indexes=b)\n        paths.append(str(p))\n    return paths\n</pre> def make_fake_rasters(out_dir, n_images, width, height, nodata=0):     out_dir = Path(out_dir)     out_dir.mkdir(parents=True, exist_ok=True)     profile = dict(         driver=\"GTiff\",         width=width,         height=height,         count=8,         dtype=\"uint16\",         nodata=nodata,         crs=\"EPSG:3857\",         transform=from_origin(0, 0, 1, 1),         tiled=True,         blockxsize=512,         blockysize=512,         compress=\"LZW\",     )     rng = np.random.default_rng(seed=42)     paths = []     for i in range(n_images):         p = out_dir / f\"fake_{i+1}_{width}px.tif\"         with rasterio.open(p, \"w\", **profile) as dst:             for b in range(1, 9):                 data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")                 data[0, 0] = nodata                 dst.write(data, indexes=b)         paths.append(str(p))     return paths In\u00a0[\u00a0]: Copied! <pre>SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288]\nNUM_IMAGES = 2\nTILE_SIZE = (1024, 1024)\nMAX_WORKERS = 32\n</pre> SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288] NUM_IMAGES = 2 TILE_SIZE = (1024, 1024) MAX_WORKERS = 32 In\u00a0[\u00a0]: Copied! <pre>WORK_DIR = Path(__file__).parent / \"bench_output\"\nWORK_DIR.mkdir(exist_ok=True)\n</pre> WORK_DIR = Path(__file__).parent / \"bench_output\" WORK_DIR.mkdir(exist_ok=True) In\u00a0[\u00a0]: Copied! <pre>SERIAL, PARALLEL = [], []\n</pre> SERIAL, PARALLEL = [], [] In\u00a0[\u00a0]: Copied! <pre>for sz in SIZES:\n    print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")\n    tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))\n    imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)\n\n    t0 = time.time()\n    g_dir = tmp / \"serial_g\"\n    l_dir = tmp / \"serial_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        window_size=TILE_SIZE,\n        parallel=False,\n        debug_logs=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        window_size=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=False,\n        debug_logs=False,\n    )\n    SERIAL.append(time.time() - t0)\n    print(f\"serial   : {SERIAL[-1]:.1f} s\")\n\n    t0 = time.time()\n    g_dir = tmp / \"parallel_g\"\n    l_dir = tmp / \"parallel_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        window_size=TILE_SIZE,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_logs=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        window_size=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_logs=False,\n    )\n    PARALLEL.append(time.time() - t0)\n    print(f\"parallel : {PARALLEL[-1]:.1f} s\")\n\n    shutil.rmtree(tmp, ignore_errors=True)\n</pre> for sz in SIZES:     print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")     tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))     imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)      t0 = time.time()     g_dir = tmp / \"serial_g\"     l_dir = tmp / \"serial_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         window_size=TILE_SIZE,         parallel=False,         debug_logs=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         window_size=TILE_SIZE,         custom_nodata_value=-9999,         parallel=False,         debug_logs=False,     )     SERIAL.append(time.time() - t0)     print(f\"serial   : {SERIAL[-1]:.1f} s\")      t0 = time.time()     g_dir = tmp / \"parallel_g\"     l_dir = tmp / \"parallel_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         window_size=TILE_SIZE,         parallel=True,         max_workers=MAX_WORKERS,         debug_logs=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         window_size=TILE_SIZE,         custom_nodata_value=-9999,         parallel=True,         max_workers=MAX_WORKERS,         debug_logs=False,     )     PARALLEL.append(time.time() - t0)     print(f\"parallel : {PARALLEL[-1]:.1f} s\")      shutil.rmtree(tmp, ignore_errors=True) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 5))\nplt.plot(SIZES, SERIAL, \"-o\", label=\"serial\")\nplt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\")\nplt.xlabel(\"Raster width = height (pixels)\")\nplt.ylabel(\"Total runtime: global + local (seconds)\")\nplt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(8, 5)) plt.plot(SIZES, SERIAL, \"-o\", label=\"serial\") plt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\") plt.xlabel(\"Raster width = height (pixels)\") plt.ylabel(\"Total runtime: global + local (seconds)\") plt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\") plt.grid(True) plt.legend() plt.tight_layout() plt.show()"},{"location":"examples/example_landsat_time_series/","title":"Landsat Time Series","text":"In\u00a0[\u00a0]: Copied! <pre># This notebook demonstrates how to preprocess Landsat 8-9 into a time series with spectralmatch.\n# Starting from 5 Landsat 8-9 OLI/TIRS C2 L1 images, the process includes clipping clouds with OmniCloudMask, masking high NDVI areas as Pseudo Invariant Features (PIFs), applying global regression Relative Radiometric Normalization, fine-tuning overlap areas with local block adjustment, and before vs after statistics.\n# This script is set up to perform matching on all tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif.\n</pre> # This notebook demonstrates how to preprocess Landsat 8-9 into a time series with spectralmatch. # Starting from 5 Landsat 8-9 OLI/TIRS C2 L1 images, the process includes clipping clouds with OmniCloudMask, masking high NDVI areas as Pseudo Invariant Features (PIFs), applying global regression Relative Radiometric Normalization, fine-tuning overlap areas with local block adjustment, and before vs after statistics. # This script is set up to perform matching on all tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. In\u00a0[\u00a0]: Copied! <pre>import os\nfrom spectralmatch import *\n\n# Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview3 folder\nworking_directory = '/Users/kanoalindiwe/Downloads/Projects/spectralmatch/docs/examples/data_landsat'\nprint(working_directory)\n\ninput_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\nmask_cloud_folder = os.path.join(working_directory, \"MaskCloud\")\nmask_vegetation_folder = os.path.join(working_directory, \"MaskVegetation\")\nmasked_folder = os.path.join(working_directory, \"Masked\")\nstats_folder = os.path.join(working_directory, \"Stats\")\n\nwindow_size = 128\nnum_workers = 5\n</pre> import os from spectralmatch import *  # Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview3 folder working_directory = '/Users/kanoalindiwe/Downloads/Projects/spectralmatch/docs/examples/data_landsat' print(working_directory)  input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"GlobalMatch\") local_folder = os.path.join(working_directory, \"LocalMatch\") mask_cloud_folder = os.path.join(working_directory, \"MaskCloud\") mask_vegetation_folder = os.path.join(working_directory, \"MaskVegetation\") masked_folder = os.path.join(working_directory, \"Masked\") stats_folder = os.path.join(working_directory, \"Stats\")  window_size = 128 num_workers = 5 In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\n\nfor path in input_image_paths:\n    create_cloud_mask_with_omnicloudmask(\n        path,\n        5,\n        3,\n        8,\n        os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.tif\"),\n        # down_sample_m=10\n    )\n\ninput_mask_rasters_paths = search_paths(mask_cloud_folder, \"*.tif\")\n\nfor path in input_mask_rasters_paths:\n    post_process_raster_cloud_mask_to_vector(\n        path,\n        os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}.gpkg\"),\n        None,\n        {1: 50},\n        {0: None, 1: 1, 2: 1, 3: 1}\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\")  for path in input_image_paths:     create_cloud_mask_with_omnicloudmask(         path,         5,         3,         8,         os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.tif\"),         # down_sample_m=10     )  input_mask_rasters_paths = search_paths(mask_cloud_folder, \"*.tif\")  for path in input_mask_rasters_paths:     post_process_raster_cloud_mask_to_vector(         path,         os.path.join(mask_cloud_folder, f\"{os.path.splitext(os.path.basename(path))[0]}.gpkg\"),         None,         {1: 50},         {0: None, 1: 1, 2: 1, 3: 1}     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\ninput_mask_vectors = search_paths(mask_cloud_folder, \"*.gpkg\", match_to_paths=(input_image_paths, r\"(.*)_CloudMask\\.gpkg$\"))\noutput_paths = create_paths(masked_folder, \"$_CloudMasked.tif\", input_image_paths)\n\nfor input_path, vector_path, output_path in zip(input_image_paths, input_mask_vectors, output_paths):\n    mask_image_with_vector(\n        input_path,\n        vector_path,\n        output_path,\n        (\"include\", \"value\", 1),\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\") input_mask_vectors = search_paths(mask_cloud_folder, \"*.gpkg\", match_to_paths=(input_image_paths, r\"(.*)_CloudMask\\.gpkg$\")) output_paths = create_paths(masked_folder, \"$_CloudMasked.tif\", input_image_paths)  for input_path, vector_path, output_path in zip(input_image_paths, input_mask_vectors, output_paths):     mask_image_with_vector(         input_path,         vector_path,         output_path,         (\"include\", \"value\", 1),     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(input_folder, \"*.tif\")\nraster_mask_paths = create_paths(mask_vegetation_folder, \"$_VegetationMask.tif\", input_image_paths)\nvector_mask_paths = create_paths(mask_vegetation_folder, \"$.gpkg\", input_image_paths)\n\nfor input_path, raster_path in zip(input_image_paths, raster_mask_paths):\n    create_ndvi_mask(\n        input_path,\n        raster_path,\n        5,\n        4,\n    )\n\nfor raster_path, vector_path in zip(raster_mask_paths, vector_mask_paths):\n    post_process_threshold_to_vector(\n        raster_path,\n        vector_path,\n        0.1,\n        \"&gt;=\",\n    )\n</pre> input_image_paths = search_paths(input_folder, \"*.tif\") raster_mask_paths = create_paths(mask_vegetation_folder, \"$_VegetationMask.tif\", input_image_paths) vector_mask_paths = create_paths(mask_vegetation_folder, \"$.gpkg\", input_image_paths)  for input_path, raster_path in zip(input_image_paths, raster_mask_paths):     create_ndvi_mask(         input_path,         raster_path,         5,         4,     )  for raster_path, vector_path in zip(raster_mask_paths, vector_mask_paths):     post_process_threshold_to_vector(         raster_path,         vector_path,         0.1,         \"&gt;=\",     ) In\u00a0[\u00a0]: Copied! <pre># This is just a simple example of creating PIFs based on NDVI values, for a more robust methodology use other techniques to create a better mask vector file\n\ninput_vector_paths = search_paths(mask_vegetation_folder, \"*.gpkg\")\nmerged_vector_pif_path = os.path.join(working_directory, \"Pifs.gpkg\")\n\nmerge_vectors(\n    input_vector_paths,\n    merged_vector_pif_path,\n    create_name_attribute=(\"image\", \", \"),\n    method=\"intersection\",\n    # method=\"keep_all\", # Create a unique mask per image\n    )\n</pre> # This is just a simple example of creating PIFs based on NDVI values, for a more robust methodology use other techniques to create a better mask vector file  input_vector_paths = search_paths(mask_vegetation_folder, \"*.gpkg\") merged_vector_pif_path = os.path.join(working_directory, \"Pifs.gpkg\")  merge_vectors(     input_vector_paths,     merged_vector_pif_path,     create_name_attribute=(\"image\", \", \"),     method=\"intersection\",     # method=\"keep_all\", # Create a unique mask per image     ) In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")\n\nglobal_regression(\n    (masked_folder, \"*.tif\"),\n    (global_folder, \"$_GlobalMatch.tif\"),\n    custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together\n    vector_mask_path=(\"exclude\", vector_mask_path),\n    # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image\n    window_size=window_size,\n    parallel_workers=num_workers,\n    debug_logs=True,\n    )\n</pre> vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")  global_regression(     (masked_folder, \"*.tif\"),     (global_folder, \"$_GlobalMatch.tif\"),     custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together     vector_mask_path=(\"exclude\", vector_mask_path),     # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image     window_size=window_size,     parallel_workers=num_workers,     debug_logs=True,     ) In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")\n\nlocal_block_adjustment(\n    (global_folder, \"*.tif\"),\n    (local_folder, \"$_LocalMatch.tif\"),\n    number_of_blocks=100,\n    vector_mask_path=(\"exclude\", vector_mask_path),\n    # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image\n    window_size=window_size,\n    parallel_workers=num_workers,\n    debug_logs=True,\n    save_block_maps=(os.path.join(local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\"), os.path.join(local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\")),\n    )\n</pre> vector_mask_path = os.path.join(working_directory , \"Pifs.gpkg\")  local_block_adjustment(     (global_folder, \"*.tif\"),     (local_folder, \"$_LocalMatch.tif\"),     number_of_blocks=100,     vector_mask_path=(\"exclude\", vector_mask_path),     # vector_mask_path=(\"exclude\", vector_mask_path, \"image\"), # Use unique mask per image     window_size=window_size,     parallel_workers=num_workers,     debug_logs=True,     save_block_maps=(os.path.join(local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\"), os.path.join(local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\")),     ) In\u00a0[\u00a0]: Copied! <pre># Compare image spectral profiles\ncompare_image_spectral_profiles(\n    input_image_dict={\n        os.path.splitext(os.path.basename(p))[0]: p\n        for p in search_paths(local_folder, \"*.tif\")\n    },\n    output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n)\n\n# Compare image spectral profiles pairs\nbefore_paths = search_paths(input_folder, \"*.tif\")\nafter_paths = search_paths(local_folder, \"*.tif\")\n\nimage_pairs = {\n    os.path.splitext(os.path.basename(b))[0]: [b, a]\n    for b, a in zip(sorted(before_paths), sorted(after_paths))\n    }\n\ncompare_image_spectral_profiles_pairs(\n    image_pairs,\n    os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n    )\n\n# Compare spatial spectral difference band average\ninput_paths = search_paths(input_folder, \"*.tif\")\nlocal_paths = search_paths(local_folder, \"*.tif\")\nbefore_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))\n\ncompare_spatial_spectral_difference_band_average(\n    input_images=[before_path, after_path],\n    output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),\n    title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",\n    diff_label=\"Reflectance Difference (0\u201310,000)\",\n    subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\",\n)\n</pre>  # Compare image spectral profiles compare_image_spectral_profiles(     input_image_dict={         os.path.splitext(os.path.basename(p))[0]: p         for p in search_paths(local_folder, \"*.tif\")     },     output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles\",     xlabel='Band',     ylabel='Reflectance(0-10,000)', )  # Compare image spectral profiles pairs before_paths = search_paths(input_folder, \"*.tif\") after_paths = search_paths(local_folder, \"*.tif\")  image_pairs = {     os.path.splitext(os.path.basename(b))[0]: [b, a]     for b, a in zip(sorted(before_paths), sorted(after_paths))     }  compare_image_spectral_profiles_pairs(     image_pairs,     os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",     xlabel='Band',     ylabel='Reflectance(0-10,000)',     )  # Compare spatial spectral difference band average input_paths = search_paths(input_folder, \"*.tif\") local_paths = search_paths(local_folder, \"*.tif\") before_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))  compare_spatial_spectral_difference_band_average(     input_images=[before_path, after_path],     output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),     title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",     diff_label=\"Reflectance Difference (0\u201310,000)\",     subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\", )"},{"location":"examples/example_worldview_mosaic/","title":"WorldView Mosaic","text":"In\u00a0[\u00a0]: Copied! <pre># This file demonstrates how to preprocess Worldview3 imagery into a mosaic using spectralmatch.\n# Starting from two overlapping Worldview3 images in reflectance, the process includes global matching, local matching, starting from saved block maps (optional for demonstration purposes), generating seamlines, and marging images, and before vs after statistics.\n# This script is set up to perform matching on all .tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. The easiest way to process your own imagery is to move it inside that folder or change the working_directory to another folder with this structure, alternatively, you can pass in custom lists of image paths.\n</pre> # This file demonstrates how to preprocess Worldview3 imagery into a mosaic using spectralmatch. # Starting from two overlapping Worldview3 images in reflectance, the process includes global matching, local matching, starting from saved block maps (optional for demonstration purposes), generating seamlines, and marging images, and before vs after statistics. # This script is set up to perform matching on all .tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. The easiest way to process your own imagery is to move it inside that folder or change the working_directory to another folder with this structure, alternatively, you can pass in custom lists of image paths. In\u00a0[\u00a0]: Copied! <pre>import os\n\nfrom fiona.env import local\nfrom spectralmatch import *\n\n# Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview3 folder\nworking_directory = '/Users/kanoalindiwe/Downloads/Projects/spectralmatch/docs/examples/data_worldview3'\nprint(working_directory)\n\ninput_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\naligned_folder = os.path.join(working_directory, \"Aligned\")\nclipped_folder = os.path.join(working_directory, \"Clipped\")\nstats_folder = os.path.join(working_directory, \"Stats\")\n\nwindow_size = 128\nnum_workers = 5\n</pre> import os  from fiona.env import local from spectralmatch import *  # Important: If this does not automatically find the correct CWD, manually copy the path to the /data_worldview3 folder working_directory = '/Users/kanoalindiwe/Downloads/Projects/spectralmatch/docs/examples/data_worldview3' print(working_directory)  input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"GlobalMatch\") local_folder = os.path.join(working_directory, \"LocalMatch\") aligned_folder = os.path.join(working_directory, \"Aligned\") clipped_folder = os.path.join(working_directory, \"Clipped\") stats_folder = os.path.join(working_directory, \"Stats\")  window_size = 128 num_workers = 5 In\u00a0[\u00a0]: Copied! <pre>saved_adjustments_path = os.path.join(global_folder, \"GlobalAdjustments.json\")\n\n\nglobal_regression(\n    (input_folder, \"*.tif\"),\n    (global_folder, \"$_Global.tif\"),\n    custom_mean_factor = 3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    )\n</pre> saved_adjustments_path = os.path.join(global_folder, \"GlobalAdjustments.json\")   global_regression(     (input_folder, \"*.tif\"),     (global_folder, \"$_Global.tif\"),     custom_mean_factor = 3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     ) In\u00a0[\u00a0]: Copied! <pre>new_global_folder = os.path.join(working_directory, \"GlobalMatch_New\")\nsaved_adjustments_path = os.path.join(new_global_folder, \"GlobalAdjustments.json\")\n\n\nglobal_regression(\n    (input_folder, \"*.tif\"),\n    (new_global_folder, \"$_Global.tif\"),\n    custom_mean_factor = 3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    specify_model_images=(\"include\", ['worldview3_example_image_right']),\n    save_adjustments=saved_adjustments_path,\n    )\n</pre> new_global_folder = os.path.join(working_directory, \"GlobalMatch_New\") saved_adjustments_path = os.path.join(new_global_folder, \"GlobalAdjustments.json\")   global_regression(     (input_folder, \"*.tif\"),     (new_global_folder, \"$_Global.tif\"),     custom_mean_factor = 3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     specify_model_images=(\"include\", ['worldview3_example_image_right']),     save_adjustments=saved_adjustments_path,     ) In\u00a0[\u00a0]: Copied! <pre>new_global_folder = os.path.join(working_directory, \"GlobalMatch_New\")\nsaved_adjustments_path = os.path.join(new_global_folder, \"GlobalAdjustments.json\")\n\n\nglobal_regression(\n    (input_folder, \"*.tif\"),\n    (new_global_folder, \"$_Global.tif\"),\n    custom_mean_factor = 3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    load_adjustments=saved_adjustments_path,\n    )\n</pre> new_global_folder = os.path.join(working_directory, \"GlobalMatch_New\") saved_adjustments_path = os.path.join(new_global_folder, \"GlobalAdjustments.json\")   global_regression(     (input_folder, \"*.tif\"),     (new_global_folder, \"$_Global.tif\"),     custom_mean_factor = 3, # Default is 1; 3 often works better to 'move' the spectral mean of images closer together     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     load_adjustments=saved_adjustments_path,     ) In\u00a0[\u00a0]: Copied! <pre>local_block_adjustment(\n    (global_folder, \"*.tif\"),\n    (local_folder, \"$_Local.tif\"),\n    number_of_blocks=100,\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    )\n</pre> local_block_adjustment(     (global_folder, \"*.tif\"),     (local_folder, \"$_Local.tif\"),     number_of_blocks=100,     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     ) In\u00a0[\u00a0]: Copied! <pre>new_local_folder = os.path.join(working_directory, \"LocalMatch_New\")\nreference_map_path = os.path.join(new_local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\")\nlocal_maps_path = os.path.join(new_local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\")\n\nlocal_block_adjustment(\n    (global_folder, \"*.tif\"),\n    (new_local_folder, \"$_Local.tif\"),\n    number_of_blocks=(30,30),\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    override_bounds_canvas_coords = (193011.1444011169369332, 2184419.3597142999060452, 205679.2836037494416814, 2198309.8632259583100677),\n    save_block_maps=(reference_map_path, local_maps_path),\n    )\n</pre> new_local_folder = os.path.join(working_directory, \"LocalMatch_New\") reference_map_path = os.path.join(new_local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\") local_maps_path = os.path.join(new_local_folder, \"LocalBlockMap\", \"$_LocalBlockMap.tif\")  local_block_adjustment(     (global_folder, \"*.tif\"),     (new_local_folder, \"$_Local.tif\"),     number_of_blocks=(30,30),     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     override_bounds_canvas_coords = (193011.1444011169369332, 2184419.3597142999060452, 205679.2836037494416814, 2198309.8632259583100677),     save_block_maps=(reference_map_path, local_maps_path),     ) In\u00a0[\u00a0]: Copied! <pre>old_local_folder = os.path.join(working_directory, \"LocalMatch\")\nnew_local_folder = os.path.join(working_directory, \"LocalMatch_New\")\nsaved_reference_block_path = os.path.join(old_local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\")\nsaved_local_block_paths = [os.path.join(os.path.join(new_local_folder, \"LocalBlockMap\"), f) for f in os.listdir(os.path.join(new_local_folder, \"LocalBlockMap\")) if f.lower().endswith(\".tif\")]\n\nlocal_block_adjustment(\n    (global_folder, \"*.tif\"),\n    (new_local_folder, \"$_Local.tif\"),\n    number_of_blocks=100,\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    load_block_maps=(None, saved_local_block_paths)\n    )\n</pre>  old_local_folder = os.path.join(working_directory, \"LocalMatch\") new_local_folder = os.path.join(working_directory, \"LocalMatch_New\") saved_reference_block_path = os.path.join(old_local_folder, \"ReferenceBlockMap\", \"ReferenceBlockMap.tif\") saved_local_block_paths = [os.path.join(os.path.join(new_local_folder, \"LocalBlockMap\"), f) for f in os.listdir(os.path.join(new_local_folder, \"LocalBlockMap\")) if f.lower().endswith(\".tif\")]  local_block_adjustment(     (global_folder, \"*.tif\"),     (new_local_folder, \"$_Local.tif\"),     number_of_blocks=100,     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     load_block_maps=(None, saved_local_block_paths)     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(local_folder, \"*.tif\")\noutput_clipped_image_paths = create_paths(aligned_folder, \"$_Aligned.tif\", input_image_paths)\n\nprocess_rasters(\n    input_image_paths,\n    output_clipped_image_paths,\n    tap=True,\n    resolution='highest',\n    debug_logs=True,\n    window_size=window_size,\n    )\n</pre> input_image_paths = search_paths(local_folder, \"*.tif\") output_clipped_image_paths = create_paths(aligned_folder, \"$_Aligned.tif\", input_image_paths)  process_rasters(     input_image_paths,     output_clipped_image_paths,     tap=True,     resolution='highest',     debug_logs=True,     window_size=window_size,     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(aligned_folder, \"*.tif\")\noutput_vector_mask = os.path.join(working_directory, \"ImageClips.gpkg\")\n\nvoronoi_center_seamline(\n    input_image_paths,\n    output_vector_mask,\n    image_field_name='image',\n    debug_logs=True,\n    )\n</pre> input_image_paths = search_paths(aligned_folder, \"*.tif\") output_vector_mask = os.path.join(working_directory, \"ImageClips.gpkg\")  voronoi_center_seamline(     input_image_paths,     output_vector_mask,     image_field_name='image',     debug_logs=True,     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = search_paths(aligned_folder, \"*.tif\")\noutput_clipped_image_paths = create_paths(clipped_folder, \"$_Clipped.tif\", input_image_paths)\ninput_vector_mask_path = os.path.join(working_directory, \"ImageClips.gpkg\")\noutput_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")\n\nprocess_rasters(\n    input_image_paths,\n    output_clipped_image_paths,\n    vector_mask_path=input_vector_mask_path,\n    debug_logs=True,\n    split_mask_by_attribute=\"image\",\n    window_size=window_size,\n    )\n\nmerge_rasters(\n    output_clipped_image_paths,\n    output_merged_image_path,\n    window_size=window_size,\n    debug_logs=True,\n)\n</pre> input_image_paths = search_paths(aligned_folder, \"*.tif\") output_clipped_image_paths = create_paths(clipped_folder, \"$_Clipped.tif\", input_image_paths) input_vector_mask_path = os.path.join(working_directory, \"ImageClips.gpkg\") output_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")  process_rasters(     input_image_paths,     output_clipped_image_paths,     vector_mask_path=input_vector_mask_path,     debug_logs=True,     split_mask_by_attribute=\"image\",     window_size=window_size,     )  merge_rasters(     output_clipped_image_paths,     output_merged_image_path,     window_size=window_size,     debug_logs=True, ) In\u00a0[\u00a0]: Copied! <pre># Compare image spectral profiles\ncompare_image_spectral_profiles(\n    input_image_dict={\n        os.path.splitext(os.path.basename(p))[0]: p\n        for p in search_paths(local_folder, \"*.tif\")\n    },\n    output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n)\n\n# Compare image spectral profiles pairs\nbefore_paths = search_paths(input_folder, \"*.tif\")\nafter_paths = search_paths(local_folder, \"*.tif\")\n\nimage_pairs = {\n    os.path.splitext(os.path.basename(b))[0]: [b, a]\n    for b, a in zip(sorted(before_paths), sorted(after_paths))\n    }\n\ncompare_image_spectral_profiles_pairs(\n    image_pairs,\n    os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),\n    title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",\n    xlabel='Band',\n    ylabel='Reflectance(0-10,000)',\n    )\n\n# Compare spatial spectral difference band average\ninput_paths = search_paths(input_folder, \"*.tif\")\nlocal_paths = search_paths(local_folder, \"*.tif\")\nbefore_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))\n\ncompare_spatial_spectral_difference_band_average(\n    input_images=[before_path, after_path],\n    output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),\n    title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",\n    diff_label=\"Reflectance Difference (0\u201310,000)\",\n    subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\",\n)\n</pre>  # Compare image spectral profiles compare_image_spectral_profiles(     input_image_dict={         os.path.splitext(os.path.basename(p))[0]: p         for p in search_paths(local_folder, \"*.tif\")     },     output_figure_path=os.path.join(stats_folder,'LocalMatch_CompareImageSpectralProfiles.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles\",     xlabel='Band',     ylabel='Reflectance(0-10,000)', )  # Compare image spectral profiles pairs before_paths = search_paths(input_folder, \"*.tif\") after_paths = search_paths(local_folder, \"*.tif\")  image_pairs = {     os.path.splitext(os.path.basename(b))[0]: [b, a]     for b, a in zip(sorted(before_paths), sorted(after_paths))     }  compare_image_spectral_profiles_pairs(     image_pairs,     os.path.join(stats_folder, 'LocalMatch_CompareImageSpectralProfilesPairs.png'),     title=\"Global to Local Match Comparison of Image Spectral Profiles Pairs\",     xlabel='Band',     ylabel='Reflectance(0-10,000)',     )  # Compare spatial spectral difference band average input_paths = search_paths(input_folder, \"*.tif\") local_paths = search_paths(local_folder, \"*.tif\") before_path, after_path = next(zip(sorted(input_paths), sorted(local_paths)))  compare_spatial_spectral_difference_band_average(     input_images=[before_path, after_path],     output_image_path=os.path.join(stats_folder, 'LocalMatch_CompareSpatialSpectralDifferenceBandAverage.png'),     title=\"Global to Local Match Comparison of Spatial Spectral Difference Band Average\",     diff_label=\"Reflectance Difference (0\u201310,000)\",     subtitle=f\"Image: {os.path.splitext(os.path.basename(before_path))[0]}\", )"}]}