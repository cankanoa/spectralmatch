{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"spectralmatch: A toolkit to perform Relative Radiometric Normalization, with utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, and statistics","text":"<p>[!IMPORTANT] This library is experimental and still under heavy development.</p>"},{"location":"#overview","title":"Overview","text":"<p>spectralmatch provides a Python library and QGIS plugin with multiple algorythms to perform Relative Radiometric Normalization (RRN). It also includes utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, statistics, preprocessing, and more.</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p>Automated: Works without manual intervention, making it ideal for large-scale applications.</p> </li> <li> <p>Consistent Multi-Image Analysis: Ensures uniformity across images by applying systematic corrections with minimal spectral distortion.</p> </li> <li> <p>Seamlessly Blended: Creates smooth transitions between images without visible seams.</p> </li> <li> <p>Unit Agnostic: Works with any pixel unit and preserves the spectral information for accurate analysis. This inlcludes negative numbers and reflectance.</p> </li> <li> <p>Better Input for Machine Learning Models: Provides high-quality, unbiased data for AI and analytical workflows.</p> </li> <li> <p>Minimizes Color Bias: Avoids excessive color normalization and does not rely on a strict reference image.</p> </li> <li> <p>Sensor Agnostic: Works with all optical sensors. In addition, images from differnt sensors can be combined for multisensor analysis.</p> </li> <li> <p>Parallel Processing: Optimized for modern CPUs to handle large datasets efficiently.</p> </li> <li> <p>Large-Scale Mosaics: Designed to process and blend vast image collections effectively.</p> </li> <li>Time Series: Normalize images across time with to compare spectral changes.</li> </ul>"},{"location":"#current-matching-algorithms","title":"Current Matching Algorithms","text":""},{"location":"#global-to-local-matching","title":"Global to local matching","text":"<p>This technique is derived from 'An auto-adapting global-to-local color balancing method for optical imagery mosaic' by Yu et al., 2017 (DOI: 10.1016/j.isprsjprs.2017.08.002). It is particularly useful for very high-resolution imagery (satellite or otherwise) and works in a two phase process. First, this method applies least squares regression to estimate scale and offset parameters that align the histograms of all images toward a shared spectral center. This is achieved by constructing a global model based on the overlapping areas of adjacent images, where the spectral relationships are defined. This global model ensures that each image conforms to a consistent radiometric baseline while preserving overall color fidelity. However, global correction alone cannot capture intra-image variability so a second local adjustment phase is performed. The overlap areas are divided into smaller blocks, and each block\u2019s mean is used to fine-tune the color correction. This block-wise tuning helps maintain local contrast and reduces visible seams, resulting in seamless and spectrally consistent mosaics with minimal distortion.</p> <p> Shows the average spectral profile of two WorldView 3 images before and after global to local matching.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<ul> <li> <p>Consistent Spectral Profile: The true spectral response of overlapping areas remains the same throughout the images.</p> </li> <li> <p>Least Squares Modeling: A least squares approach can effectively model and fit all images' spectral profiles.</p> </li> <li> <p>Scale and Offset Adjustment: Applying scale and offset corrections can effectively harmonize images.</p> </li> <li> <p>Minimized Color Differences: The best color correction is achieved when color differences are minimized.</p> </li> <li> <p>Geometric Alignment: Images are assumed to be geometrically aligned with known relative positions.</p> </li> <li> <p>Global Consistency: Overlapping color differences are consistent across the entire image.</p> </li> <li> <p>Local Adjustments: Block-level color differences result from the global application of adjustments.</p> </li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Detailed installation instructions are available in the docs.</p>"},{"location":"#installation-as-a-qgis-plugin","title":"Installation as a QGIS Plugin","text":"<p>Install the spectralmatch plugin in QGIS and use it in the Processing Toolbox.</p>"},{"location":"#installation-as-a-python-library","title":"Installation as a Python Library","text":"<p>Before installing, ensure you have the following system-level prerequisites: <code>Python \u2265 3.10</code>, <code>pip</code>, <code>PROJ \u2265 9.3</code>, and <code>GDAL = 3.10.2</code>. Use this command to install the library:</p> <pre><code>pip install spectralmatch\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at spectralmatch.github.io/spectralmatch/.</p>"},{"location":"#contributing-guide","title":"Contributing Guide","text":"<p>Contributing Guide is available at spectralmatch.github.io/spectralmatch/development.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See LICENSE for details.</p>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>This project includes a Makefile to streamline development tasks. Makefiles allow you to automate and organize common tasks, in this case to help serve and deploy documentation, manage version tags, format and lint code, and run tests.</p> <p>Installation instructions are on their own page</p>"},{"location":"contributing/#collaboration-instructions","title":"Collaboration Instructions","text":"<p>We welcome all contributions the project! Please be respectful and work towards improving the library. To get started:</p> <ol> <li> <p>Create an issue describing the feature or bug or just to ask a question. Provide relevant context, desired timeline, any assistance needed, who will be responsible for the work, anticipated results, and any other details.</p> </li> <li> <p>Fork the repository and create a new feature branch.</p> </li> <li> <p>Make your changes and add any necessary tests.</p> </li> <li> <p>Open a Pull Request against the main repository.</p> </li> </ol>"},{"location":"contributing/#design-guidelines-and-philosophy","title":"Design Guidelines and Philosophy","text":"<ul> <li>Keep code concise and simple</li> <li>Adapt code for large datasets with windows, multiprocessing, progressive computations, etc</li> <li>Keep code modular and have descriptive names</li> <li>Create docstrings (Google style), tests, and update the docs for new functionality</li> <li>Use similar naming convention and input parameters as other functions</li> <li>Use PEP 8 code formatting </li> </ul>"},{"location":"contributing/#file-cleanup","title":"File Cleanup","text":"<p>Temporary generated files can be deleted once they are no longer needed via this command: <pre><code>make clean\n</code></pre></p>"},{"location":"contributing/#docs","title":"Docs","text":""},{"location":"contributing/#serve-docs-locally","title":"Serve docs locally","text":"<p>Runs a local dev server at http://localhost:8000. <pre><code>make docs-serve\n</code></pre></p>"},{"location":"contributing/#build-static-site","title":"Build static site","text":"<p>Generates the static site into the site/ folder.</p> <pre><code>make docs-build\n</code></pre>"},{"location":"contributing/#deploy-to-github-pages","title":"Deploy to GitHub Pages","text":"<p>Deploys built site using mkdocs gh-deploy. <pre><code>make docs-deploy\n</code></pre></p>"},{"location":"contributing/#versioning","title":"Versioning","text":"<p>Uses git tag to create annotated version tags and push them. This also syncs to Pypi. New versions will be released when the maintainer determines sufficient new functionality has been added. <pre><code>make tag version=1.2.3\n</code></pre></p>"},{"location":"contributing/#code-formatting","title":"Code Formatting","text":"<p>This project uses black for code formatting and ruff for linting.</p>"},{"location":"contributing/#set-up-pre-commit-hooks-recommended","title":"Set Up Pre-commit Hooks (Recommended)","text":"<p>To maintain code consistency use this hook to check and correct code formatting automatically:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>"},{"location":"contributing/#manual-formatting","title":"Manual Formatting","text":"<p>Format code: Automatically formats all Python files with black.</p> <pre><code>make format\n</code></pre> <p>Check formatting: Checks that all code is formatted (non-zero exit code if not). <pre><code>make check-format\n</code></pre></p> <p>Lint code: Runs ruff to catch style and quality issues. <pre><code>make lint\n</code></pre></p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>pytest is used for testing. Tests will automatically be run when merging into main but they can also be run locally via: <pre><code>make test\n</code></pre></p> <p>To test a individual folder or file: <pre><code>make test-file path=path/to/folder_or_file\n</code></pre></p>"},{"location":"formats_and_requirements/","title":"File Formats and Input Requirements","text":""},{"location":"formats_and_requirements/#input-raster-requirements","title":"Input Raster Requirements","text":"<p>Input rasters must meet specific criteria to ensure compatibility during processing. These are checked by _check_raster_requirements():</p> <ul> <li>Have a valid geotransform</li> <li>Share the same coordinate reference system (CRS)</li> <li>Have an identical number of bands</li> <li>Use consistent nodata values</li> </ul> <p>Additionally, all rasters should:</p> <ul> <li>Have overlap which represents the same data in each raster</li> <li>Have a consistent spectral profile </li> </ul>"},{"location":"formats_and_requirements/#regression-parameters-file","title":"Regression Parameters File","text":"<p>Regression parameters can be stored in a <code>json</code> file which includes:</p> <ul> <li>Adjustments: Per-band scale and offset values applied to each image.</li> <li>Whole Stats: Per-band mean, std, and size representing overall image statistics.</li> <li>Overlap Stats: Per-image pair mean, std, and size for overlapping geometry regions.</li> </ul> <p>The structure is a dictionary keyed by images basenames (no extension) with the following format:</p> <p><pre><code>{\n  \"image_name\": {\n    \"adjustments\": {\n      \"band_0\": {\"scale\": float, \"offset\": float},\n      ...\n    },\n    \"whole_stats\": {\n      \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n      ...\n    },\n    \"overlap_stats\": {\n      \"other_image\": {\n        \"band_0\": {\"mean\": float, \"std\": float, \"size\": int},\n        ...\n      },\n      ...\n    }\n  },\n  ...\n}\n</code></pre> This format represents the following: For each image_name there are adjustment, whole_stats and overlap_stats. For each adjustments, for each band, there is scale and offset. For each whole_stats and overlap_stats, for each band, there is mean, std, and size (number of pixels). Each band key follows the format band_0, band_1, etc. Mean and std are floats and size is an integer.</p> <p>This structure is validated by <code>_validate_adjustment_model_structure()</code> before use to ensure consistency and completeness across images and bands. Global regression does not actually use 'adjustments' field because they are recalculated every run.</p>"},{"location":"formats_and_requirements/#block-maps-file","title":"Block Maps File","text":"<p>Block maps are spatial summaries of raster data, where each block represents the mean values of a group of pixels over a fixed region. They are used to reduce image resolution while preserving local radiometric characteristics, enabling efficient comparison and adjustment across images. Each map is structured as a grid of blocks with values for each spectral band. They can be saved as regular <code>geotif</code> files and together store this information: block_local_means, block_reference_mean, num_row, num_col, bounds_canvas_coords. </p> <p>There are two types of block maps, although their format is exactly the same:</p> <ul> <li>Local Block Map: Each block stores the mean value of all pixels within its boundary for a single image.</li> <li>Reference Block Map: Each block is the mean of all images means for its boundary; simply the mean of all local block maps.</li> </ul> <p>Both block maps have the shape: <code>num_row, num_col, num_bands</code>, however, there are multiple (one for each image) local block maps and only one reference block map. Once a reference block map is created it is unique to its input images and cannot be accurately modified to add additional images. However, images can be 'brought' to a reference block map even if they were not involved in its creation as long as it covers that image.</p>"},{"location":"installation/","title":"Installation Methods","text":""},{"location":"installation/#installation-as-qgis-plugin-for-easy-gui-interface","title":"Installation as QGIS Plugin for Easy GUI Interface","text":""},{"location":"installation/#1-download-and-install-qgis","title":"1. Download and install QGIS","text":""},{"location":"installation/#2-open-qgis","title":"2.  Open QGIS","text":""},{"location":"installation/#3-go-to-plugins-manage-and-install-plugins","title":"3.  Go to Plugins \u2192 Manage and Install Plugins\u2026","text":""},{"location":"installation/#4-find-spectralmatch-in-the-list-install-and-enable-it","title":"4.  Find spectralmatch in the list, install, and enable it","text":""},{"location":"installation/#5-find-the-plugin-in-the-processing-toolbox","title":"5.  Find the plugin in the Processing Toolbox","text":""},{"location":"installation/#installation-as-a-python-library-for-use-in-code-recommended","title":"Installation as a Python Library for use in Code (Recommended)","text":""},{"location":"installation/#1-system-requirements","title":"1. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL \u2265 3.6</li> <li>pip</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python=3.10 \"gdal&gt;=3.6\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"installation/#2-install-spectralmatch","title":"2. Install spectralmatch","text":"<p>You can automatically install the library via PyPI. (this method installs only the core code as a library):</p> <pre><code>pip install spectralmatch\n</code></pre>"},{"location":"installation/#3-run-an-example-and-modify-for-your-use-optional","title":"3. Run an example and modify for your use (optional)","text":"<p>Example scripts are provided to verify a successful installation and help you get started quickly in the repository at <code>/docs/examples</code> and downloadable via this <code>link</code>.</p>"},{"location":"installation/#installation-as-python-code-for-development-and-customization","title":"Installation as Python Code for Development and Customization","text":""},{"location":"installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\n</code></pre> <p>Assuming you have Make installed, you can then run <code>make install-setup</code> to automatically complete the remaining setup steps.</p>"},{"location":"installation/#2-system-requirements","title":"2. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL \u2265 3.6</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python=3.10 \"gdal=3.10.2\" \"proj&gt;=9.3\" -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"installation/#3-install-dependancies-optional-dev-and-docs-dependancies","title":"3. Install Dependancies (Optional Dev and Docs Dependancies)","text":"<p>The <code>pyproject.toml</code> defines core dependancies to run the library and optional dev, and docs dependancies.</p> <pre><code>pip install . # normal dependencies\npip install -e \".[dev]\"   # developer dependencies\npip install -e \".[docs]\"  # documentation dependencies\n</code></pre>"},{"location":"installation/#4-read-the-contributing-guide-if-you-aim-to-contribute","title":"4. Read the Contributing Guide if you aim to contribute","text":""},{"location":"api/handlers/","title":"Data Handlers for IO","text":""},{"location":"api/handlers/#spectralmatch.handlers.mask_rasters","title":"<code>mask_rasters(input_image_paths, output_image_paths, vector_mask_path, split_mask_by_attribute=None, resampling_method='nearest', tap=False, resolution='highest', window_size=None, debug_logs=False, include_touched_pixels=False)</code>","text":"<p>Masks rasters using vector geometries. If <code>split_mask_by_attribute</code> is set, geometries are filtered by the raster's basename (excluding extension) to allow per-image masking with specific matching features.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_paths</code> <code>List[str]</code> <p>Paths to input rasters.</p> required <code>output_image_paths</code> <code>List[str]</code> <p>Corresponding output raster paths.</p> required <code>vector_mask_path</code> <code>str</code> <p>Path to vector mask file (.shp, .gpkg, etc.).</p> required <code>split_mask_by_attribute</code> <code>Optional[str]</code> <p>Attribute to match raster basenames.</p> <code>None</code> <code>resampling_method</code> <code>Literal['nearest', 'bilinear', 'cubic']</code> <p>Resampling algorithm.</p> <code>'nearest'</code> <code>tap</code> <code>bool</code> <p>Snap output bounds to target-aligned pixels.</p> <code>False</code> <code>resolution</code> <code>Literal['highest', 'average', 'lowest']</code> <p>Strategy to determine target resolution.</p> <code>'highest'</code> <code>window_size</code> <code>Optional[int | Tuple[int, int]]</code> <p>Optional tile size for processing.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Print debug information if True.</p> <code>False</code> <code>include_touched_pixels</code> <code>bool</code> <p>If True, include touched pixels in output raster.</p> <code>False</code> Outputs <p>Saved masked raster files to output_image_paths.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def mask_rasters(\n    input_image_paths: List[str],\n    output_image_paths: List[str],\n    vector_mask_path: str,\n    split_mask_by_attribute: Optional[str] = None,\n    resampling_method: Literal[\"nearest\", \"bilinear\", \"cubic\"] = \"nearest\",\n    tap: bool = False,\n    resolution: Literal[\"highest\", \"average\", \"lowest\"] = \"highest\",\n    window_size: Optional[int | Tuple[int, int]] = None,\n    debug_logs: bool = False,\n    include_touched_pixels: bool = False,\n    ) -&gt; None:\n    \"\"\"\n    Masks rasters using vector geometries. If `split_mask_by_attribute` is set,\n    geometries are filtered by the raster's basename (excluding extension) to allow\n    per-image masking with specific matching features.\n\n    Args:\n        input_image_paths (List[str]): Paths to input rasters.\n        output_image_paths (List[str]): Corresponding output raster paths.\n        vector_mask_path (str): Path to vector mask file (.shp, .gpkg, etc.).\n        split_mask_by_attribute (Optional[str]): Attribute to match raster basenames.\n        resampling_method (Literal[\"nearest\", \"bilinear\", \"cubic\"]): Resampling algorithm.\n        tap (bool): Snap output bounds to target-aligned pixels.\n        resolution (Literal[\"highest\", \"average\", \"lowest\"]): Strategy to determine target resolution.\n        window_size (Optional[int | Tuple[int, int]]): Optional tile size for processing.\n        debug_logs (bool): Print debug information if True.\n        include_touched_pixels (bool): If True, include touched pixels in output raster.\n\n    Outputs:\n        Saved masked raster files to output_image_paths.\n    \"\"\"\n    if debug_logs: print(f'Masking {len(input_image_paths)} rasters')\n\n    gdf = gpd.read_file(vector_mask_path)\n\n    if isinstance(window_size, int): window_size = (window_size, window_size)\n\n    # Compute target resolution and bounds\n    resolutions = []\n    bounds_list = []\n    crs_set = set()\n\n    for path in input_image_paths:\n        with rasterio.open(path) as src:\n            res_x, res_y = src.res\n            resolutions.append((res_x, res_y))\n            bounds_list.append(src.bounds)\n            crs_set.add(src.crs)\n\n    if len(crs_set) &gt; 1:\n        raise ValueError(\"Input rasters must have the same CRS.\")\n\n    resolutions_array = np.array(resolutions)\n    if resolution == \"highest\":\n        target_res = resolutions_array.min(axis=0)\n    elif resolution == \"lowest\":\n        target_res = resolutions_array.max(axis=0)\n    else:\n        target_res = resolutions_array.mean(axis=0)\n    if debug_logs: print(f'Resolution: {target_res}')\n\n    temp_dir = tempfile.mkdtemp()\n    tapped_paths = []\n\n    # Loop 1: Tapping (if enabled)\n    for in_path in input_image_paths:\n        raster_name = os.path.splitext(os.path.basename(in_path))[0]\n        with rasterio.open(in_path) as src:\n            profile = src.profile.copy()\n\n            if tap:\n                res_x, res_y = target_res\n                minx = np.floor(src.bounds.left / res_x) * res_x\n                miny = np.floor(src.bounds.bottom / res_y) * res_y\n                maxx = np.ceil(src.bounds.right / res_x) * res_x\n                maxy = np.ceil(src.bounds.top / res_y) * res_y\n\n                dst_width = int((maxx - minx) / res_x)\n                dst_height = int((maxy - miny) / res_y)\n                dst_transform = rasterio.transform.from_origin(minx, maxy, res_x, res_y)\n\n                profile.update({\n                    \"height\": dst_height,\n                    \"width\": dst_width,\n                    \"transform\": dst_transform\n                })\n\n                temp_path = os.path.join(temp_dir, f\"{raster_name}_tapped.tif\")\n                tapped_paths.append(temp_path)\n\n                src_windows = list(_create_windows(src.width, src.height, *window_size)) if window_size else [Window(0, 0, src.width, src.height)]\n                dst_windows = list(_create_windows(dst_width, dst_height, *window_size)) if window_size else [Window(0, 0, dst_width, dst_height)]\n\n                with rasterio.open(temp_path, \"w\", **profile) as dst:\n                    for src_win, dst_win in zip(src_windows, dst_windows):\n                        reproject(\n                            source=rasterio.band(src, list(range(1, src.count + 1))),\n                            destination=rasterio.band(dst, list(range(1, src.count + 1))),\n                            src_transform=src.window_transform(src_win),\n                            src_crs=src.crs,\n                            dst_transform=dst_transform,\n                            dst_crs=src.crs,\n                            src_nodata=src.nodata,\n                            dst_nodata=src.nodata,\n                            resampling=Resampling[resampling_method],\n                            src_window=src_win,\n                            dst_window=dst_win\n                        )\n            else:\n                tapped_paths.append(in_path)\n\n    # Loop 2: Apply mask\n    for in_path, out_path in zip(tapped_paths, output_image_paths):\n        raster_name = os.path.splitext(os.path.basename(in_path))[0].replace('_tapped', '')\n        if debug_logs: print(f'Masking: {raster_name}')\n        with rasterio.open(in_path) as src:\n            if split_mask_by_attribute:\n                filtered_gdf = gdf[gdf[split_mask_by_attribute].str.strip() == raster_name.strip()]\n                if filtered_gdf.empty:\n                    if debug_logs: print(f\"No matching features\")\n                    continue\n                geometries = filtered_gdf.geometry.values\n            else:\n                geometries = gdf.geometry.values\n\n            profile = src.profile.copy()\n\n            if window_size: windows = list(_create_windows(src.width, src.height, *window_size))\n            else: windows = [Window(0, 0, src.width, src.height)]\n\n            os.makedirs(os.path.dirname(out_path), exist_ok=True)\n            with rasterio.open(out_path, \"w\", **profile) as dst:\n                for window in windows:\n                    data = src.read(window=window)\n                    transform = src.window_transform(window)\n\n                    mask_array = geometry_mask(\n                        geometries,\n                        out_shape=(data.shape[1], data.shape[2]),\n                        transform=transform,\n                        invert=True,\n                        all_touched=include_touched_pixels\n                    )\n\n                    masked = np.where(mask_array, data, src.nodata)\n                    dst.write(masked, window=window)\n\n    # Cleanup\n    if tap:\n        shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"api/handlers/#spectralmatch.handlers.merge_rasters","title":"<code>merge_rasters(input_image_paths, output_image_path, window_size=None, debug_logs=False, output_dtype=None)</code>","text":"<p>Merges multiple input rasters into a single mosaic file by aligning each image geospatially and writing them in the correct location using tiling.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_paths</code> <code>List[str]</code> <p>Paths to input raster images.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the merged output raster.</p> required <code>window_size</code> <code>int | Tuple[int, int] | None</code> <p>Tile size for memory-efficient processing.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <code>output_dtype</code> <code>str | None</code> <p>Output dtype for output raster. None will default to input raster type.</p> <code>None</code> Output <p>A geospatially aligned, merged raster is saved to <code>output_image_path</code>.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def merge_rasters(\n    input_image_paths: List[str],\n    output_image_path: str,\n    window_size: Optional[int | Tuple[int, int]] = None,\n    debug_logs: bool = False,\n    output_dtype: str | None = None,\n    ) -&gt; None:\n    \"\"\"\n    Merges multiple input rasters into a single mosaic file by aligning each image geospatially and writing them in the correct location using tiling.\n\n    Args:\n        input_image_paths (List[str]): Paths to input raster images.\n        output_image_path (str): Path to save the merged output raster.\n        window_size (int | Tuple[int, int] | None, optional): Tile size for memory-efficient processing.\n        debug_logs (bool, optional): Enable debug logging.\n        output_dtype (str | None, optional): Output dtype for output raster. None will default to input raster type.\n\n    Output:\n        A geospatially aligned, merged raster is saved to `output_image_path`.\n    \"\"\"\n    if debug_logs: print('Start merging')\n    if not os.path.exists(os.path.dirname(output_image_path)):\n        os.makedirs(os.path.dirname(output_image_path))\n\n    if isinstance(window_size, int):\n        window_size = (window_size, window_size)\n\n    # Read metadata and calculate combined bounds and resolution\n    all_bounds = []\n    all_res = []\n    crs = None\n    dtype = None\n    count = None\n\n    for path in input_image_paths:\n        with rasterio.open(path) as src:\n            nodata_value = src.nodata\n\n    for path in input_image_paths:\n        with rasterio.open(path) as src:\n            all_bounds.append(src.bounds)\n            all_res.append(src.res)\n            if crs is None:\n                crs = src.crs\n                dtype = output_dtype or src.dtypes[0]\n                count = src.count\n\n    minx = min(b.left for b in all_bounds)\n    miny = min(b.bottom for b in all_bounds)\n    maxx = max(b.right for b in all_bounds)\n    maxy = max(b.top for b in all_bounds)\n\n    res_x, res_y = all_res[0]  # Assume same resolution across rasters\n    width = int(np.ceil((maxx - minx) / res_x))\n    height = int(np.ceil((maxy - miny) / res_y))\n    transform = from_origin(minx, maxy, res_x, res_y)\n\n    if window_size:\n        windows = list(_create_windows(width, height, *window_size))\n    else:\n        windows = [Window(0, 0, width, height)]\n\n    profile = {\n        \"driver\": \"GTiff\",\n        \"height\": height,\n        \"width\": width,\n        \"count\": count,\n        \"dtype\": dtype,\n        \"crs\": crs,\n        \"transform\": transform,\n        \"nodata\": nodata_value or None\n    }\n    # if debug_logs: print(f\"xStart:yStart xSizeXySize ({len(windows)} windows): \", end=\"\")\n    with rasterio.open(output_image_path, 'w', **profile) as dst:\n        for window in windows:\n            win_transform = rasterio.windows.transform(window, transform)\n            win_bounds = BoundingBox(*rasterio.windows.bounds(window, transform))\n            merged_data = np.zeros((count, window.height, window.width), dtype=dtype)\n\n            for path in input_image_paths:\n                with rasterio.open(path) as src:\n                    src_bounds = src.bounds\n                    if (\n                            src_bounds.right &lt;= win_bounds.left or\n                            src_bounds.left &gt;= win_bounds.right or\n                            src_bounds.top &lt;= win_bounds.bottom or\n                            src_bounds.bottom &gt;= win_bounds.top\n                    ):\n                        continue\n                    try:\n                        src_window = rasterio.windows.from_bounds(\n                            *win_bounds,\n                            transform=src.transform\n                        )\n                        src_data = src.read(\n                            window=src_window,\n                            out_shape=(count, window.height, window.width),\n                            resampling=Resampling.nearest\n                        )\n\n                        nodata_val = src.nodata\n                        if nodata_val is not None:\n                            mask = ~(np.isclose(src_data, nodata_val))\n                        else:\n                            mask = (src_data != 0)\n\n                        merged_data = np.where(mask, src_data, merged_data)\n\n                    except Exception as e:\n                        if debug_logs:\n                            print(f\"Skipping {path} in window {window} due to error: {e}\")\n\n            dst.write(merged_data, window=window)\n            # if debug_logs: print(f\"{window.col_off}:{window.row_off} {window.width}x{window.height}, \", end=\"\", flush=True)\n    if debug_logs:\n        print()\n        print(\"Done merging\")\n</code></pre>"},{"location":"api/mask/","title":"Create Mask and Pseudo-Invariant Features","text":""},{"location":"api/mask/#spectralmatch.mask.create_cloud_mask_with_omnicloudmask","title":"<code>create_cloud_mask_with_omnicloudmask(input_image_path, red_band_index, green_band_index, nir_band_index, output_mask_path, down_sample_m=None)</code>","text":"<p>Generates a cloud mask using OmniCloudMask from a multi-band image.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input image.</p> required <code>red_band_index</code> <code>int</code> <p>Index of the red band.</p> required <code>green_band_index</code> <code>int</code> <p>Index of the green band.</p> required <code>nir_band_index</code> <code>int</code> <p>Index of the NIR (or substitute blue) band.</p> required <code>output_mask_path</code> <code>str</code> <p>Path to save the output cloud mask GeoTIFF.</p> required <code>down_sample_m</code> <code>float</code> <p>Target resolution (in meters) to downsample the input before processing.</p> <code>None</code> Outputs <p>Saves a single-band cloud mask GeoTIFF at the specified path.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def create_cloud_mask_with_omnicloudmask(\n    input_image_path,\n    red_band_index,\n    green_band_index,\n    nir_band_index, # Blue band can work if nir isnt available\n    output_mask_path,\n    down_sample_m=None, # Down sample to 10 m if imagery has a spatial resolution &lt; 10 m\n    ):\n    \"\"\"\n    Generates a cloud mask using OmniCloudMask from a multi-band image.\n\n    Args:\n        input_image_path (str): Path to the input image.\n        red_band_index (int): Index of the red band.\n        green_band_index (int): Index of the green band.\n        nir_band_index (int): Index of the NIR (or substitute blue) band.\n        output_mask_path (str): Path to save the output cloud mask GeoTIFF.\n        down_sample_m (float, optional): Target resolution (in meters) to downsample the input before processing.\n\n    Outputs:\n        Saves a single-band cloud mask GeoTIFF at the specified path.\n    \"\"\"\n\n    with rasterio.open(input_image_path) as src:\n        if down_sample_m is not None:\n            # Compute new dimensions based on the image bounds and the desired resolution.\n            left, bottom, right, top = src.bounds\n            new_width = int((right - left) / down_sample_m)\n            new_height = int((top - bottom) / down_sample_m)\n            new_transform = from_origin(left, top, down_sample_m, down_sample_m)\n            # Read the bands with resampling to the new size.\n            red   = src.read(red_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            green = src.read(green_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            nir   = src.read(nir_band_index, out_shape=(new_height, new_width),\n                             resampling=Resampling.bilinear)\n            meta = src.meta.copy()\n            meta.update({\n                'width': new_width,\n                'height': new_height,\n                'transform': new_transform,\n            })\n        else:\n            # Read without resampling.\n            red   = src.read(red_band_index)\n            green = src.read(green_band_index)\n            nir   = src.read(nir_band_index)\n            meta = src.meta.copy()\n\n        # Stack bands into an array of shape (3, height, width).\n        band_array = np.stack([red, green, nir], axis=0)\n\n    # Predict the mask (expected shape: (1, height, width))\n    pred_mask = predict_from_array(band_array)\n    pred_mask = np.squeeze(pred_mask)\n\n    # Update metadata for a single-band output.\n    meta.update({\n        'driver': 'GTiff',\n        'count': 1,\n        'dtype': pred_mask.dtype,\n        'nodata': 0,\n    })\n\n    # Write the predicted mask to a GeoTIFF file.\n    with rasterio.open(output_mask_path, 'w', **meta) as dst:\n        dst.write(pred_mask, 1)\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.create_ndvi_mask","title":"<code>create_ndvi_mask(input_image_path, output_image_path, nir_band, red_band)</code>","text":"<p>Computes NDVI from a multi-band image and saves the result as a GeoTIFF.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input image with NIR and red bands.</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the NDVI output GeoTIFF.</p> required <code>nir_band</code> <code>int</code> <p>Band index for NIR (1-based).</p> required <code>red_band</code> <code>int</code> <p>Band index for red (1-based).</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the saved NDVI output.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def create_ndvi_mask(\n    input_image_path: str,\n    output_image_path: str,\n    nir_band: int,\n    red_band: int,\n    ) -&gt; str:\n    \"\"\"\n    Computes NDVI from a multi-band image and saves the result as a GeoTIFF.\n\n    Args:\n        input_image_path (str): Path to the input image with NIR and red bands.\n        output_image_path (str): Path to save the NDVI output GeoTIFF.\n        nir_band (int): Band index for NIR (1-based).\n        red_band (int): Band index for red (1-based).\n\n    Returns:\n        str: Path to the saved NDVI output.\n    \"\"\"\n    if not os.path.exists(os.path.dirname(output_image_path)): os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n\n    with rasterio.open(input_image_path) as src:\n        nir = src.read(nir_band).astype(np.float32)\n        red = src.read(red_band).astype(np.float32)\n        ndvi = (nir - red) / (nir + red + 1e-9)\n\n        print(\"NIR min/max:\", np.nanmin(nir), np.nanmax(nir))\n        print(\"Red min/max:\", np.nanmin(red), np.nanmax(red))\n        print(\"NDVI min/max:\", np.nanmin(ndvi), np.nanmax(ndvi))\n\n        profile = src.profile\n        profile.update(dtype=rasterio.float32, count=1)\n\n        with rasterio.open(output_image_path, 'w', **profile) as dst:\n            dst.write(ndvi, 1)\n\n    return output_image_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.mask_image_with_vector","title":"<code>mask_image_with_vector(input_image_path, input_vector_path, output_image_path, exclude_features={}, invert_mask=False)</code>","text":"<p>Masks a raster using vector geometries within the raster's bounds.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to input raster.</p> required <code>input_vector_path</code> <code>str</code> <p>Path to vector file (e.g., .shp, .gpkg).</p> required <code>output_image_path</code> <code>str</code> <p>Path to save masked raster.</p> required <code>exclude_features</code> <code>dict[any, any]</code> <p>Dict of attribute filters to exclude (e.g., {\"class\": \"water\"}).</p> <code>{}</code> <code>invert_mask</code> <code>bool</code> <p>If True, keeps only areas inside vector geometries.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the masked raster file.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def mask_image_with_vector(\n    input_image_path: str,\n    input_vector_path: str,\n    output_image_path: str,\n    exclude_features: dict[any, any] = {},\n    invert_mask: bool = False\n    ) -&gt; str:\n    \"\"\"\n    Masks a raster using vector geometries within the raster's bounds.\n\n    Args:\n        input_image_path: Path to input raster.\n        input_vector_path: Path to vector file (e.g., .shp, .gpkg).\n        output_image_path: Path to save masked raster.\n        exclude_features: Dict of attribute filters to exclude (e.g., {\"class\": \"water\"}).\n        invert_mask: If True, keeps only areas inside vector geometries.\n\n    Returns:\n        Path to the masked raster file.\n    \"\"\"\n    if not os.path.exists(os.path.dirname(output_image_path)): os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n\n    with rasterio.open(input_image_path) as src:\n        image_crs = src.crs\n\n        with fiona.open(input_vector_path, 'r') as vector:\n            filtered_geoms = []\n            for feature in vector:\n                if exclude_features:\n                    match = all(feature['properties'].get(k) != v for k, v in exclude_features.items())\n                else:\n                    match = True\n\n                if match:\n                    geom = shape(feature['geometry'])\n                    filtered_geoms.append(geom)\n\n        if not filtered_geoms:\n            return output_image_path\n\n        geom_union = unary_union(filtered_geoms)\n        geometries = [geom_union.__geo_interface__]\n\n        mask, transform, window = raster_geometry_mask(\n            src,\n            geometries,\n            invert=invert_mask,\n            crop=False,\n            pad=False,\n            all_touched=False\n        )\n\n        data = src.read()\n        data[:, mask] = src.nodata if src.nodata is not None else 0\n\n        out_meta = src.meta.copy()\n        with rasterio.open(output_image_path, 'w', **out_meta) as dst:\n            dst.write(data)\n\n    return output_image_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.post_process_raster_cloud_mask_to_vector","title":"<code>post_process_raster_cloud_mask_to_vector(input_image_path, output_vector_path, minimum_mask_size_percentile=None, polygon_buffering_in_map_units=None, value_mapping=None)</code>","text":"<p>Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input cloud mask raster.</p> required <code>output_vector_path</code> <code>str</code> <p>Path to the output vector layer.</p> required <code>minimum_mask_size_percentile</code> <code>float</code> <p>Percentile threshold to filter small polygons by area.</p> <code>None</code> <code>polygon_buffering_in_map_units</code> <code>dict</code> <p>Mapping of raster values to buffer distances.</p> <code>None</code> <code>value_mapping</code> <code>dict</code> <p>Mapping of original raster values to new values before vectorization.</p> <code>None</code> Outputs <p>Saves a vector layer to the output path.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def post_process_raster_cloud_mask_to_vector(\n    input_image_path: str,\n    output_vector_path: str,\n    minimum_mask_size_percentile: float = None,\n    polygon_buffering_in_map_units: dict = None,\n    value_mapping: dict = None\n    ) -&gt; ogr.DataSource:\n    \"\"\"\n    Converts a raster cloud mask to a vector layer with optional filtering, buffering, and merging.\n\n    Args:\n        input_image_path (str): Path to the input cloud mask raster.\n        output_vector_path (str): Path to the output vector layer.\n        minimum_mask_size_percentile (float, optional): Percentile threshold to filter small polygons by area.\n        polygon_buffering_in_map_units (dict, optional): Mapping of raster values to buffer distances.\n        value_mapping (dict, optional): Mapping of original raster values to new values before vectorization.\n\n    Outputs:\n        Saves a vector layer to the output path.\n    \"\"\"\n\n    with rasterio.open(input_image_path) as src:\n        raster_data = src.read(1)\n        transform = src.transform\n        crs = src.crs\n\n    if value_mapping is not None:\n        mapped = np.copy(raster_data)\n        for orig_value, new_value in value_mapping.items():\n            mapped[raster_data == orig_value] = new_value\n        raster_data = mapped\n\n    results = (\n        {'properties': {'value': v}, 'geometry': s}\n        for s, v in shapes(raster_data, transform=transform, connectivity=4)\n    )\n    features = list(results)\n    if not features:\n        print(\"No features were detected in the raster mask.\")\n        return None\n\n\n    gdf = gpd.GeoDataFrame.from_features(features, crs=crs)\n\n    gdf['area'] = gdf.geometry.area\n    if minimum_mask_size_percentile is not None:\n        area_threshold = np.percentile(gdf['area'], minimum_mask_size_percentile)\n        print(f\"Area threshold (at {minimum_mask_size_percentile}th percentile): {area_threshold:.2f}\")\n        gdf = gdf[gdf['area'] &gt;= area_threshold].copy()\n\n    if polygon_buffering_in_map_units is not None:\n        gdf['geometry'] = gdf.apply(\n            lambda row: row['geometry'].buffer(polygon_buffering_in_map_units.get(row['value'], 0))\n            if row['value'] in polygon_buffering_in_map_units else row['geometry'],\n            axis=1\n        )\n\n    merged_features = []\n    for val, group in gdf.groupby('value'):\n        # Use union_all() to merge the geometries within the group.\n        # (Requires Shapely 2.0 or later; otherwise use shapely.ops.unary_union on group.geometry.tolist())\n        union_geom = group.geometry.union_all()\n        # If the union produces a single Polygon, add it directly;\n        # if it produces a MultiPolygon, split it into individual features.\n        if union_geom.geom_type == 'Polygon':\n            merged_features.append({'value': val, 'geometry': union_geom})\n        elif union_geom.geom_type == 'MultiPolygon':\n            for geom in union_geom.geoms:\n                merged_features.append({'value': val, 'geometry': geom})\n        else:\n            # In case of unexpected geometry types, skip or handle accordingly.\n            print(f\"Unexpected geometry type for value {val}: {union_geom.geom_type}\")\n    # Create a new GeoDataFrame from merged features.\n    gdf = gpd.GeoDataFrame(merged_features, crs=gdf.crs)\n\n\n    ogr_driver = ogr.GetDriverByName(\"Memory\")\n    mem_ds = ogr_driver.CreateDataSource(\"in_memory\")\n\n    # Determine an appropriate OGR geometry type using the first feature.\n    first_geom = gdf.geometry.iloc[0]\n    if first_geom.geom_type == \"Polygon\":\n        ogr_geom_type = ogr.wkbPolygon\n    elif first_geom.geom_type == \"MultiPolygon\":\n        ogr_geom_type = ogr.wkbMultiPolygon\n    else:\n        ogr_geom_type = ogr.wkbUnknown\n\n    # Convert the CRS to OGR SpatialReference.\n    sr = osr.SpatialReference()\n    try:\n        sr.ImportFromWkt(crs.to_wkt())\n    except AttributeError:\n        sr.ImportFromEPSG(4326)\n\n    mem_layer = mem_ds.CreateLayer(\"post_processed\", sr, ogr_geom_type)\n\n    # Add attribute field for 'value' (and any other non-geometry columns if needed).\n    # Here we add 'value' for example.\n    field_defn = ogr.FieldDefn(\"value\", ogr.OFTInteger)\n    mem_layer.CreateField(field_defn)\n\n    # Add each row from the GeoDataFrame as an OGR feature.\n    for idx, row in gdf.iterrows():\n        feat = ogr.Feature(mem_layer.GetLayerDefn())\n        ogr_geom = ogr.CreateGeometryFromWkt(row['geometry'].wkt)\n        feat.SetGeometry(ogr_geom)\n        feat.SetField(\"value\", row['value'])\n        mem_layer.CreateFeature(feat)\n        feat = None\n\n    _write_vector(mem_ds, output_vector_path)\n\n    return output_vector_path\n</code></pre>"},{"location":"api/mask/#spectralmatch.mask.post_process_threshold_to_vector","title":"<code>post_process_threshold_to_vector(input_image_path, output_vector_path, threshold_val, operator_str='&lt;=')</code>","text":"<p>Converts a thresholded raster mask to a vector layer based on a comparison operator.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_path</code> <code>str</code> <p>Path to the input single-band raster.</p> required <code>output_vector_path</code> <code>str</code> <p>Path to save the output vector file (GeoPackage).</p> required <code>threshold_val</code> <code>float | int</code> <p>Threshold value to apply.</p> required <code>operator_str</code> <code>str</code> <p>Comparison operator ('&lt;=', '&gt;=', '&lt;', '&gt;', '=='). Defaults to '&lt;='.</p> <code>'&lt;='</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the saved vector file.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unsupported comparison operator is provided.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def post_process_threshold_to_vector(\n    input_image_path: str,\n    output_vector_path: str,\n    threshold_val: float | int,\n    operator_str: str=\"&lt;=\",\n    ) -&gt; str:\n    \"\"\"\n    Converts a thresholded raster mask to a vector layer based on a comparison operator.\n\n    Args:\n        input_image_path (str): Path to the input single-band raster.\n        output_vector_path (str): Path to save the output vector file (GeoPackage).\n        threshold_val (float | int): Threshold value to apply.\n        operator_str (str, optional): Comparison operator ('&lt;=', '&gt;=', '&lt;', '&gt;', '=='). Defaults to '&lt;='.\n\n    Returns:\n        str: Path to the saved vector file.\n\n    Raises:\n        ValueError: If an unsupported comparison operator is provided.\n    \"\"\"\n\n    ds = gdal.Open(input_image_path)\n    band = ds.GetRasterBand(1)\n    arr = band.ReadAsArray()\n\n    if operator_str == \"&lt;=\":\n        mask = arr &lt;= threshold_val\n    elif operator_str == \"&gt;=\":\n        mask = arr &gt;= threshold_val\n    elif operator_str == \"&lt;\":\n        mask = arr &lt; threshold_val\n    elif operator_str == \"&gt;\":\n        mask = arr &gt; threshold_val\n    elif operator_str == \"==\":\n        mask = arr == threshold_val\n    else:\n        raise ValueError(\"Unsupported operator\")\n\n    mask = mask.astype(np.uint8)\n\n    mem_ds = gdal.GetDriverByName(\"MEM\").Create(\"\", ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Byte)\n    mem_ds.SetGeoTransform(ds.GetGeoTransform())\n    mem_ds.SetProjection(ds.GetProjection())\n    mem_ds.GetRasterBand(1).WriteArray(mask)\n\n    drv = ogr.GetDriverByName(\"GPKG\")\n    if os.path.exists(output_vector_path):\n        drv.DeleteDataSource(output_vector_path)\n    out_ds = drv.CreateDataSource(output_vector_path)\n    out_lyr = out_ds.CreateLayer(\"mask\", srs=None)\n    out_lyr.CreateField(ogr.FieldDefn(\"DN\", ogr.OFTInteger))\n\n    gdal.Polygonize(mem_ds.GetRasterBand(1), mem_ds.GetRasterBand(1), out_lyr, 0, [])\n    ds, mem_ds, out_ds = None, None, None\n    return output_vector_path\n</code></pre>"},{"location":"api/match/","title":"Matching Algorithms","text":""},{"location":"api/match/#spectralmatch.match.global_regression.global_regression","title":"<code>global_regression(input_images, output_images, *, custom_mean_factor=1.0, custom_std_factor=1.0, vector_mask_path=None, window_size=None, debug_logs=False, custom_nodata_value=None, parallel_workers=None, calculation_dtype_precision='float32', specify_model_images=None, save_adjustments=None, load_adjustments=None)</code>","text":"<p>Performs global radiometric normalization across overlapping images using least squares regression.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>str | List[str]</code> <p>A folder path containing <code>.tif</code> files to search for or a list of input image paths.</p> required <code>output_images</code> <code>Tuple[str, str] | List[str]</code> <p>Either a tuple of (output_folder, suffix) to generate output paths from, or a list of output image paths. If a list is provided, its length must match the number of input images.</p> required <code>custom_mean_factor</code> <code>float</code> <p>Weight for mean constraints in regression. Defaults to 1.0.</p> <code>1.0</code> <code>custom_std_factor</code> <code>float</code> <p>Weight for standard deviation constraints in regression. Defaults to 1.0.</p> <code>1.0</code> <code>vector_mask_path</code> <code>Optional[str]</code> <p>Optional mask to limit stats to specific areas. Defaults to None.</p> <code>None</code> <code>window_size</code> <code>int | Tuple[int, int] | None</code> <p>Tile size for processing: int for square tiles, (width, height) for custom size, or None for full image. Defaults to None.</p> <code>None</code> <code>debug_logs</code> <code>bool</code> <p>If True, prints debug information and constraint matrices. Defaults to False.</p> <code>False</code> <code>custom_nodata_value</code> <code>float | None</code> <p>Overrides detected NoData value. Defaults to None.</p> <code>None</code> <code>parallel_workers</code> <code>Literal['cpu'] | int | None</code> <p>If set, enables multiprocessing. \"cpu\" = all cores, int = specific count, None = no parallel processing. Defaults to None.</p> <code>None</code> <code>calculation_dtype_precision</code> <code>str</code> <p>Data type used for internal calculations. Defaults to \"float32\".</p> <code>'float32'</code> <code>specify_model_images</code> <code>Tuple[Literal['exclude', 'include'], List[str]] | None</code> <p>First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.</p> <code>None</code> <code>save_adjustments</code> <code>str | None</code> <p>The output path of a .json file to save adjustments parameters. Defaults to not saving.</p> <code>None</code> <code>load_adjustments</code> <code>str | None</code> <p>If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List[str]: Paths to the globally adjusted output raster images.</p> Source code in <code>spectralmatch/match/global_regression.py</code> <pre><code>def global_regression(\n    input_images: str | List[str],\n    output_images: Tuple[str, str] | List[str],\n    *,\n    custom_mean_factor: float = 1.0,\n    custom_std_factor: float = 1.0,\n    vector_mask_path: Optional[str] = None,\n    window_size: int | Tuple[int, int] | None = None,\n    debug_logs: bool = False,\n    custom_nodata_value: float | None = None,\n    parallel_workers: Literal[\"cpu\"] | int | None = None,\n    calculation_dtype_precision: str = \"float32\",\n    specify_model_images: Tuple[Literal[\"exclude\", \"include\"], List[str]] | None = None,\n    save_adjustments: str | None = None,\n    load_adjustments: str | None = None,\n    ) -&gt; list:\n    \"\"\"\n    Performs global radiometric normalization across overlapping images using least squares regression.\n\n    Args:\n        input_images (str | List[str]): A folder path containing `.tif` files to search for or a list of input image paths.\n        output_images (Tuple[str, str] | List[str]): Either a tuple of (output_folder, suffix) to generate output paths from, or a list of output image paths. If a list is provided, its length must match the number of input images.\n        custom_mean_factor (float, optional): Weight for mean constraints in regression. Defaults to 1.0.\n        custom_std_factor (float, optional): Weight for standard deviation constraints in regression. Defaults to 1.0.\n        vector_mask_path (Optional[str], optional): Optional mask to limit stats to specific areas. Defaults to None.\n        window_size (int | Tuple[int, int] | None): Tile size for processing: int for square tiles, (width, height) for custom size, or None for full image. Defaults to None.\n        debug_logs (bool, optional): If True, prints debug information and constraint matrices. Defaults to False.\n        custom_nodata_value (float | None, optional): Overrides detected NoData value. Defaults to None.\n        parallel_workers (Literal[\"cpu\"] | int | None): If set, enables multiprocessing. \"cpu\" = all cores, int = specific count, None = no parallel processing. Defaults to None.\n        calculation_dtype_precision (str, optional): Data type used for internal calculations. Defaults to \"float32\".\n        specify_model_images (Tuple[Literal[\"exclude\", \"include\"], List[str]] | None ): First item in tuples sets weather to 'include' or 'exclude' the listed images from model building statistics. Second item is the list of image names (without their extension) to apply criteria to. For example, if this param is only set to 'include' one image, all other images will be matched to that one image. Defaults to no exclusion.\n        save_adjustments (str | None, optional): The output path of a .json file to save adjustments parameters. Defaults to not saving.\n        load_adjustments (str | None, optional): If set, loads saved whole and overlapping statistics only for images that exist in the .json file. Other images will still have their statistics calculated. Defaults to None.\n\n    Returns:\n        List[str]: Paths to the globally adjusted output raster images.\n    \"\"\"\n\n    print(\"Start global regression\")\n\n    input_image_paths, output_image_paths = _resolve_input_output_paths(input_images, output_images)\n    input_image_names = list(input_image_paths.keys())\n    num_input_images = len(input_image_paths)\n\n\n    _check_raster_requirements(list(input_image_paths.values()), debug_logs)\n\n    if isinstance(window_size, int): window_size = (window_size, window_size)\n    nodata_val = _get_nodata_value(list(input_image_paths.values()), custom_nodata_value)\n\n    # Find loaded and input files if load adjustments\n    loaded_model = {}\n    if load_adjustments:\n        with open(load_adjustments, \"r\") as f:\n            loaded_model = json.load(f)\n        _validate_adjustment_model_structure(loaded_model)\n        loaded_names = set(loaded_model.keys())\n        input_names = set(input_image_names)\n    else:\n        loaded_names = set([])\n        input_names = set(input_image_names)\n\n    matched = input_names &amp; loaded_names\n    only_loaded = loaded_names - input_names\n    only_input = input_names - loaded_names\n    if debug_logs:\n        print(f\"Total images: input images: {len(input_names)}, loaded images {len(loaded_names)}: \")\n        print(f\"    Matched adjustments (to override) ({len(matched)}):\", sorted(matched))\n        print(f\"    Only in loaded adjustments (to add) ({len(only_loaded)}):\", sorted(only_loaded))\n        print(f\"    Only in input (to calculate) ({len(only_input)}):\", sorted(only_input))\n\n    # Find images to include in model\n    included_names = list(matched | only_loaded | only_input)\n    if specify_model_images:\n        mode, names = specify_model_images\n        name_set = set(names)\n        if mode == \"include\":\n            included_names = [n for n in input_image_names if n in name_set]\n        elif mode == \"exclude\":\n            included_names = [n for n in input_image_names if n not in name_set]\n        excluded_names = [n for n in input_image_names if n not in included_names]\n    if debug_logs:\n        print(\"Images to influence the model:\")\n        print(f\"    Included in model ({len(included_names)}): {sorted(included_names)}\")\n        if specify_model_images: print(f\"    Excluded from model ({len(excluded_names)}): {sorted(excluded_names)}\")\n        else: print(f\"    Excluded from model (0): []\")\n\n    # Calculate stats\n    if debug_logs: print(\"Calculating statistics\")\n    with rasterio.open(list(input_image_paths.values())[0]) as src: num_bands = src.count\n\n    # Get images bounds\n    all_bounds = {}\n    for name, path in input_image_paths.items():\n        with rasterio.open(path) as ds:\n            all_bounds[name] = ds.bounds\n\n    # Calculate overlap stats\n    overlapping_pairs = _find_overlaps(all_bounds)\n\n    all_overlap_stats = {}\n    for name_i, name_j in overlapping_pairs:\n\n        if name_i in loaded_model and name_j in loaded_model[name_i].get(\"overlap_stats\", {}):\n            continue\n\n        stats = _calculate_overlap_stats(\n            num_bands,\n            input_image_paths[name_i],\n            input_image_paths[name_j],\n            name_i,\n            name_j,\n            all_bounds[name_i],\n            all_bounds[name_j],\n            nodata_val,\n            nodata_val,\n            vector_mask_path=vector_mask_path,\n            window_size=window_size,\n            debug_logs=debug_logs,\n        )\n\n        for k_i, v in stats.items():\n            all_overlap_stats[k_i] = {\n                **all_overlap_stats.get(k_i, {}),\n                **{\n                    k_j: {**all_overlap_stats.get(k_i, {}).get(k_j, {}), **s}\n                    for k_j, s in v.items()\n                },\n            }\n\n\n    # Add loaded image stats to model\n    if load_adjustments:\n        for name_i, model_entry in loaded_model.items():\n            if name_i not in input_image_paths:\n                continue\n\n            for name_j, bands in model_entry.get(\"overlap_stats\", {}).items():\n                if name_j not in input_image_paths:\n                    continue\n\n                all_overlap_stats.setdefault(name_i, {})[name_j] = {\n                    int(k.split(\"_\")[1]): {\n                        \"mean\": bands[k][\"mean\"],\n                        \"std\": bands[k][\"std\"],\n                        \"size\": bands[k][\"size\"]\n                    } for k in bands\n                }\n\n    # Calculate whole stats\n    all_whole_stats = {}\n    for name, path in input_image_paths.items():\n        if name in loaded_model:\n            all_whole_stats[name] = {\n                int(k.split(\"_\")[1]): {\n                    \"mean\": loaded_model[name][\"whole_stats\"][k][\"mean\"],\n                    \"std\": loaded_model[name][\"whole_stats\"][k][\"std\"],\n                    \"size\": loaded_model[name][\"whole_stats\"][k][\"size\"]\n                }\n                for k in loaded_model[name][\"whole_stats\"]\n            }\n        else:\n            all_whole_stats.update(\n                _calculate_whole_stats(\n                    input_image_path=path,\n                    nodata=nodata_val,\n                    num_bands=num_bands,\n                    image_name=name,\n                    vector_mask_path=vector_mask_path,\n                    window_size=window_size,\n                )\n            )\n\n    all_image_names = list(dict.fromkeys(input_image_names + list(loaded_model.keys())))\n    num_total = len(all_image_names)\n\n    # Print model sources\n    if debug_logs:\n        print(f\"\\nCreating model for {len(all_image_names)} total images from {len(included_names)} included:\")\n        print(f\"{'ID':&lt;4}\\t{'Source':&lt;6}\\t{'Inclusion':&lt;8}\\tName\")\n        for i, name in enumerate(all_image_names):\n            source = \"load\" if name in (matched | only_loaded) else \"calc\"\n            included = \"incl\" if name in included_names else \"excl\"\n            print(f\"{i:&lt;4}\\t{source:&lt;6}\\t{included:&lt;8}\\t{name}\")\n\n    # Build model\n    all_params = np.zeros((num_bands, 2 * num_total, 1), dtype=float)\n    image_names_with_id = [(i, name) for i, name in enumerate(all_image_names)]\n    for b in range(num_bands):\n        if debug_logs: print(f\"\\nProcessing band {b}:\")\n\n        A, y, tot_overlap = [], [], 0\n        for i, name_i in image_names_with_id:\n            for j, name_j in image_names_with_id[i + 1:]:\n                stat = all_overlap_stats.get(name_i, {}).get(name_j)\n                if stat is None:\n                    continue\n\n                # This condition ensures that only overlaps involving at least one included image contribute constraints, allowing external images to be calibrated against the model without influencing it.\n                if name_i not in included_names and name_j not in included_names:\n                    continue\n\n                s = stat[b][\"size\"]\n                m1, v1 = stat[b][\"mean\"], stat[b][\"std\"]\n                m2, v2 = (\n                    all_overlap_stats[name_j][name_i][b][\"mean\"],\n                    all_overlap_stats[name_j][name_i][b][\"std\"],\n                )\n\n                row_m = [0] * (2 * num_total)\n                row_s = [0] * (2 * num_total)\n                row_m[2 * i: 2 * i + 2] = [m1, 1]\n                row_m[2 * j: 2 * j + 2] = [-m2, -1]\n                row_s[2 * i], row_s[2 * j] = v1, -v2\n\n                A.extend([\n                    [v * s * custom_mean_factor for v in row_m],\n                    [v * s * custom_std_factor for v in row_s],\n                ])\n                y.extend([0, 0])\n                tot_overlap += s\n\n        pjj = 1.0 if tot_overlap == 0 else tot_overlap / (2.0 * num_total)\n\n        for name in included_names:\n            mj = all_whole_stats[name][b][\"mean\"]\n            vj = all_whole_stats[name][b][\"std\"]\n            j_idx = all_image_names.index(name)\n            row_m = [0] * (2 * num_total)\n            row_s = [0] * (2 * num_total)\n            row_m[2 * j_idx: 2 * j_idx + 2] = [mj * pjj, 1 * pjj]\n            row_s[2 * j_idx] = vj * pjj\n            A.extend([row_m, row_s])\n            y.extend([mj * pjj, vj * pjj])\n\n        for name in input_image_names:\n            if name in included_names:\n                continue\n            row = [0] * (2 * num_total)\n            A.append(row.copy())\n            y.append(0)\n            A.append(row.copy())\n            y.append(0)\n\n        A_arr = np.asarray(A)\n        y_arr = np.asarray(y)\n        res = least_squares(lambda p: A_arr @ p - y_arr, [1, 0] * num_total)\n\n        if debug_logs:\n            _print_constraint_system(\n                constraint_matrix=A_arr,\n                adjustment_params=res.x,\n                observed_values_vector=y_arr,\n                overlap_pairs=overlapping_pairs,\n                image_names_with_id=image_names_with_id,\n\n            )\n\n        all_params[b] = res.x.reshape((2 * num_total, 1))\n\n    # Save adjustments\n    if save_adjustments:\n        _save_adjustments(\n            save_path=save_adjustments,\n            input_image_names=list(input_image_paths.keys()),\n            all_params=all_params,\n            all_whole_stats=all_whole_stats,\n            all_overlap_stats=all_overlap_stats,\n            num_bands=num_bands,\n            calculation_dtype_precision=calculation_dtype_precision\n        )\n\n    if parallel_workers == \"cpu\":\n        parallel = True\n        max_workers = mp.cpu_count()\n    elif isinstance(parallel_workers, int) and parallel_workers &gt; 0:\n        parallel = True\n        max_workers = parallel_workers\n    else:\n        parallel = False\n        max_workers = None\n\n    out_paths: List[str] = []\n    for idx, (name, img_path) in enumerate(input_image_paths.items()):\n        out_path = output_image_paths[name]\n        out_paths.append(out_path)\n        if not os.path.exists(os.path.dirname(out_path)): os.makedirs(os.path.dirname(out_path), exist_ok=True)\n\n        if debug_logs: print(f\"Apply adjustments and saving results for {name}\")\n        with rasterio.open(img_path) as src:\n            meta = src.meta.copy()\n            meta.update({\"count\": num_bands, \"nodata\": nodata_val})\n            with rasterio.open(out_path, \"w\", **meta) as dst:\n\n                if window_size:\n                    tw, th = window_size\n                    windows = list(_create_windows(src.width, src.height, tw, th))\n                else:\n                    windows = [Window(0, 0, src.width, src.height)]\n\n                if parallel:\n                    ctx = _choose_context(prefer_fork=True)\n                    pool = ProcessPoolExecutor(\n                        max_workers=max_workers,\n                        mp_context=ctx,\n                        initializer=_init_worker,\n                        initargs=(img_path,),\n                    )\n\n                for b in range(num_bands):\n                    a = float(all_params[b, 2 * idx, 0])\n                    b0 = float(all_params[b, 2 * idx + 1, 0])\n\n                    if parallel:\n                        futs = [\n                            pool.submit(_process_tile_global,\n                                        w,\n                                        b,\n                                        a,\n                                        b0,\n                                        nodata_val,\n                                        calculation_dtype_precision,\n                                        debug_logs,\n                                        )\n                            for w in windows\n                        ]\n                        for fut in as_completed(futs):\n                            win, buf = fut.result()\n                            dst.write(buf.astype(meta[\"dtype\"]), b + 1, window=win)\n                    else:\n                        for win in windows:\n                            _, buf = _process_tile_global(\n                                win,\n                                b,\n                                a,\n                                b0,\n                                nodata_val,\n                                debug_logs,\n                            )\n                            dst.write(buf.astype(meta[\"dtype\"]), b + 1, window=win)\n                if parallel:\n                    pool.shutdown()\n\n    print(\"Finished global regression\")\n    return out_paths\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.get_bounding_rect_images_block_space","title":"<code>get_bounding_rect_images_block_space(block_valid_counts)</code>","text":"<p>Compute block-space bounding rectangles for each image based on valid pixel counts.</p> <p>Parameters:</p> Name Type Description Default <code>block_valid_counts</code> <code>ndarray</code> <p>Shape (num_images, num_row, num_col, num_bands)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray of shape (num_images, 4): each row is (min_row, min_col, max_row, max_col)</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def get_bounding_rect_images_block_space(\n    block_valid_counts: np.ndarray\n    ) -&gt; np.ndarray:\n    \"\"\"\n    Compute block-space bounding rectangles for each image based on valid pixel counts.\n\n    Args:\n        block_valid_counts (np.ndarray): Shape (num_images, num_row, num_col, num_bands)\n\n    Returns:\n        np.ndarray of shape (num_images, 4): each row is (min_row, min_col, max_row, max_col)\n    \"\"\"\n\n    num_images, num_row, num_col, num_bands = block_valid_counts.shape\n    output = np.zeros((num_images, 4), dtype=int)\n\n    for i in range(num_images):\n        valid_mask = np.any(block_valid_counts[i] &gt; 0, axis=2)\n        rows, cols = np.where(valid_mask)\n\n        if rows.size &gt; 0 and cols.size &gt; 0:\n            min_row, max_row = rows.min(), rows.max() + 1\n            min_col, max_col = cols.min(), cols.max() + 1\n        else:\n            min_row = max_row = min_col = max_col = 0\n\n        output[i] = (min_row, min_col, max_row, max_col)\n\n    return output\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.get_pre_computed_block_maps","title":"<code>get_pre_computed_block_maps(load_block_maps, calculation_dtype_precision)</code>","text":"<p>Load pre-computed block mean maps from files.</p> <p>Parameters:</p> Name Type Description Default <code>load_block_maps</code> <code>tuple[str, list[str]]</code> <ul> <li>First element is the reference block map file path (str), used to determine block dimensions and canvas extent.</li> <li>Second element is a list of local block map file paths (List[str]), each corresponding by index to input images.</li> </ul> required <code>calculation_dtype_precision</code> <code>str</code> <p>Used as the dtype to read input rasters and return data.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Tuple[ np.ndarray,  # block_local_means: shape (num_images, num_row, num_col, num_bands) np.ndarray,  # block_reference_mean: shape (num_row, num_col, num_bands) int,         # num_row int,         # num_col Tuple[float, float, float, float]  # bounds_canvas_coords (minx, miny, maxx, maxy)</p> <code>ndarray</code> <p>]</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def get_pre_computed_block_maps(\n    load_block_maps: Tuple[str, List[str]],\n    calculation_dtype_precision: str,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, int, int, Tuple[float, float, float, float]]:\n    \"\"\"\n    Load pre-computed block mean maps from files.\n\n    Args:\n        load_block_maps (tuple[str, list[str]]):\n            - First element is the reference block map file path (str), used to determine block dimensions and canvas extent.\n            - Second element is a list of local block map file paths (List[str]), each corresponding by index to input images.\n        calculation_dtype_precision (str): Used as the dtype to read input rasters and return data.\n\n    Returns:\n        Tuple[\n            np.ndarray,  # block_local_means: shape (num_images, num_row, num_col, num_bands)\n            np.ndarray,  # block_reference_mean: shape (num_row, num_col, num_bands)\n            int,         # num_row\n            int,         # num_col\n            Tuple[float, float, float, float]  # bounds_canvas_coords (minx, miny, maxx, maxy)\n        ]\n    \"\"\"\n    ref_path, local_paths = load_block_maps\n\n    with rasterio.open(ref_path) as src:\n        ref_data = src.read().astype(calculation_dtype_precision).transpose(1, 2, 0)\n        nodata_val = src.nodata\n        if nodata_val is not None:\n            ref_data[ref_data == nodata_val] = np.nan\n        block_reference_mean = ref_data\n        bounds_canvas_coords = src.bounds\n\n    block_local_means = []\n    for p in local_paths:\n        with rasterio.open(p) as src:\n            data = src.read().astype(calculation_dtype_precision).transpose(1, 2, 0)\n            nodata_val = src.nodata\n            if nodata_val is not None:\n                data[data == nodata_val] = np.nan\n            block_local_means.append(data)\n\n    block_local_means = np.stack(block_local_means, axis=0)\n    num_row, num_col = block_reference_mean.shape[:2]\n\n    print(f\"Loaded reference block map and {len(local_paths)} local block maps. Shape: ({num_row}, {num_col}, {block_reference_mean.shape[2]})\")\n    return block_local_means, block_reference_mean, num_row, num_col, bounds_canvas_coords\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.local_block_adjustment","title":"<code>local_block_adjustment(input_images, output_images, *, output_local_basename='_local', custom_nodata_value=None, number_of_blocks=100, alpha=1.0, calculation_dtype_precision='float32', output_dtype='float32', debug_logs=False, window_size=None, correction_method='gamma', parallel_workers=None, save_block_maps=False, load_block_maps=None)</code>","text":"<p>Performs local radiometric adjustment on a set of raster images using block-based statistics.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>str | List[str]</code> <p>A folder path containing <code>.tif</code> files to search for or a list of input image paths.</p> required <code>output_images</code> <code>Tuple[str, str] | List[str]</code> <p>Either a tuple of (output_folder, suffix) to generate output paths from, or a list of output image paths. If a list is provided, its length must match the number of input images.</p> required <code>output_local_basename</code> <code>str</code> <p>Suffix for output filenames. Defaults to \"_local\".</p> <code>'_local'</code> <code>custom_nodata_value</code> <code>float | None</code> <p>Overrides detected NoData value. Defaults to None.</p> <code>None</code> <code>number_of_blocks</code> <code>int | tuple | Literal['coefficient_of_variation']</code> <p>int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.</p> <code>100</code> <code>alpha</code> <code>float</code> <p>Blending factor between global and local means. Defaults to 1.0.</p> <code>1.0</code> <code>calculation_dtype_precision</code> <code>str</code> <p>Precision for internal calculations. Defaults to \"float32\".</p> <code>'float32'</code> <code>output_dtype</code> <code>str</code> <p>Data type for output rasters. Defaults to \"float32\".</p> <code>'float32'</code> <code>debug_logs</code> <code>bool</code> <p>If True, prints progress. Defaults to False.</p> <code>False</code> <code>window_size</code> <code>int | Tuple[int, int] | None | Literal['block']</code> <p>Tile size for processing: int for square tiles, (width, height) for custom size, None for full image, or \"block\" to set as the size of the block map. Defaults to None.</p> <code>None</code> <code>correction_method</code> <code>Literal['gamma', 'linear']</code> <p>Local correction method. Defaults to \"gamma\".</p> <code>'gamma'</code> <code>parallel_workers</code> <code>Literal['cpu'] | int | None</code> <p>If set, enables multiprocessing. \"cpu\" = all cores, int = specific count, None = no parallel processing. Defaults to None.</p> <code>None</code> <code>save_block_maps</code> <code>bool</code> <p>If True, saves intermediate results for examination or to start midway through with block maps. Defaults to False.</p> <code>False</code> <code>load_block_maps</code> <code>Optional[Tuple[str, List[str]]]</code> <p>A tuple containing:     - A reference block map path (str): This is used for the reference dataset, sets the canvas extent, and determines the number of blocks.     - A list of local block map paths (List[str]): Each path corresponds to an image in input_image_paths by position and will be used for the local dataset. The list must have the same length as input_image_paths.</p> <p>This is used to:     - Load the reference block mean map.     - Load each image's local block mean map.     - Enable saving intermediate results after block computation and after each image is processed (you can remove a local image from processing and still get the same results as long as it was used for initial calculation).</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List[str]: Paths to the locally adjusted output raster images.</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def local_block_adjustment(\n    input_images: str | List[str],\n    output_images: Tuple[str, str] | List[str],\n    *,\n    output_local_basename: str = \"_local\",\n    custom_nodata_value: float | None = None,\n    number_of_blocks: Union[int, Tuple[int, int], Literal[\"coefficient_of_variation\"]] = 100,\n    alpha: float = 1.0,\n    calculation_dtype_precision: str = \"float32\",\n    output_dtype: str = \"float32\",\n    debug_logs: bool = False,\n    window_size: int | Tuple[int, int] | None | Literal[\"block\"] = None,\n    correction_method: Literal[\"gamma\", \"linear\"] = \"gamma\",\n    parallel_workers: Literal[\"cpu\"] | int | None = None,\n    save_block_maps: bool = False,\n    load_block_maps: Optional[Tuple[str, List[str]]] = None\n    )-&gt; list:\n    \"\"\"\n    Performs local radiometric adjustment on a set of raster images using block-based statistics.\n\n    Args:\n        input_images (str | List[str]): A folder path containing `.tif` files to search for or a list of input image paths.\n        output_images (Tuple[str, str] | List[str]): Either a tuple of (output_folder, suffix) to generate output paths from, or a list of output image paths. If a list is provided, its length must match the number of input images.\n        output_local_basename (str, optional): Suffix for output filenames. Defaults to \"_local\".\n        custom_nodata_value (float | None, optional): Overrides detected NoData value. Defaults to None.\n        number_of_blocks (int | tuple | Literal[\"coefficient_of_variation\"]): int as a target of blocks per image, tuple to set manually set total blocks width and height, coefficient_of_variation to find the number of blocks based on this metric.\n        alpha (float, optional): Blending factor between global and local means. Defaults to 1.0.\n        calculation_dtype_precision (str, optional): Precision for internal calculations. Defaults to \"float32\".\n        output_dtype (str, optional): Data type for output rasters. Defaults to \"float32\".\n        debug_logs (bool, optional): If True, prints progress. Defaults to False.\n        window_size (int | Tuple[int, int] | None | Literal[\"block\"]): Tile size for processing: int for square tiles, (width, height) for custom size, None for full image, or \"block\" to set as the size of the block map. Defaults to None.\n        correction_method (Literal[\"gamma\", \"linear\"], optional): Local correction method. Defaults to \"gamma\".\n        parallel_workers (Literal[\"cpu\"] | int | None): If set, enables multiprocessing. \"cpu\" = all cores, int = specific count, None = no parallel processing. Defaults to None.\n        save_block_maps (bool, optional): If True, saves intermediate results for examination or to start midway through with block maps. Defaults to False.\n        load_block_maps (Optional[Tuple[str, List[str]]]):\n            A tuple containing:\n                - A reference block map path (str): This is used for the reference dataset, sets the canvas extent, and determines the number of blocks.\n                - A list of local block map paths (List[str]): Each path corresponds to an image in input_image_paths by position and will be used for the local dataset. The list must have the same length as input_image_paths.\n\n            This is used to:\n                - Load the reference block mean map.\n                - Load each image's local block mean map.\n                - Enable saving intermediate results after block computation and after each image is processed (you can remove a local image from processing and still get the same results as long as it was used for initial calculation).\n\n    Returns:\n        List[str]: Paths to the locally adjusted output raster images.\n    \"\"\"\n\n    print(\"Start local block adjustment\")\n\n    input_image_paths, output_image_paths = _resolve_input_output_paths(input_images, output_images)\n    input_image_names = list(input_image_paths.keys())\n\n    _check_raster_requirements(input_image_paths, debug_logs)\n    if not os.path.exists(output_image_folder): os.makedirs(output_image_folder)\n    if isinstance(window_size, int): window_size = (window_size, window_size)\n    input_image_names = [os.path.splitext(os.path.basename(path))[0] for path in input_image_paths]\n\n    # Load data from precomputed block maps if set\n    if load_block_maps:\n        block_local_means, block_reference_mean, num_row, num_col, bounds_canvas_coords = get_pre_computed_block_maps(load_block_maps, calculation_dtype_precision)\n        validate_pre_computed_block_maps(block_local_means, block_reference_mean, num_row, num_col, bounds_canvas_coords, input_image_paths)\n        loaded_block_map_reference_path, loaded_block_map_local_paths = load_block_maps\n        loaded_block_map_reference_name = os.path.splitext(os.path.basename(loaded_block_map_reference_path))[0]\n        loaded_block_map_local_names = [os.path.splitext(os.path.basename(path))[0] for path in loaded_block_map_local_paths]\n\n\n    nodata_val = _get_nodata_value(input_image_paths, custom_nodata_value)\n    projection = rasterio.open(input_image_paths[0]).crs\n    if debug_logs: print(f\"Global nodata value: {nodata_val}\")\n    bounds_images_coords = [rasterio.open(img).bounds for img in input_image_paths]\n    with rasterio.open(input_image_paths[0]) as ds:num_bands = ds.count\n    if not load_block_maps: bounds_canvas_coords = _get_bounding_rectangle(input_image_paths)\n\n\n    # Calculate the number of blocks\n    if not load_block_maps:\n        if isinstance(number_of_blocks, int):\n            num_row, num_col = _compute_block_size(input_image_paths, number_of_blocks, bounds_canvas_coords)\n        elif isinstance(number_of_blocks, tuple):\n            num_row, num_col = number_of_blocks\n        elif isinstance(number_of_blocks, str):\n            num_row, num_col = _compute_mosaic_coefficient_of_variation(input_image_paths, nodata_val) # This is the approach from the paper to compute bock size\n\n    if debug_logs: print(\"Computing local block map\")\n    if not load_block_maps:\n        block_local_means, block_local_counts = _compute_local_blocks(\n            input_image_paths,\n            bounds_canvas_coords,\n            num_row,\n            num_col,\n            num_bands,\n            window_size,\n            debug_logs,\n            nodata_val,\n            calculation_dtype_precision,\n        )\n\n    bounds_images_block_space = get_bounding_rect_images_block_space(block_local_means)\n\n    if debug_logs: print(\"Computing reference block map\")\n    if not load_block_maps:\n        block_reference_mean = _compute_reference_blocks(\n            block_local_means,\n            block_local_counts,\n            )\n\n    if save_block_maps:\n        _download_block_map(\n            np.nan_to_num(block_reference_mean, nan=nodata_val),\n            bounds_canvas_coords,\n            os.path.join(output_image_folder, \"BlockReferenceMean\", f\"BlockReferenceMean.tif\"),\n            projection,\n            calculation_dtype_precision,\n            nodata_val,\n            num_col,\n            num_row,\n        )\n        for img_idx, (block_local_mean, input_image_name) in enumerate(zip(block_local_means, input_image_names)):\n            _download_block_map(\n                np.nan_to_num(block_local_mean, nan=nodata_val),\n                bounds_canvas_coords,\n                os.path.join(output_image_folder, \"BlockLocalMean\", f\"{input_image_name}_BlockLocalMean.tif\"),\n                projection,\n                calculation_dtype_precision,\n                nodata_val,\n                num_col,\n                num_row,\n            )\n            # _download_block_map(\n            #     np.nan_to_num(block_local_count, nan=nodata_val),\n            #     bounds_canvas_coords,\n            #     os.path.join(output_image_folder, \"BlockLocalCount\", f\"{input_image_name}_BlockLocalCount.tif\"),\n            #     projection,\n            #     calculation_dtype_precision,\n            #     nodata_val,\n            #     num_col,\n            #     num_row,\n            # )\n\n    # block_local_mean = _smooth_array(block_local_mean, nodata_value=global_nodata_value)\n\n    if parallel_workers == \"cpu\":\n        parallel = True\n        max_workers = mp.cpu_count()\n    elif isinstance(parallel_workers, int) and parallel_workers &gt; 0:\n        parallel = True\n        max_workers = parallel_workers\n    else:\n        parallel = False\n        max_workers = None\n\n    out_paths: List[str] = []\n    for img_idx, img_path in enumerate(input_image_paths):\n        in_name = os.path.splitext(os.path.basename(img_path))[0]\n        out_name = os.path.splitext(os.path.basename(img_path))[0] + output_local_basename\n        out_path = os.path.join(output_image_folder, f\"{out_name}.tif\")\n        out_paths.append(str(out_path))\n\n        if debug_logs: print(f\"Processing {in_name}\")\n        if debug_logs: print(f\"Computing local correction, applying, and saving\")\n        with rasterio.open(img_path) as src:\n            meta = src.meta.copy()\n            meta.update({\"count\": num_bands, \"dtype\": output_dtype, \"nodata\": nodata_val})\n            block_reference_mean_masked = np.where(\n                (np.arange(block_reference_mean.shape[0])[:, None, None] &gt;= bounds_images_block_space[img_idx][0]) &amp;\n                (np.arange(block_reference_mean.shape[0])[:, None, None] &lt; bounds_images_block_space[img_idx][2]) &amp;\n                (np.arange(block_reference_mean.shape[1])[None, :, None] &gt;= bounds_images_block_space[img_idx][1]) &amp;\n                (np.arange(block_reference_mean.shape[1])[None, :, None] &lt; bounds_images_block_space[img_idx][3]),\n                block_reference_mean,\n                np.nan\n            )\n\n            if isinstance(window_size, tuple):\n                tw, th = window_size\n                windows = list(_create_windows(src.width, src.height, tw, th))\n            elif window_size == \"block\":\n                block_width_geo = (bounds_canvas_coords[2] - bounds_canvas_coords[0]) / num_col\n                block_height_geo = (bounds_canvas_coords[3] - bounds_canvas_coords[1]) / num_row\n                res_x = abs(src.transform.a)\n                res_y = abs(src.transform.e)\n                tile_width = max(1, int(round(block_width_geo / res_x)))\n                tile_height = max(1, int(round(block_height_geo / res_y)))\n                windows = list(_create_windows(src.width, src.height, tile_width, tile_height))\n            elif window_size is None:\n                windows = [Window(0, 0, src.width, src.height)]\n            # if debug_logs: print(f\"BandIDWindowID[xStart:yStart xSizeXySize] ({len(windows)} windows): \", end=\"\")\n\n            if parallel:\n                ctx = _choose_context(prefer_fork=True)\n\n                ref_shm = shared_memory.SharedMemory(create=True, size=block_reference_mean.nbytes)\n                ref_array = np.ndarray(block_reference_mean.shape, dtype=block_reference_mean.dtype, buffer=ref_shm.buf)\n                ref_array[:] = block_reference_mean[:]\n\n                loc_shm = shared_memory.SharedMemory(create=True, size=block_local_means[img_idx].nbytes)\n                loc_array = np.ndarray(block_local_means[img_idx].shape, dtype=block_local_means[img_idx].dtype, buffer=loc_shm.buf)\n                loc_array[:] = block_local_means[img_idx][:]\n\n                pool = ProcessPoolExecutor(\n                    max_workers=max_workers,\n                    mp_context=ctx,\n                    initializer=_init_worker,\n                    initargs=(img_path, ref_shm.name, loc_shm.name, block_reference_mean.shape, block_local_means[img_idx].shape, block_reference_mean.dtype.name),\n                )\n\n                try:\n                    with rasterio.open(out_path, \"w\", **meta) as dst:\n                        futures = [\n                            pool.submit(_compute_tile_local,\n                                        w,\n                                        b,\n                                        num_row,\n                                        num_col,\n                                        bounds_canvas_coords,\n                                        bounds_images_coords[img_idx],\n                                        block_reference_mean_masked,\n                                        block_local_means[img_idx],\n                                        nodata_val,\n                                        alpha,\n                                        correction_method,\n                                        calculation_dtype_precision,\n                                        debug_logs,\n                                        w_id,\n                                        output_image_folder,\n                                        out_name,\n                                        projection,\n                                        num_bands,\n                                        save_block_maps,\n                                        )\n                            for b in range(num_bands)\n                            for w_id, w in enumerate(windows)\n                        ]\n                        for fut in as_completed(futures):\n                            win, b_idx, buf = fut.result()\n                            dst.write(buf.astype(output_dtype), b_idx + 1, window=win)\n                            del buf, win\n                finally:\n                    pool.shutdown(wait=True)\n                    ref_shm.close()\n                    loc_shm.close()\n                    ref_shm.unlink()\n                    loc_shm.unlink()\n            else:\n                with rasterio.open(out_path, \"w\", **meta) as dst:\n                    _worker_dataset_cache[\"ds\"] = rasterio.open(img_path, \"r\")\n                    _worker_dataset_cache[\"block_ref_mean\"] = block_reference_mean\n                    _worker_dataset_cache[\"block_loc_mean\"] = block_local_means[img_idx]\n\n                    for b in range(num_bands):\n                        for w_id, win in enumerate(windows):\n                            win_, b_idx, buf = _compute_tile_local(\n                                win,\n                                b,\n                                num_row,\n                                num_col,\n                                bounds_canvas_coords,\n                                bounds_images_coords[img_idx],\n                                block_reference_mean_masked,\n                                block_local_means[img_idx],\n                                nodata_val,\n                                alpha,\n                                correction_method,\n                                calculation_dtype_precision,\n                                debug_logs,\n                                w_id,\n                                output_image_folder,\n                                out_name,\n                                projection,\n                                num_bands,\n                                save_block_maps,\n                            )\n                            dst.write(buf.astype(output_dtype), b_idx + 1, window=win_)\n                            del buf, win_\n            if debug_logs: print()\n            if not parallel:\n                if \"ds\" in _worker_dataset_cache:\n                    _worker_dataset_cache[\"ds\"].close()\n                    del _worker_dataset_cache[\"ds\"]\n                _worker_dataset_cache.pop(\"block_ref_mean\", None)\n                _worker_dataset_cache.pop(\"block_loc_mean\", None)\n\n            del block_reference_mean_masked, windows\n            gc.collect()\n    print(\"Finished local block adjustment\")\n    return out_paths\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.validate_pre_computed_block_maps","title":"<code>validate_pre_computed_block_maps(block_local_means, input_image_paths)</code>","text":"<p>Validate consistency between pre-computed block maps and expected input image metadata.</p> <p>Parameters:</p> Name Type Description Default <code>block_local_means</code> <code>ndarray</code> <p>Array of shape (num_images, num_row, num_col, num_bands).</p> required <code>input_image_paths</code> <code>List[str]</code> <p>List of input image file paths.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if any inconsistency is found.</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def validate_pre_computed_block_maps(\n    block_local_means: np.ndarray,\n    input_image_paths: List[str]\n    ) -&gt; None:\n    \"\"\"\n    Validate consistency between pre-computed block maps and expected input image metadata.\n\n    Args:\n        block_local_means: Array of shape (num_images, num_row, num_col, num_bands).\n        input_image_paths: List of input image file paths.\n\n    Raises:\n        ValueError: if any inconsistency is found.\n    \"\"\"\n    if len(input_image_paths) != block_local_means.shape[0]:\n        raise ValueError(\"Number of input images does not match number of local block maps.\")\n    else:\n        print(\"Number of local block maps matches input images\")\n</code></pre>"},{"location":"api/statistics/","title":"Creating Statistical Figures","text":""},{"location":"api/statistics/#spectralmatch.statistics.compare_image_spectral_profiles","title":"<code>compare_image_spectral_profiles(input_image_dict, output_figure_path, title, xlabel, ylabel)</code>","text":"<p>Compares spectral profiles of multiple images by plotting median and interquartile ranges.</p> <p>Parameters:</p> Name Type Description Default <code>input_image_dict</code> <code>dict</code> <p>Mapping of labels to image file paths.</p> required <code>output_figure_path</code> <code>str</code> <p>Path to save the output plot.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>xlabel</code> <code>str</code> <p>Label for the x-axis.</p> required <code>ylabel</code> <code>str</code> <p>Label for the y-axis.</p> required Outputs <p>Saves a spectral profile comparison figure to the specified path.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_image_spectral_profiles(\n    input_image_dict: dict,\n    output_figure_path: str,\n    title: str,\n    xlabel: str,\n    ylabel: str,\n    ):\n    \"\"\"\n    Compares spectral profiles of multiple images by plotting median and interquartile ranges.\n\n    Args:\n        input_image_dict (dict): Mapping of labels to image file paths.\n        output_figure_path (str): Path to save the output plot.\n        title (str): Title of the plot.\n        xlabel (str): Label for the x-axis.\n        ylabel (str): Label for the y-axis.\n\n    Outputs:\n        Saves a spectral profile comparison figure to the specified path.\n    \"\"\"\n\n    plt.figure(figsize=(10, 6))\n    colors = itertools.cycle(plt.cm.tab10.colors)  # Cycle through colors\n    spectral_profiles = []\n    labels = []\n\n    for label, image_path in input_image_dict.items():\n        dataset = gdal.Open(image_path)\n        if dataset is None:\n            print(f\"Failed to open {image_path}\")\n            continue\n\n        image_data = dataset.ReadAsArray()\n        if image_data.ndim == 3:\n            bands, height, width = image_data.shape\n        else:\n            bands, height, width = 1, *image_data.shape\n            image_data = np.expand_dims(image_data, axis=0)\n\n        image_data = image_data.reshape(bands, -1)\n        mean_spectral = np.median(image_data, axis=1)\n        q25, q75 = np.percentile(image_data, [25, 75], axis=1)\n        spectral_profiles.append((mean_spectral, q25, q75))\n        labels.append(label)\n\n    for i, (mean_spectral, q25, q75) in enumerate(spectral_profiles):\n        color = next(colors)  # Assign unique color\n        plt.plot(range(1, len(mean_spectral) + 1), mean_spectral, color=color, label=labels[i])\n        plt.fill_between(range(1, len(mean_spectral) + 1), q25, q75, color=color, alpha=0.3)\n\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(output_figure_path, dpi=300)\n    plt.close()\n    print(f\"Figure saved to: {output_figure_path}\")\n</code></pre>"},{"location":"api/statistics/#spectralmatch.statistics.compare_image_spectral_profiles_pairs","title":"<code>compare_image_spectral_profiles_pairs(image_groups_dict, output_figure_path)</code>","text":"<p>Plots paired spectral profiles for before-and-after image comparisons.</p> <p>Parameters:</p> Name Type Description Default <code>image_groups_dict</code> <code>dict</code> <p>Mapping of labels to image path pairs (before, after).</p> required <code>output_figure_path</code> <code>str</code> <p>Path to save the resulting comparison figure.</p> required Outputs <p>Saves a spectral comparison plot showing pre- and post-processing profiles.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_image_spectral_profiles_pairs(\n    image_groups_dict: dict,\n    output_figure_path: str,\n    ):\n    \"\"\"\n    Plots paired spectral profiles for before-and-after image comparisons.\n\n    Args:\n        image_groups_dict (dict): Mapping of labels to image path pairs (before, after).\n        output_figure_path (str): Path to save the resulting comparison figure.\n\n    Outputs:\n        Saves a spectral comparison plot showing pre- and post-processing profiles.\n    \"\"\"\n\n    plt.figure(figsize=(10, 6))\n    colors = itertools.cycle(plt.cm.tab10.colors)  # Cycle through colors\n\n    for label, group in image_groups_dict.items():\n        if len(group) == 2:  # Ensure paired comparison\n            image_path1, image_path2 = group\n            color = next(colors)  # Assign the same color to both images\n\n            for i, image_path in enumerate([image_path1, image_path2]):\n                with rasterio.open(image_path) as src:\n                    img = src.read()\n                    num_bands = img.shape[0]\n                    img_reshaped = img.reshape(num_bands, -1)\n                    nodata_value = src.nodata\n                    if nodata_value is not None:\n                        img_reshaped = np.where(img_reshaped == nodata_value, np.nan, img_reshaped)\n                    mean_spectral = np.nanmean(img_reshaped, axis=1)\n                    bands = np.arange(1, num_bands + 1)\n                    linestyle = 'dashed' if i == 0 else 'solid'\n                    plt.plot(bands, mean_spectral, linestyle=linestyle, color=color, label=f\"{label} - {'Before' if i == 0 else 'After'}\")\n\n    plt.xlabel(\"Band Number\")\n    plt.ylabel(\"Reflectance(0-10,000)\")\n    plt.title(\"Pre and Post Spectral Match Comparison\")\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(output_figure_path, dpi=300)\n    plt.close()\n    print(f\"Figure saved to: {output_figure_path}\")\n</code></pre>"},{"location":"api/statistics/#spectralmatch.statistics.compare_spatial_spectral_difference_average","title":"<code>compare_spatial_spectral_difference_average(input_overlapping_image_pair_path, output_image_path)</code>","text":"<p>Generates a heatmap of the average spectral difference between two overlapping images.</p> <p>Parameters:</p> Name Type Description Default <code>input_overlapping_image_pair_path</code> <code>list</code> <p>List containing exactly two image paths (pre and post).</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the resulting difference visualization.</p> required Outputs <p>Saves a heatmap image illustrating spatial spectral differences.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the list does not contain exactly two images or if image dimensions differ.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_spatial_spectral_difference_average(\n    input_overlapping_image_pair_path: list,\n    output_image_path: str,\n    ):\n    \"\"\"\n    Generates a heatmap of the average spectral difference between two overlapping images.\n\n    Args:\n        input_overlapping_image_pair_path (list): List containing exactly two image paths (pre and post).\n        output_image_path (str): Path to save the resulting difference visualization.\n\n    Outputs:\n        Saves a heatmap image illustrating spatial spectral differences.\n\n    Raises:\n        ValueError: If the list does not contain exactly two images or if image dimensions differ.\n    \"\"\"\n\n    if len(input_overlapping_image_pair_path) != 2:\n        raise ValueError(\"Function requires exactly two image paths for comparison.\")\n\n    image_path1, image_path2 = input_overlapping_image_pair_path\n\n    with rasterio.open(image_path1) as src1, rasterio.open(image_path2) as src2:\n        img1 = src1.read()  # Read all bands (shape: bands, height, width)\n        img2 = src2.read()\n\n        if img1.shape != img2.shape:\n            raise ValueError(\"Images must have the same dimensions for comparison.\")\n\n        # Compute absolute spectral difference per band\n        diff = np.abs(img2 - img1)\n        mean_diff = np.mean(diff, axis=0)  # Average across bands for visualization\n\n        plt.figure(figsize=(10, 6))\n        plt.imshow(mean_diff, cmap='coolwarm', interpolation='nearest')\n        plt.colorbar(label=\"Spectral Difference\")\n        plt.title(\"Spatial Spectral Difference (Post - Pre)\")\n        plt.axis(\"off\")\n\n        plt.savefig(output_image_path, dpi=300, bbox_inches='tight')\n        plt.close()\n\n    print(f\"Spatial spectral difference figure saved to: {output_image_path}\")\n</code></pre>"},{"location":"api/statistics/#spectralmatch.statistics.compare_spatial_spectral_difference_individual_bands","title":"<code>compare_spatial_spectral_difference_individual_bands(input_overlapping_image_pair_paths, output_image_path)</code>","text":"<p>Creates a color-coded visualization of spectral differences per band between two overlapping images.</p> <p>Parameters:</p> Name Type Description Default <code>input_overlapping_image_pair_paths</code> <code>tuple</code> <p>Tuple of two image paths (before, after).</p> required <code>output_image_path</code> <code>str</code> <p>Path to save the RGB difference visualization as a PNG.</p> required Outputs <p>Saves a PNG image where color represents the dominant band of spectral difference and brightness indicates magnitude.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input images differ in shape.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_spatial_spectral_difference_individual_bands(\n    input_overlapping_image_pair_paths: tuple,\n    output_image_path: str,\n    ):\n    \"\"\"\n    Creates a color-coded visualization of spectral differences per band between two overlapping images.\n\n    Args:\n        input_overlapping_image_pair_paths (tuple): Tuple of two image paths (before, after).\n        output_image_path (str): Path to save the RGB difference visualization as a PNG.\n\n    Outputs:\n        Saves a PNG image where color represents the dominant band of spectral difference and brightness indicates magnitude.\n\n    Raises:\n        ValueError: If input images differ in shape.\n    \"\"\"\n\n    path1, path2 = input_overlapping_image_pair_paths\n    with rasterio.open(path1) as src1, rasterio.open(path2) as src2:\n        img1 = src1.read()  # shape: (num_bands, height, width)\n        img2 = src2.read()  # shape: (num_bands, height, width)\n\n        if img1.shape != img2.shape:\n            raise ValueError(\n                f\"Input images do not have the same shape:\\n\"\n                f\" Image1 shape: {img1.shape}, Image2 shape: {img2.shape}\"\n            )\n\n        num_bands, height, width = img1.shape\n\n    diff = np.abs(img1 - img2).astype(np.float32)  # (bands, height, width)\n\n    global_min = diff.min()  # often 0\n    global_max = diff.max()\n\n    default_colors = [\n        (1.0, 0.0, 0.0),  # Band 1 -&gt; Red\n        (0.0, 1.0, 0.0),  # Band 2 -&gt; Green\n        (0.0, 0.0, 1.0),  # Band 3 -&gt; Blue\n        (1.0, 1.0, 0.0),  # Band 4 -&gt; Yellow\n        (1.0, 0.0, 1.0),  # Band 5 -&gt; Magenta\n        (0.0, 1.0, 1.0),  # Band 6 -&gt; Cyan\n        (1.0, 0.5, 0.0),  # Band 7 -&gt; Orange\n        # etc. Add more if needed\n    ]\n\n    band_colors = [default_colors[i % len(default_colors)] for i in range(num_bands)]\n    band_colors = np.array(band_colors, dtype=np.float32)  # shape: (num_bands, 3)\n\n    # Initialize an empty float array for RGB: shape = (3, height, width)\n    output_rgb = np.zeros((3, height, width), dtype=np.float32)\n\n    # sum of differences per pixel across all bands -&gt; shape: (height, width)\n    sum_diff = diff.sum(axis=0)\n    sum_diff_safe = np.where(sum_diff == 0, 1e-10, sum_diff)  # avoid division-by-zero\n\n    # fraction_diff[b, y, x] = diff[b, y, x] / sum_diff[y, x]\n    fraction_diff = diff / sum_diff_safe\n\n    # Accumulate weighted colors\n    for b in range(num_bands):\n        # band_colors[b] is shape (3,)\n        # fraction_diff[b] is shape (height, width)\n        output_rgb += fraction_diff[b] * band_colors[b].reshape(3, 1, 1)\n\n\n    brightness = (sum_diff - global_min) / (global_max - global_min + 1e-10)\n    brightness = np.clip(brightness, 0.0, 1.0)\n    # Multiply the RGB by brightness\n    output_rgb *= brightness.reshape(1, height, width)\n\n    output_rgb_for_plot = np.transpose(output_rgb, (1, 2, 0))\n\n    # Ensure the data is in 0..1\n    output_rgb_for_plot = np.clip(output_rgb_for_plot, 0, 1)\n\n    # Use plt.imsave to write out a PNG\n    plt.imsave(output_image_path, output_rgb_for_plot)\n\n    print(f\"Saved difference visualization PNG to: {output_image_path}\")\n</code></pre>"},{"location":"examples/benchmark/","title":"Benchmark Multithreading","text":"In\u00a0[\u00a0]: Copied! <pre>import os, shutil, tempfile, time\nfrom pathlib import Path\n</pre> import os, shutil, tempfile, time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_origin\n</pre> import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.transform import from_origin In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import global_regression, local_block_adjustment\n</pre> from spectralmatch import global_regression, local_block_adjustment In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def make_fake_rasters(out_dir, n_images, width, height, nodata=0):\n    out_dir = Path(out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n    profile = dict(\n        driver=\"GTiff\",\n        width=width,\n        height=height,\n        count=8,\n        dtype=\"uint16\",\n        nodata=nodata,\n        crs=\"EPSG:3857\",\n        transform=from_origin(0, 0, 1, 1),\n        tiled=True,\n        blockxsize=512,\n        blockysize=512,\n        compress=\"LZW\",\n    )\n    rng = np.random.default_rng(seed=42)\n    paths = []\n    for i in range(n_images):\n        p = out_dir / f\"fake_{i+1}_{width}px.tif\"\n        with rasterio.open(p, \"w\", **profile) as dst:\n            for b in range(1, 9):\n                data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")\n                data[0, 0] = nodata\n                dst.write(data, indexes=b)\n        paths.append(str(p))\n    return paths\n</pre> def make_fake_rasters(out_dir, n_images, width, height, nodata=0):     out_dir = Path(out_dir)     out_dir.mkdir(parents=True, exist_ok=True)     profile = dict(         driver=\"GTiff\",         width=width,         height=height,         count=8,         dtype=\"uint16\",         nodata=nodata,         crs=\"EPSG:3857\",         transform=from_origin(0, 0, 1, 1),         tiled=True,         blockxsize=512,         blockysize=512,         compress=\"LZW\",     )     rng = np.random.default_rng(seed=42)     paths = []     for i in range(n_images):         p = out_dir / f\"fake_{i+1}_{width}px.tif\"         with rasterio.open(p, \"w\", **profile) as dst:             for b in range(1, 9):                 data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")                 data[0, 0] = nodata                 dst.write(data, indexes=b)         paths.append(str(p))     return paths In\u00a0[\u00a0]: Copied! <pre>SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288]\nNUM_IMAGES = 2\nTILE_SIZE = (1024, 1024)\nMAX_WORKERS = 32\n</pre> SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288] NUM_IMAGES = 2 TILE_SIZE = (1024, 1024) MAX_WORKERS = 32 In\u00a0[\u00a0]: Copied! <pre>WORK_DIR = Path(__file__).parent / \"bench_output\"\nWORK_DIR.mkdir(exist_ok=True)\n</pre> WORK_DIR = Path(__file__).parent / \"bench_output\" WORK_DIR.mkdir(exist_ok=True) In\u00a0[\u00a0]: Copied! <pre>SERIAL, PARALLEL = [], []\n</pre> SERIAL, PARALLEL = [], [] In\u00a0[\u00a0]: Copied! <pre>for sz in SIZES:\n    print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")\n    tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))\n    imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)\n\n    t0 = time.time()\n    g_dir = tmp / \"serial_g\"\n    l_dir = tmp / \"serial_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        window_size=TILE_SIZE,\n        parallel=False,\n        debug_logs=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        window_size=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=False,\n        debug_logs=False,\n    )\n    SERIAL.append(time.time() - t0)\n    print(f\"serial   : {SERIAL[-1]:.1f} s\")\n\n    t0 = time.time()\n    g_dir = tmp / \"parallel_g\"\n    l_dir = tmp / \"parallel_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        window_size=TILE_SIZE,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_logs=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        window_size=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_logs=False,\n    )\n    PARALLEL.append(time.time() - t0)\n    print(f\"parallel : {PARALLEL[-1]:.1f} s\")\n\n    shutil.rmtree(tmp, ignore_errors=True)\n</pre> for sz in SIZES:     print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")     tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))     imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)      t0 = time.time()     g_dir = tmp / \"serial_g\"     l_dir = tmp / \"serial_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         window_size=TILE_SIZE,         parallel=False,         debug_logs=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         window_size=TILE_SIZE,         custom_nodata_value=-9999,         parallel=False,         debug_logs=False,     )     SERIAL.append(time.time() - t0)     print(f\"serial   : {SERIAL[-1]:.1f} s\")      t0 = time.time()     g_dir = tmp / \"parallel_g\"     l_dir = tmp / \"parallel_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         window_size=TILE_SIZE,         parallel=True,         max_workers=MAX_WORKERS,         debug_logs=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         window_size=TILE_SIZE,         custom_nodata_value=-9999,         parallel=True,         max_workers=MAX_WORKERS,         debug_logs=False,     )     PARALLEL.append(time.time() - t0)     print(f\"parallel : {PARALLEL[-1]:.1f} s\")      shutil.rmtree(tmp, ignore_errors=True) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 5))\nplt.plot(SIZES, SERIAL, \"-o\", label=\"serial\")\nplt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\")\nplt.xlabel(\"Raster width = height (pixels)\")\nplt.ylabel(\"Total runtime: global + local (seconds)\")\nplt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(8, 5)) plt.plot(SIZES, SERIAL, \"-o\", label=\"serial\") plt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\") plt.xlabel(\"Raster width = height (pixels)\") plt.ylabel(\"Total runtime: global + local (seconds)\") plt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\") plt.grid(True) plt.legend() plt.tight_layout() plt.show()"},{"location":"examples/example_landsat_time_series/","title":"Landsat Time Series","text":"In\u00a0[\u00a0]: Copied! <pre># This notebook demonstrates how to preprocess Landsat 8-9 into a time series with spectralmatch. Starting from 5 Landsat 8-9 OLI/TIRS C2 L1 images, the process includes clipping clouds with OmniCloudMask, masking high NDVI areas as Pseudo Invariant Features (PIFs), applying global regression Relative Radiometric Normalization, fine-tuning overlap areas with local block adjustment, and before vs after statistics.\n\n# This script is setup to perform matching on all tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif.\n</pre> # This notebook demonstrates how to preprocess Landsat 8-9 into a time series with spectralmatch. Starting from 5 Landsat 8-9 OLI/TIRS C2 L1 images, the process includes clipping clouds with OmniCloudMask, masking high NDVI areas as Pseudo Invariant Features (PIFs), applying global regression Relative Radiometric Normalization, fine-tuning overlap areas with local block adjustment, and before vs after statistics.  # This script is setup to perform matching on all tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. In\u00a0[\u00a0]: Copied! <pre>import os\nimport importlib\n\nfrom spectralmatch.match.global_regression import global_regression\nfrom spectralmatch.match.local_block_adjustment import local_block_adjustment\nfrom spectralmatch.handlers import merge_rasters\nfrom spectralmatch.mask import create_cloud_mask_with_omnicloudmask, post_process_raster_cloud_mask_to_vector, create_ndvi_mask, post_process_threshold_to_vector, mask_image_with_vector\n\nworking_directory = os.path.join(os.getcwd(), \"data_landsat\")\nprint(working_directory)\n</pre> import os import importlib  from spectralmatch.match.global_regression import global_regression from spectralmatch.match.local_block_adjustment import local_block_adjustment from spectralmatch.handlers import merge_rasters from spectralmatch.mask import create_cloud_mask_with_omnicloudmask, post_process_raster_cloud_mask_to_vector, create_ndvi_mask, post_process_threshold_to_vector, mask_image_with_vector  working_directory = os.path.join(os.getcwd(), \"data_landsat\") print(working_directory) In\u00a0[\u00a0]: Copied! <pre>input_folder = os.path.join(working_directory, \"Input\")\noutput_folder = os.path.join(working_directory, 'Masks');\nos.makedirs(output_folder, exist_ok=True)\ninput_image_paths_array = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if\n                           f.lower().endswith(\".tif\")]\n\nfor path in input_image_paths_array:\n    create_cloud_mask_with_omnicloudmask(\n        path,\n        5,\n        3,\n        8,\n        os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.tif\"),\n        # down_sample_m=10\n    )\n\ninput_mask_rasters = [os.path.join(output_folder, f) for f in os.listdir(output_folder) if f.lower().endswith(\".tif\")]\n\nfor path in input_mask_rasters:\n    post_process_raster_cloud_mask_to_vector(\n        path,\n        os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.gpkg\"),\n        None,\n        {1: 50},\n        {0: 0, 1: 1, 2: 1, 3: 1}\n    )\n</pre> input_folder = os.path.join(working_directory, \"Input\") output_folder = os.path.join(working_directory, 'Masks'); os.makedirs(output_folder, exist_ok=True) input_image_paths_array = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if                            f.lower().endswith(\".tif\")]  for path in input_image_paths_array:     create_cloud_mask_with_omnicloudmask(         path,         5,         3,         8,         os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.tif\"),         # down_sample_m=10     )  input_mask_rasters = [os.path.join(output_folder, f) for f in os.listdir(output_folder) if f.lower().endswith(\".tif\")]  for path in input_mask_rasters:     post_process_raster_cloud_mask_to_vector(         path,         os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(path))[0]}_CloudMask.gpkg\"),         None,         {1: 50},         {0: 0, 1: 1, 2: 1, 3: 1}     ) In\u00a0[\u00a0]: Copied! <pre>input_folder = os.path.join(working_directory, \"Input\")\nmask_folder = os.path.join(working_directory, \"Masks\")\noutput_folder = os.path.join(working_directory, \"Masked\")\ninput_paths = sorted([os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")])\ninput_mask_vectors = sorted(\n    [os.path.join(mask_folder, f) for f in os.listdir(mask_folder) if f.lower().endswith(\".gpkg\")])\noutput_paths = sorted(\n    [os.path.join(output_folder, os.path.splitext(os.path.basename(path))[0] + \"_CloudMasked.tif\") for path in\n     input_paths])\n\nfor input_path, vector_path, output_path in zip(input_paths, input_mask_vectors, output_paths):\n    mask_image_with_vector(\n        input_path,\n        vector_path,\n        output_path,\n        {\"value\": 0},\n        True\n    )\n</pre> input_folder = os.path.join(working_directory, \"Input\") mask_folder = os.path.join(working_directory, \"Masks\") output_folder = os.path.join(working_directory, \"Masked\") input_paths = sorted([os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")]) input_mask_vectors = sorted(     [os.path.join(mask_folder, f) for f in os.listdir(mask_folder) if f.lower().endswith(\".gpkg\")]) output_paths = sorted(     [os.path.join(output_folder, os.path.splitext(os.path.basename(path))[0] + \"_CloudMasked.tif\") for path in      input_paths])  for input_path, vector_path, output_path in zip(input_paths, input_mask_vectors, output_paths):     mask_image_with_vector(         input_path,         vector_path,         output_path,         {\"value\": 0},         True     ) In\u00a0[\u00a0]: Copied! <pre>input_folder = os.path.join(working_directory, \"Input\")\nmask_folder = os.path.join(working_directory, \"Pifs\")\noutput_folder = os.path.join(working_directory, \"Pifed\")\ninput_paths = sorted([os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")])\noutput_raster_masks = sorted(\n    [os.path.join(mask_folder, os.path.splitext(os.path.basename(path))[0] + \"_CloudMasked.tif\") for path in\n     input_paths])\noutput_vectors_masks = sorted(\n    [os.path.join(mask_folder, os.path.splitext(os.path.basename(path))[0] + \"_CloudMasked.gpkg\") for path in\n     input_paths])\n\nfor input_path, raster_path, vector_path in zip(input_paths, output_raster_masks, output_vectors_masks):\n    create_ndvi_mask(\n        input_path,\n        raster_path,\n        5,\n        4,\n    )\n\nfor input_path, raster_path, vector_path in zip(input_paths, output_raster_masks, output_vectors_masks):\n    post_process_threshold_to_vector(\n        raster_path,\n        vector_path,\n        0.2,\n        \"&lt;=\",\n    )\n</pre> input_folder = os.path.join(working_directory, \"Input\") mask_folder = os.path.join(working_directory, \"Pifs\") output_folder = os.path.join(working_directory, \"Pifed\") input_paths = sorted([os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")]) output_raster_masks = sorted(     [os.path.join(mask_folder, os.path.splitext(os.path.basename(path))[0] + \"_CloudMasked.tif\") for path in      input_paths]) output_vectors_masks = sorted(     [os.path.join(mask_folder, os.path.splitext(os.path.basename(path))[0] + \"_CloudMasked.gpkg\") for path in      input_paths])  for input_path, raster_path, vector_path in zip(input_paths, output_raster_masks, output_vectors_masks):     create_ndvi_mask(         input_path,         raster_path,         5,         4,     )  for input_path, raster_path, vector_path in zip(input_paths, output_raster_masks, output_vectors_masks):     post_process_threshold_to_vector(         raster_path,         vector_path,         0.2,         \"&lt;=\",     ) In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = working_directory + \"/Input/Masks.gpkg\"\ninput_folder = os.path.join(working_directory, \"Masked\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\ninput_image_paths = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")]\n\nglobal_regression(\n    input_image_paths,\n    global_folder,\n    custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together\n    custom_std_factor = 1,\n    # vector_mask_path=vector_mask_path,\n    debug_logs=False,\n    window_size=(512, 512),\n    parallel=True,\n    )\n</pre> vector_mask_path = working_directory + \"/Input/Masks.gpkg\" input_folder = os.path.join(working_directory, \"Masked\") global_folder = os.path.join(working_directory, \"GlobalMatch\") input_image_paths = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")]  global_regression(     input_image_paths,     global_folder,     custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together     custom_std_factor = 1,     # vector_mask_path=vector_mask_path,     debug_logs=False,     window_size=(512, 512),     parallel=True,     ) In\u00a0[\u00a0]: Copied! <pre>global_folder = os.path.join(working_directory, \"GlobalMatch\")\ninput_image_paths = [os.path.join(global_folder, f) for f in os.listdir(global_folder) if f.lower().endswith(\".tif\")]\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\nglobal_image_paths_array = [os.path.join(global_folder, f) for f in os.listdir(global_folder) if f.lower().endswith(\".tif\")]\n\nmatched_local_images_paths = local_block_adjustment(\n    global_image_paths_array,\n    local_folder,\n    number_of_blocks=100,\n    debug_logs=False,\n    window_size=(512, 512),\n    parallel=True,\n    )\n\nmerge_rasters(\n    matched_local_images_paths, # Rasters are layered with the last ones on top\n    os.path.join(working_directory, \"MatchedLocalImages.tif\"),\n    window_size=(512, 512),\n    )\n\nprint(\"Done with global and local histogram matching\")\n</pre> global_folder = os.path.join(working_directory, \"GlobalMatch\") input_image_paths = [os.path.join(global_folder, f) for f in os.listdir(global_folder) if f.lower().endswith(\".tif\")] local_folder = os.path.join(working_directory, \"LocalMatch\") global_image_paths_array = [os.path.join(global_folder, f) for f in os.listdir(global_folder) if f.lower().endswith(\".tif\")]  matched_local_images_paths = local_block_adjustment(     global_image_paths_array,     local_folder,     number_of_blocks=100,     debug_logs=False,     window_size=(512, 512),     parallel=True,     )  merge_rasters(     matched_local_images_paths, # Rasters are layered with the last ones on top     os.path.join(working_directory, \"MatchedLocalImages.tif\"),     window_size=(512, 512),     )  print(\"Done with global and local histogram matching\") In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/example_worldview_mosaic/","title":"WorldView Mosaic","text":"In\u00a0[\u00a0]: Copied! <pre># This file demonstrates how to preprocess Worldview3 imagery into a mosaic using spectralmatch.\n# Starting from two overlapping Worldview3 images in reflectance, the process includes global matching, local matching, starting from saved block maps (optional for demonstration purposes), generating seamlines, and marging images, and before vs after statistics.\n# This script is set up to perform matching on all .tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif.\n</pre> # This file demonstrates how to preprocess Worldview3 imagery into a mosaic using spectralmatch. # Starting from two overlapping Worldview3 images in reflectance, the process includes global matching, local matching, starting from saved block maps (optional for demonstration purposes), generating seamlines, and marging images, and before vs after statistics. # This script is set up to perform matching on all .tif files from a folder within the working directory called \"Input\" e.g. working_directory/Input/*.tif. In\u00a0[\u00a0]: Copied! <pre>import os\nimport importlib\n\nfrom spectralmatch.match.global_regression import global_regression\nfrom spectralmatch.match.local_block_adjustment import local_block_adjustment\nfrom spectralmatch.handlers import merge_rasters, mask_rasters\nfrom spectralmatch.voronoi_center_seamline import voronoi_center_seamline\n\nworking_directory = '/Users/kanoalindiwe/Downloads/Projects/spectralmatch/docs/examples/data_worldview3' # If this does not automatically find the correct CWD, manually copy the path to the data_worldview3 folder\nprint(working_directory)\n\ninput_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"LocalMatch\")\nclipped_images = os.path.join(working_directory, \"ClippedImages\")\n\nwindow_size = 128\nnum_workers = 5\n</pre> import os import importlib  from spectralmatch.match.global_regression import global_regression from spectralmatch.match.local_block_adjustment import local_block_adjustment from spectralmatch.handlers import merge_rasters, mask_rasters from spectralmatch.voronoi_center_seamline import voronoi_center_seamline  working_directory = '/Users/kanoalindiwe/Downloads/Projects/spectralmatch/docs/examples/data_worldview3' # If this does not automatically find the correct CWD, manually copy the path to the data_worldview3 folder print(working_directory)  input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"GlobalMatch\") local_folder = os.path.join(working_directory, \"LocalMatch\") clipped_images = os.path.join(working_directory, \"ClippedImages\")  window_size = 128 num_workers = 5 In\u00a0[\u00a0]: Copied! <pre>saved_adjustments_path = os.path.join(global_folder, \"GlobalAdjustments.json\")\n\nglobal_regression(\n    input_folder,\n    (global_folder, \"_global\"),\n    custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    save_adjustments=saved_adjustments_path,\n    )\n</pre> saved_adjustments_path = os.path.join(global_folder, \"GlobalAdjustments.json\")  global_regression(     input_folder,     (global_folder, \"_global\"),     custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     save_adjustments=saved_adjustments_path,     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = [os.path.join(global_folder, f) for f in os.listdir(global_folder) if f.lower().endswith(\".tif\")]\n\nlocal_block_adjustment(\n    input_image_paths,\n    local_folder,\n    number_of_blocks=100,\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    save_block_maps=True,\n    )\n</pre> input_image_paths = [os.path.join(global_folder, f) for f in os.listdir(global_folder) if f.lower().endswith(\".tif\")]  local_block_adjustment(     input_image_paths,     local_folder,     number_of_blocks=100,     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     save_block_maps=True,     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = [os.path.join(global_folder, f) for f in os.listdir(global_folder) if f.lower().endswith(\".tif\")]\n\nold_local_folder = os.path.join(working_directory, \"LocalMatch\")\nnew_local_folder = os.path.join(working_directory, \"LocalMatch_New\")\n\nsaved_reference_block_path = os.path.join(old_local_folder, \"BlockReferenceMean\", \"BlockReferenceMean.tif\")\nsaved_local_block_paths = [os.path.join(os.path.join(old_local_folder, \"BlockLocalMean\"), f) for f in os.listdir(os.path.join(old_local_folder, \"BlockLocalMean\")) if f.lower().endswith(\".tif\")]\n\nlocal_block_adjustment(\n    input_image_paths,\n    new_local_folder,\n    number_of_blocks=100,\n    debug_logs=True,\n    window_size=window_size,\n    parallel_workers=num_workers,\n    load_block_maps=(saved_reference_block_path, saved_local_block_paths)\n    )\n</pre> input_image_paths = [os.path.join(global_folder, f) for f in os.listdir(global_folder) if f.lower().endswith(\".tif\")]  old_local_folder = os.path.join(working_directory, \"LocalMatch\") new_local_folder = os.path.join(working_directory, \"LocalMatch_New\")  saved_reference_block_path = os.path.join(old_local_folder, \"BlockReferenceMean\", \"BlockReferenceMean.tif\") saved_local_block_paths = [os.path.join(os.path.join(old_local_folder, \"BlockLocalMean\"), f) for f in os.listdir(os.path.join(old_local_folder, \"BlockLocalMean\")) if f.lower().endswith(\".tif\")]  local_block_adjustment(     input_image_paths,     new_local_folder,     number_of_blocks=100,     debug_logs=True,     window_size=window_size,     parallel_workers=num_workers,     load_block_maps=(saved_reference_block_path, saved_local_block_paths)     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = [os.path.join(local_folder, f) for f in os.listdir(local_folder) if f.lower().endswith(\".tif\")]\noutput_vector_mask = os.path.join(working_directory, \"ImageClips.gpkg\")\n\nvoronoi_center_seamline(\n    input_image_paths,\n    output_vector_mask,\n    image_field_name='image',\n    debug_logs=True,\n    )\n</pre> input_image_paths = [os.path.join(local_folder, f) for f in os.listdir(local_folder) if f.lower().endswith(\".tif\")] output_vector_mask = os.path.join(working_directory, \"ImageClips.gpkg\")  voronoi_center_seamline(     input_image_paths,     output_vector_mask,     image_field_name='image',     debug_logs=True,     ) In\u00a0[\u00a0]: Copied! <pre>input_image_paths = sorted([os.path.join(local_folder, f) for f in os.listdir(local_folder) if f.lower().endswith(\".tif\")])\noutput_clipped_image_paths = sorted([os.path.join(clipped_images, os.path.splitext(os.path.basename(path))[0] + \"_Clipped.tif\") for path in input_image_paths])\n\ninput_vector_mask_path = os.path.join(working_directory, \"ImageClips.gpkg\")\noutput_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")\n\nmask_rasters(\n    input_image_paths,\n    output_clipped_image_paths,\n    input_vector_mask_path,\n    tap=True,\n    debug_logs=True,\n    split_mask_by_attribute=\"image\",\n    window_size=window_size,\n    )\n\nmerge_rasters(\n    output_clipped_image_paths,\n    output_merged_image_path,\n    window_size=window_size,\n    debug_logs=True,\n)\n</pre> input_image_paths = sorted([os.path.join(local_folder, f) for f in os.listdir(local_folder) if f.lower().endswith(\".tif\")]) output_clipped_image_paths = sorted([os.path.join(clipped_images, os.path.splitext(os.path.basename(path))[0] + \"_Clipped.tif\") for path in input_image_paths])  input_vector_mask_path = os.path.join(working_directory, \"ImageClips.gpkg\") output_merged_image_path = os.path.join(working_directory, \"MergedImage.tif\")  mask_rasters(     input_image_paths,     output_clipped_image_paths,     input_vector_mask_path,     tap=True,     debug_logs=True,     split_mask_by_attribute=\"image\",     window_size=window_size,     )  merge_rasters(     output_clipped_image_paths,     output_merged_image_path,     window_size=window_size,     debug_logs=True, ) In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import (\n    compare_spatial_spectral_difference_individual_bands,\n    compare_image_spectral_profiles_pairs,\n    compare_image_spectral_profiles,\n    compare_spatial_spectral_difference_average)\n\ncompare_spatial_spectral_difference_individual_bands(\n    (\n    '/image/a.tif',\n    '/image/b.tif'),\n    '/output.png'\n)\n\n\ncompare_image_spectral_profiles_pairs(\n    {\n        'Image A': [\n            '/image/before/a.tif',\n            'image/after/a.tif'\n        ],\n        'Image B': [\n            '/image/before/b.tif',\n            '/image/after/b.tif'\n        ]\n    },\n    '/output.png'\n)\n\n\ncompare_image_spectral_profiles(\n    {\n        'Image A': 'image/a.tif',\n        'Image B': '/image/b.tif'\n    },\n    \"/output.png\",\n    \"Digital Number Spectral Profile Comparison\",\n    'Band',\n    'Digital Number(0-2,047)',\n\n)\n\n\ncompare_spatial_spectral_difference_average(\n    [\n        '/image/a.tif',\n        '/image/a.tif'\n     ],\n    '/output.png'\n)\n</pre> from spectralmatch import (     compare_spatial_spectral_difference_individual_bands,     compare_image_spectral_profiles_pairs,     compare_image_spectral_profiles,     compare_spatial_spectral_difference_average)  compare_spatial_spectral_difference_individual_bands(     (     '/image/a.tif',     '/image/b.tif'),     '/output.png' )   compare_image_spectral_profiles_pairs(     {         'Image A': [             '/image/before/a.tif',             'image/after/a.tif'         ],         'Image B': [             '/image/before/b.tif',             '/image/after/b.tif'         ]     },     '/output.png' )   compare_image_spectral_profiles(     {         'Image A': 'image/a.tif',         'Image B': '/image/b.tif'     },     \"/output.png\",     \"Digital Number Spectral Profile Comparison\",     'Band',     'Digital Number(0-2,047)',  )   compare_spatial_spectral_difference_average(     [         '/image/a.tif',         '/image/a.tif'      ],     '/output.png' )"}]}