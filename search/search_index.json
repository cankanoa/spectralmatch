{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"spectralmatch: A toolkit for performing Relative Radiometric Normalization, with utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, and statistics","text":"<p>[!IMPORTANT] This library is experimental and still under heavy development.</p>"},{"location":"#overview","title":"Overview","text":"<p>spectralmatch provides a Python library and QGIS plugin with multiple algorythms to perform Relative Radiometric Normalization (RRN). It also includes utilities for generating seamlines, cloud masks, Pseudo-Invariant Features, statistics, preprocessing, and more.</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p>Automated: Works without manual intervention, making it ideal for large-scale applications.</p> </li> <li> <p>Consistent Multi-Image Analysis: Ensures uniformity across images by applying systematic corrections with minimal spectral distortion.</p> </li> <li> <p>Seamlessly Blended: Creates smooth transitions between images without visible seams.</p> </li> <li> <p>Unit Agnostic: Works with any pixel unit and preserves the spectral information for accurate analysis. This inlcludes negative numbers and reflectance.</p> </li> <li> <p>Better Input for Machine Learning Models: Provides high-quality, unbiased data for AI and analytical workflows.</p> </li> <li> <p>Minimizes Color Bias: Avoids excessive color normalization and does not rely on a strict reference image.</p> </li> <li> <p>Sensor Agnostic: Works with all optical sensors. In addition, images from differnt sensors can be combined for multisensor analysis.</p> </li> <li> <p>Parallel Processing: Optimized for modern CPUs to handle large datasets efficiently.</p> </li> <li> <p>Large-Scale Mosaics: Designed to process and blend vast image collections effectively.</p> </li> <li>Time Series: Normalize images across time with to compare spectral changes.</li> </ul>"},{"location":"#current-matching-algorithms","title":"Current Matching Algorithms","text":""},{"location":"#global-to-local-matching","title":"Global to local matching","text":"<p>This technique is derived from 'An auto-adapting global-to-local color balancing method for optical imagery mosaic' by Yu et al., 2017 (DOI: 10.1016/j.isprsjprs.2017.08.002). It is particularly useful for very high-resolution imagery (satellite or otherwise) and works in a two phase process. First, this method applies least squares regression to estimate scale and offset parameters that align the histograms of all images toward a shared spectral center. This is achieved by constructing a global model based on the overlapping areas of adjacent images, where the spectral relationships are defined. This global model ensures that each image conforms to a consistent radiometric baseline while preserving overall color fidelity. However, global correction alone cannot capture intra-image variability so a second local adjustment phase is performed. The overlap areas are divided into smaller blocks, and each block\u2019s mean is used to fine-tune the color correction. This block-wise tuning helps maintain local contrast and reduces visible seams, resulting in seamless and spectrally consistent mosaics with minimal distortion.</p> <p> Shows the average spectral profile of two WorldView 3 images before and after global to local matching.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<ul> <li> <p>Consistent Spectral Profile: The true spectral response of overlapping areas remains the same throughout the images.</p> </li> <li> <p>Least Squares Modeling: A least squares approach can effectively model and fit all images' spectral profiles.</p> </li> <li> <p>Scale and Offset Adjustment: Applying scale and offset corrections can effectively harmonize images.</p> </li> <li> <p>Minimized Color Differences: The best color correction is achieved when color differences are minimized.</p> </li> <li> <p>Geometric Alignment: Images are assumed to be geometrically aligned with known relative positions.</p> </li> <li> <p>Global Consistency: Overlapping color differences are consistent across the entire image.</p> </li> <li> <p>Local Adjustments: Block-level color differences result from the global application of adjustments.</p> </li> </ul>"},{"location":"#installation-with-pypi-and-use-as-a-python-library","title":"Installation with Pypi and use as a Python Library","text":""},{"location":"#1-system-requirements","title":"1. System requirements","text":"<p>Before installing, ensure you have the following system-level prerequisites:</p> <ul> <li>Python \u2265 3.10</li> <li>PROJ \u2265 9.3</li> <li>GDAL \u2265 3.6</li> </ul> <p>An easy way to install these dependancies is to use Miniconda: <pre><code>conda create -n spectralmatch python&gt;=3.10 gdal&gt;=3.6 proj&gt;=9.3 -c conda-forge\nconda activate spectralmatch\n</code></pre></p>"},{"location":"#2-install-spectralmatch-via-pypi-or-source","title":"2. Install spectralmatch (via PyPI or Source)","text":"<p>The recommended way to install is via PyPI. (this method installs only the core code as a library):</p> <pre><code>pip install spectralmatch\n</code></pre> <p>Another install method is to clone the repository and confugure the dependancies with <code>pyproject.toml</code>. (this method installs the whole repository for development or customization):</p> <pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\npip install .\n</code></pre>"},{"location":"#3-run-example-code-and-modify-for-use-optional","title":"3. Run example code and modify for use (optional)","text":"<p>Example scripts are provided to verify a successful installation and help you get started quickly:</p> <ul> <li>Global to local: <code>docs/examples/example_global_to_local.py</code></li> </ul>"},{"location":"#install-and-use-as-a-qgis-plugin","title":"Install and use as a QGIS Plugin","text":""},{"location":"#1-download-and-install-qgis","title":"1. Download and install QGIS","text":""},{"location":"#2-open-qgis","title":"2.  Open QGIS","text":""},{"location":"#3-go-to-plugins-manage-and-install-plugins","title":"3.  Go to Plugins \u2192 Manage and Install Plugins\u2026","text":""},{"location":"#4-find-spectralmatch-in-the-list-install-and-enable-it","title":"4.  Find spectralmatch in the list, install, and enable it","text":""},{"location":"#5-find-the-plugin-in-the-processing-toolbox","title":"5.  Find the plugin in the Processing Toolbox","text":""},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at spectralmatch.github.io/spectralmatch/.</p>"},{"location":"#contributing-guide","title":"Contributing Guide","text":"<p>We welcome all contributions the project! To get started: 1. Create an issue with the appropriate label describing the feature or improvement. Provide relevant context, desired timeline, any assistance needed, who will be responsible for the work, anticipated results, and any other details. 2. Fork the repository and create a new feature branch. 3. Make your changes and add any necessary tests. 4. Open a Pull Request against the main repository.</p>"},{"location":"#developer-guide","title":"Developer Guide","text":"<ol> <li> <p>Clone the Repository <pre><code>git clone https://github.com/spectralmatch/spectralmatch.git\ncd spectralmatch\n</code></pre></p> </li> <li> <p>Install with Dev andor Docs Extras</p> </li> </ol> <p>There are additional <code>[dev]</code> and <code>[docs]</code> dependancies specified in <code>pyproject.toml</code>:</p> <pre><code>pip install -e \".[dev]\"   # for developer dependencies\npip install -e \".[docs]\"  # for documentation dependencies\n</code></pre> <ol> <li>Set Up Pre-commit Hooks</li> </ol> <p>To maintain code consistency before each commit install these hooks:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>"},{"location":"#testing","title":"Testing","text":"<p>pytest is used for testing. Tests will automatically be run when merging into main but they can also be run locally via:</p> <pre><code>pytest\n</code></pre> <p>Run tests for a specific file or function:</p> <pre><code>pytest folder/file.py\n</code></pre>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See LICENSE for details.</p>"},{"location":"installation/","title":"Installation","text":"<p>...</p>"},{"location":"api/handlers/","title":"Handlers","text":""},{"location":"api/handlers/#spectralmatch.handlers.write_vector","title":"<code>write_vector(mem_ds, output_vector_path)</code>","text":"<p>Writes an in-memory vector datasource to disk. The driver is chosen based on the file extension of output_vector_path. All layers, including metadata, schema, and features, are preserved.</p> Source code in <code>spectralmatch/handlers.py</code> <pre><code>def write_vector(\n    mem_ds: ogr.DataSource,\n    output_vector_path: str\n    ) -&gt; None:\n\n    \"\"\"\n    Writes an in-memory vector datasource to disk.\n    The driver is chosen based on the file extension of output_vector_path.\n    All layers, including metadata, schema, and features, are preserved.\n    \"\"\"\n    # Map file extensions to OGR driver names for common vector formats.\n    driver_mapping = {\n        '.shp': 'ESRI Shapefile',\n        '.geojson': 'GeoJSON',\n        '.gpkg': 'GPKG'\n    }\n    ext = os.path.splitext(output_vector_path)[1].lower()\n    driver_name = driver_mapping.get(ext, 'GeoJSON')  # Fallback to GeoJSON if unknown.\n\n    driver = ogr.GetDriverByName(driver_name)\n    if driver is None:\n        raise RuntimeError(f\"No driver found for extension: {ext}\")\n\n    # If the output file already exists, delete it.\n    if os.path.exists(output_vector_path):\n        driver.DeleteDataSource(output_vector_path)\n\n    out_ds = driver.CreateDataSource(output_vector_path)\n    if out_ds is None:\n        raise RuntimeError(f\"Could not create output vector dataset: {output_vector_path}\")\n\n    # Loop over every layer in the in-memory datasource and copy it.\n    for i in range(mem_ds.GetLayerCount()):\n        mem_layer = mem_ds.GetLayerByIndex(i)\n        layer_name = mem_layer.GetName()\n        srs = mem_layer.GetSpatialRef()\n        geom_type = mem_layer.GetGeomType()\n\n        out_layer = out_ds.CreateLayer(layer_name, srs, geom_type)\n\n        # Copy field definitions\n        mem_defn = mem_layer.GetLayerDefn()\n        for j in range(mem_defn.GetFieldCount()):\n            field_defn = mem_defn.GetFieldDefn(j)\n            out_layer.CreateField(field_defn)\n\n        # Copy features (including geometry, fields, and feature-level metadata)\n        mem_layer.ResetReading()\n        for feat in mem_layer:\n            out_feat = ogr.Feature(out_layer.GetLayerDefn())\n            out_feat.SetGeometry(feat.GetGeometryRef().Clone())\n            for j in range(mem_defn.GetFieldCount()):\n                field_name = mem_defn.GetFieldDefn(j).GetNameRef()\n                out_feat.SetField(field_name, feat.GetField(j))\n            out_layer.CreateFeature(out_feat)\n            out_feat = None\n    out_ds.Destroy()\n</code></pre>"},{"location":"api/mask/","title":"Masking","text":""},{"location":"api/mask/#spectralmatch.mask.post_process_raster_cloud_mask_to_vector","title":"<code>post_process_raster_cloud_mask_to_vector(input_image_path, minimum_mask_size_percentile=None, polygon_buffering_in_map_units=None, value_mapping=None)</code>","text":"<p>Vectorizes a cloud mask raster and post-processes the polygons.</p> <p>Parameters: input_image (str): Path to the input mask raster (e.g., a TIFF). minimum_mask_size_percentile (float, optional): Percentile threshold; polygons whose area is below this percentile are removed. If None, no area-based filtering is applied. polygon_buffering_in_map_units (dict, optional): A dictionary mapping a polygon's 'value' attribute (from vectorization) to a buffering distance in map units. For example: {0: 5, 1: 30} buffers polygons with value 0 by 5 units and those with value 1 by 30 units. If a polygon's value is not in the dictionary, its geometry remains unchanged. value_mapping (dict, optional): A dictionary mapping original pixel values to new group values. For example: {1: 1, 2: 1, 3: 1} clusters pixels with values 1, 2, and 3 together.</p> <p>Returns: ogr.DataSource: An in-memory GDAL vector datasource containing the processed polygon features.</p> <p>The function performs: 1. Reading the first band of the raster mask. 2. Optional value mapping. 3. Vectorization of the raster into polygons. 4. (Optional) Removal of polygons with areas below the given percentile. 5. Buffering for each polygon based on the provided dictionary. 6. Merging of overlapping polygons with the same \"value\". 7. Conversion into an in-memory GDAL vector datasource.</p> Source code in <code>spectralmatch/mask.py</code> <pre><code>def post_process_raster_cloud_mask_to_vector(\n    input_image_path: str,\n    minimum_mask_size_percentile: float = None,\n    polygon_buffering_in_map_units: dict = None,\n    value_mapping: dict = None\n    ) -&gt; ogr.DataSource:\n\n    \"\"\"\n    Vectorizes a cloud mask raster and post-processes the polygons.\n\n    Parameters:\n    input_image (str): Path to the input mask raster (e.g., a TIFF).\n    minimum_mask_size_percentile (float, optional): Percentile threshold; polygons whose area is below\n    this percentile are removed. If None, no area-based filtering is applied.\n    polygon_buffering_in_map_units (dict, optional): A dictionary mapping a polygon's 'value' attribute\n    (from vectorization) to a buffering distance in map units.\n    For example: {0: 5, 1: 30} buffers polygons with value 0 by 5 units and those with value 1 by 30 units.\n    If a polygon's value is not in the dictionary, its geometry remains unchanged.\n    value_mapping (dict, optional): A dictionary mapping original pixel values to new group values.\n    For example: {1: 1, 2: 1, 3: 1} clusters pixels with values 1, 2, and 3 together.\n\n    Returns:\n    ogr.DataSource: An in-memory GDAL vector datasource containing the processed polygon features.\n\n    The function performs:\n    1. Reading the first band of the raster mask.\n    2. Optional value mapping.\n    3. Vectorization of the raster into polygons.\n    4. (Optional) Removal of polygons with areas below the given percentile.\n    5. Buffering for each polygon based on the provided dictionary.\n    6. Merging of overlapping polygons with the same \"value\".\n    7. Conversion into an in-memory GDAL vector datasource.\n    \"\"\"\n    # --- Step 1: Read the raster mask ---\n    with rasterio.open(input_image_path) as src:\n        raster_data = src.read(1)\n        transform = src.transform\n        crs = src.crs  # Rasterio CRS (usually a pyproj CRS)\n\n    # --- Step 2: Apply optional value mapping ---\n    if value_mapping is not None:\n        mapped = np.copy(raster_data)\n        for orig_value, new_value in value_mapping.items():\n            mapped[raster_data == orig_value] = new_value\n        raster_data = mapped\n\n    # --- Step 3: Vectorize the raster ---\n    results = (\n        {'properties': {'value': v}, 'geometry': s}\n        for s, v in shapes(raster_data, transform=transform, connectivity=4)\n    )\n    features = list(results)\n    if not features:\n        print(\"No features were detected in the raster mask.\")\n        return None\n\n    # Create a GeoDataFrame from the vectorized features.\n    gdf = gpd.GeoDataFrame.from_features(features, crs=crs)\n\n    # --- Step 4: Compute areas and, if requested, filter out small polygons ---\n    gdf['area'] = gdf.geometry.area\n    if minimum_mask_size_percentile is not None:\n        area_threshold = np.percentile(gdf['area'], minimum_mask_size_percentile)\n        print(f\"Area threshold (at {minimum_mask_size_percentile}th percentile): {area_threshold:.2f}\")\n        gdf = gdf[gdf['area'] &gt;= area_threshold].copy()\n\n    # --- Step 5: Apply buffering per polygon based on the provided dictionary ---\n    if polygon_buffering_in_map_units is not None:\n        gdf['geometry'] = gdf.apply(\n            lambda row: row['geometry'].buffer(polygon_buffering_in_map_units.get(row['value'], 0))\n            if row['value'] in polygon_buffering_in_map_units else row['geometry'],\n            axis=1\n        )\n\n    # --- Step 6: Merge overlapping polygons by 'value' ---\n    # Group by the 'value' attribute and merge (union) polygons within each group.\n    merged_features = []\n    for val, group in gdf.groupby('value'):\n        # Use union_all() to merge the geometries within the group.\n        # (Requires Shapely 2.0 or later; otherwise use shapely.ops.unary_union on group.geometry.tolist())\n        union_geom = group.geometry.union_all()\n        # If the union produces a single Polygon, add it directly;\n        # if it produces a MultiPolygon, split it into individual features.\n        if union_geom.geom_type == 'Polygon':\n            merged_features.append({'value': val, 'geometry': union_geom})\n        elif union_geom.geom_type == 'MultiPolygon':\n            for geom in union_geom.geoms:\n                merged_features.append({'value': val, 'geometry': geom})\n        else:\n            # In case of unexpected geometry types, skip or handle accordingly.\n            print(f\"Unexpected geometry type for value {val}: {union_geom.geom_type}\")\n    # Create a new GeoDataFrame from merged features.\n    gdf = gpd.GeoDataFrame(merged_features, crs=gdf.crs)\n\n    # --- Step 7: Convert the GeoDataFrame to an in-memory GDAL vector datasource ---\n    ogr_driver = ogr.GetDriverByName(\"Memory\")\n    mem_ds = ogr_driver.CreateDataSource(\"in_memory\")\n\n    # Determine an appropriate OGR geometry type using the first feature.\n    first_geom = gdf.geometry.iloc[0]\n    if first_geom.geom_type == \"Polygon\":\n        ogr_geom_type = ogr.wkbPolygon\n    elif first_geom.geom_type == \"MultiPolygon\":\n        ogr_geom_type = ogr.wkbMultiPolygon\n    else:\n        ogr_geom_type = ogr.wkbUnknown\n\n    # Convert the CRS to OGR SpatialReference.\n    sr = osr.SpatialReference()\n    try:\n        sr.ImportFromWkt(crs.to_wkt())\n    except AttributeError:\n        sr.ImportFromEPSG(4326)\n\n    mem_layer = mem_ds.CreateLayer(\"post_processed\", sr, ogr_geom_type)\n\n    # Add attribute field for 'value' (and any other non-geometry columns if needed).\n    # Here we add 'value' for example.\n    field_defn = ogr.FieldDefn(\"value\", ogr.OFTInteger)\n    mem_layer.CreateField(field_defn)\n    # Optionally, add other fields (e.g. 'area') if desired.\n\n    # Add each row from the GeoDataFrame as an OGR feature.\n    for idx, row in gdf.iterrows():\n        feat = ogr.Feature(mem_layer.GetLayerDefn())\n        ogr_geom = ogr.CreateGeometryFromWkt(row['geometry'].wkt)\n        feat.SetGeometry(ogr_geom)\n        feat.SetField(\"value\", row['value'])\n        mem_layer.CreateFeature(feat)\n        feat = None\n\n    return mem_ds\n</code></pre>"},{"location":"api/match/","title":"Matching Algorithms","text":""},{"location":"api/match/#spectralmatch.match.global_regression.global_regression","title":"<code>global_regression(input_image_paths, output_image_folder, *, custom_mean_factor=1.0, custom_std_factor=1.0, output_global_basename='_global', vector_mask_path=None, tile_width_and_height_tuple=None, debug_mode=False, custom_nodata_value=None, parallel=False, max_workers=None, calc_dtype='float32')</code>","text":"<p>Matches multiple input raster images to a common global statistical range using overlapping areas for deriving statistical adjustments. Adjustments include mean and standard deviation factors, ensuring the images are globally consistent in derived values.</p> <p>This function processes pairs of overlapping raster images to compute statistical parameters, combines global statistics for the entire collection of raster images, and generates output raster images with adjusted pixel values. Additional features such as custom nodata values, vector mask usage, and tiling are supported. The function allows parallel processing to optimize performance.</p> <p>Args: input_image_paths (List[str]): Paths to input raster images. output_image_folder (str): Directory where adjusted images will be saved. custom_mean_factor (float): Scale factor for mean adjustment, default is 1.0. custom_std_factor (float): Scale factor for standard deviation adjustment, default is 1.0. output_global_basename (str): Global basename suffix added to output image filenames, default is \"_global\". vector_mask_path (Optional[str]): Path to a vector mask file used to limit processing, optional. tile_width_and_height_tuple (Optional[Tuple[int, int]]): Tuple specifying tile width and height for tiled processing, optional. debug_mode (bool): Enables debug mode when set to True, default is False. custom_nodata_value (float | None): Override nodata value for rasters, optional. parallel (bool): Enables parallel processing when set to True, default is False. max_workers (int | None): Maximum number of workers for parallel processing, default is None. calc_dtype (str): Data type used for intermediate calculations, default is \"float32\".</p> <p>Returns: List[str]: Paths to the output adjusted raster images.</p> Source code in <code>spectralmatch/match/global_regression.py</code> <pre><code>def global_regression(\n    input_image_paths: List[str],\n    output_image_folder: str,\n    *,\n    custom_mean_factor: float = 1.0,\n    custom_std_factor: float = 1.0,\n    output_global_basename: str = \"_global\",\n    vector_mask_path: Optional[str] = None,\n    tile_width_and_height_tuple: Optional[Tuple[int, int]] = None,\n    debug_mode: bool = False,\n    custom_nodata_value: float | None = None,\n    parallel: bool = False,\n    max_workers: int | None = None,\n    calc_dtype: str = \"float32\",\n    ):\n\n    \"\"\"\n    Matches multiple input raster images to a common global statistical range using overlapping areas\n    for deriving statistical adjustments. Adjustments include mean and standard deviation factors, ensuring\n    the images are globally consistent in derived values.\n\n    This function processes pairs of overlapping raster images to compute statistical parameters, combines\n    global statistics for the entire collection of raster images, and generates output raster images with\n    adjusted pixel values. Additional features such as custom nodata values, vector mask usage, and tiling\n    are supported. The function allows parallel processing to optimize performance.\n\n    Args:\n    input_image_paths (List[str]): Paths to input raster images.\n    output_image_folder (str): Directory where adjusted images will be saved.\n    custom_mean_factor (float): Scale factor for mean adjustment, default is 1.0.\n    custom_std_factor (float): Scale factor for standard deviation adjustment, default is 1.0.\n    output_global_basename (str): Global basename suffix added to output image filenames, default is \"_global\".\n    vector_mask_path (Optional[str]): Path to a vector mask file used to limit processing, optional.\n    tile_width_and_height_tuple (Optional[Tuple[int, int]]): Tuple specifying tile width and height for tiled processing, optional.\n    debug_mode (bool): Enables debug mode when set to True, default is False.\n    custom_nodata_value (float | None): Override nodata value for rasters, optional.\n    parallel (bool): Enables parallel processing when set to True, default is False.\n    max_workers (int | None): Maximum number of workers for parallel processing, default is None.\n    calc_dtype (str): Data type used for intermediate calculations, default is \"float32\".\n\n    Returns:\n    List[str]: Paths to the output adjusted raster images.\n    \"\"\"\n    print(\"Start global matching\")\n\n    _check_raster_requirements(input_image_paths, debug_mode)\n\n    nodata_val = _get_nodata_value(input_image_paths, custom_nodata_value)\n\n    if debug_mode: print(\"Calculating statistics\")\n    with rasterio.open(input_image_paths[0]) as src: num_bands = src.count\n    num_images = len(input_image_paths)\n\n    all_bounds = {}\n    for idx, p in enumerate(input_image_paths):\n        with rasterio.open(p) as ds:\n            all_bounds[idx] = ds.bounds\n\n    overlapping_pairs = _find_overlaps(all_bounds)\n\n    all_overlap_stats = {}\n    for id_i, id_j in overlapping_pairs:\n        stats = _calculate_overlap_stats(\n            num_bands,\n            input_image_paths[id_i],\n            input_image_paths[id_j],\n            id_i,\n            id_j,\n            all_bounds[id_i],\n            all_bounds[id_j],\n            nodata_val,\n            nodata_val,\n            vector_mask_path=vector_mask_path,\n            tile_width_and_height_tuple=tile_width_and_height_tuple,\n            debug_mode=debug_mode,\n        )\n        all_overlap_stats.update(\n            {\n                k_i: {\n                    **all_overlap_stats.get(k_i, {}),\n                    **{\n                        k_j: {**all_overlap_stats.get(k_i, {}).get(k_j, {}), **s}\n                        for k_j, s in v.items()\n                    },\n                }\n                for k_i, v in stats.items()\n            }\n        )\n\n    all_whole_stats = {}\n    for idx, path in enumerate(input_image_paths):\n        all_whole_stats.update(\n            _calculate_whole_stats(\n                input_image_path=path,\n                nodata=nodata_val,\n                num_bands=num_bands,\n                image_id=idx,\n                vector_mask_path=vector_mask_path,\n                tile_width_and_height_tuple=tile_width_and_height_tuple,\n            )\n        )\n\n    all_params = np.zeros((num_bands, 2 * num_images, 1), dtype=float)\n    for b in range(num_bands):\n        if debug_mode: print(f\"Processing band {b} for {num_images} images\")\n\n        A, y, tot_overlap = [], [], 0\n        for i in range(num_images):\n\n            for j in range(i + 1, num_images):\n                stat = all_overlap_stats.get(i, {}).get(j)\n                if stat is None:\n                    continue\n                s = stat[b][\"size\"]\n                m1, v1 = stat[b][\"mean\"], stat[b][\"std\"]\n                m2, v2 = (\n                    all_overlap_stats[j][i][b][\"mean\"],\n                    all_overlap_stats[j][i][b][\"std\"],\n                )\n                row_m = [0] * (2 * num_images)\n                row_s = [0] * (2 * num_images)\n                row_m[2 * i : 2 * i + 2] = [m1, 1]\n                row_m[2 * j : 2 * j + 2] = [-m2, -1]\n                row_s[2 * i], row_s[2 * j] = v1, -v2\n                A.extend(\n                    [\n                        [v * s * custom_mean_factor for v in row_m],\n                        [v * s * custom_std_factor for v in row_s],\n                    ]\n                )\n                y.extend([0, 0])\n                tot_overlap += s\n        pjj = 1.0 if tot_overlap == 0 else tot_overlap / (2.0 * num_images)\n        for j in range(num_images):\n            mj = all_whole_stats[j][b][\"mean\"]\n            vj = all_whole_stats[j][b][\"std\"]\n            row_m = [0] * (2 * num_images)\n            row_s = [0] * (2 * num_images)\n            row_m[2 * j : 2 * j + 2] = [mj * pjj, 1 * pjj]\n            row_s[2 * j] = vj * pjj\n            A.extend([row_m, row_s])\n            y.extend([mj * pjj, vj * pjj])\n\n        A_arr = np.asarray(A)\n        y_arr = np.asarray(y)\n        res = least_squares(lambda p: np.asarray(A) @ p - np.asarray(y), [1, 0] * num_images)\n        if debug_mode:\n            overlap_pairs = overlapping_pairs\n            _print_constraint_system(\n                constraint_matrix=A_arr,\n                adjustment_params=res.x,\n                observed_values_vector=y_arr,\n                overlap_pairs=overlap_pairs,\n                num_images=num_images,\n            )\n\n        all_params[b] = res.x.reshape((2 * num_images, 1))\n\n    img_dir = os.path.join(output_image_folder, \"Images\")\n    if not os.path.exists(img_dir): os.makedirs(img_dir)\n    out_paths: List[str] = []\n\n    if parallel and max_workers is None:\n        max_workers = mp.cpu_count()\n\n    for img_idx, img_path in enumerate(input_image_paths):\n        base = os.path.splitext(os.path.basename(img_path))[0]\n        out_path = os.path.join(img_dir, f\"{base}{output_global_basename}.tif\")\n        out_paths.append(str(out_path))\n\n        if debug_mode: print(f\"Apply adjustments and saving results for {base}\")\n        with rasterio.open(img_path) as src:\n            meta = src.meta.copy()\n            meta.update({\"count\": num_bands, \"nodata\": nodata_val})\n            with rasterio.open(out_path, \"w\", **meta) as dst:\n\n                if tile_width_and_height_tuple:\n                    tw, th = tile_width_and_height_tuple\n                    windows = list(_create_windows(src.width, src.height, tw, th))\n                else:\n                    windows = [Window(0, 0, src.width, src.height)]\n\n                if parallel:\n                    ctx = _choose_context(prefer_fork=True)\n                    pool = ProcessPoolExecutor(\n                        max_workers=max_workers,\n                        mp_context=ctx,\n                        initializer=_init_worker,\n                        initargs=(img_path,),\n                    )\n\n                for b in range(num_bands):\n                    a = all_params[b, 2 * img_idx, 0]\n                    b0 = all_params[b, 2 * img_idx + 1, 0]\n\n                    if parallel:\n                        futs = [\n                            pool.submit(_process_tile_global,\n                                        w,\n                                        b,\n                                        a,\n                                        b0,\n                                        nodata_val,\n                                        calc_dtype,\n                                        debug_mode,\n                                        )\n                            for w in windows\n                        ]\n                        for fut in as_completed(futs):\n                            win, buf = fut.result()\n                            dst.write(buf.astype(meta[\"dtype\"]), b + 1, window=win)\n                    else:\n                        for win in windows:\n                            _, buf = _process_tile_global(\n                                win,\n                                b,\n                                a,\n                                b0,\n                                nodata_val,\n                                debug_mode,\n                            )\n                            dst.write(buf.astype(meta[\"dtype\"]), b + 1, window=win)\n                if parallel:\n                    pool.shutdown()\n\n    print(\"Finished global matching\")\n    return out_paths\n</code></pre>"},{"location":"api/match/#spectralmatch.match.local_block_adjustment.local_block_adjustment","title":"<code>local_block_adjustment(input_image_paths, output_image_folder, *, output_local_basename='_local', custom_nodata_value=None, target_blocks_per_image=100, alpha=1.0, calculation_dtype_precision='float32', output_dtype='float32', projection='EPSG:4326', debug_mode=False, tile_width_and_height_tuple=None, correction_method='gamma', parallel=False, max_workers=None)</code>","text":"<p>Matches histograms of input raster images using local histogram matching approach. This function processes raster images, adjusts their histograms locally based on reference blocks, and saves the corrected images to the specified output directory. The procedure operates block-wise on the raster images for local corrections and supports parallel execution for performance optimization.</p> <p>Args: input_image_paths (List[str]): A list of paths to input raster image files. output_image_folder (str): Directory path where the output images will be saved. output_local_basename (str): Suffix for the output filenames indicating local histogram matching, default is \"_local\". custom_nodata_value (float | None): Custom value to represent no data areas; if None, it is auto-detected from input rasters. target_blocks_per_image (int): Approximate number of blocks to divide each raster for local histogram matching, default is 100. alpha (float): Scaling factor for adjustment when applying histogram corrections, default is 1.0 (no scaling). calculation_dtype_precision (str): The data type precision used internally for corrections, default is \"float32\". output_dtype (str): Data type of the output images, default is \"float32\". projection (str): Coordinate reference system for the output rasters, default is \"EPSG:4326\". debug_mode (bool): Flag to enable saving intermediate block map for debugging, default is False. tile_width_and_height_tuple (Optional[Tuple[int, int]]): Optional tuple specifying the width and height of tiles for processing input raster, default is None. correction_method (Literal[\"gamma\", \"linear\"]): Method for histogram correction, either \"gamma\" or \"linear.\" Default is \"gamma\". parallel (bool): If True, enables parallel processing for higher efficiency, default is False. max_workers (int | None): Limits the number of parallel workers, default is None (uses system CPU count if parallel is True).</p> <p>Returns: List[str]: List of file paths to the output raster images that have been locally histogram-matched.</p> Source code in <code>spectralmatch/match/local_block_adjustment.py</code> <pre><code>def local_block_adjustment(\n    input_image_paths: List[str],\n    output_image_folder: str,\n    *,\n    output_local_basename: str = \"_local\",\n    custom_nodata_value: float | None = None,\n    target_blocks_per_image: int = 100,\n    alpha: float = 1.0,\n    calculation_dtype_precision: str = \"float32\",\n    output_dtype: str = \"float32\",\n    projection: str = \"EPSG:4326\",\n    debug_mode: bool = False,\n    tile_width_and_height_tuple: Optional[Tuple[int, int]] = None,\n    correction_method: Literal[\"gamma\", \"linear\"] = \"gamma\",\n    parallel: bool = False,\n    max_workers: int | None = None,\n    ):\n\n    \"\"\"\n    Matches histograms of input raster images using local histogram matching approach.\n    This function processes raster images, adjusts their histograms locally based on\n    reference blocks, and saves the corrected images to the specified output directory.\n    The procedure operates block-wise on the raster images for local corrections and\n    supports parallel execution for performance optimization.\n\n    Args:\n    input_image_paths (List[str]): A list of paths to input raster image files.\n    output_image_folder (str): Directory path where the output images will be saved.\n    output_local_basename (str): Suffix for the output filenames indicating local\n    histogram matching, default is \"_local\".\n    custom_nodata_value (float | None): Custom value to represent no data areas;\n    if None, it is auto-detected from input rasters.\n    target_blocks_per_image (int): Approximate number of blocks to divide each\n    raster for local histogram matching, default is 100.\n    alpha (float): Scaling factor for adjustment when applying histogram corrections,\n    default is 1.0 (no scaling).\n    calculation_dtype_precision (str): The data type precision used internally\n    for corrections, default is \"float32\".\n    output_dtype (str): Data type of the output images, default is \"float32\".\n    projection (str): Coordinate reference system for the output rasters,\n    default is \"EPSG:4326\".\n    debug_mode (bool): Flag to enable saving intermediate block map for debugging,\n    default is False.\n    tile_width_and_height_tuple (Optional[Tuple[int, int]]): Optional tuple\n    specifying the width and height of tiles for processing input raster,\n    default is None.\n    correction_method (Literal[\"gamma\", \"linear\"]): Method for histogram correction,\n    either \"gamma\" or \"linear.\" Default is \"gamma\".\n    parallel (bool): If True, enables parallel processing for higher efficiency,\n    default is False.\n    max_workers (int | None): Limits the number of parallel workers, default is\n    None (uses system CPU count if parallel is True).\n\n    Returns:\n    List[str]: List of file paths to the output raster images that have been\n    locally histogram-matched.\n    \"\"\"\n    print(\"Start local matching\")\n    _check_raster_requirements(input_image_paths, debug_mode)\n\n    nodata_val = _get_nodata_value(input_image_paths, custom_nodata_value)\n    if debug_mode: print(f\"Global nodata value: {nodata_val}\")\n\n    out_img_dir = os.path.join(output_image_folder, \"Images\")\n    if not os.path.exists(out_img_dir): os.makedirs(out_img_dir)\n\n    bounding_rect = _get_bounding_rectangle(input_image_paths)\n    M, N = _compute_block_size(input_image_paths, target_blocks_per_image, bounding_rect)\n    # M, N = _compute_mosaic_coefficient_of_variation(input_image_paths, global_nodata_value) # Aproach from the paper to compute bock size\n\n    with rasterio.open(input_image_paths[0]) as ds:\n        num_bands = ds.count\n\n    if debug_mode: print(\"Computing global reference block map\")\n    block_ref_mean, _ = _compute_blocks(\n        input_image_paths,\n        bounding_rect,\n        M,\n        N,\n        num_bands,\n        nodata_value=nodata_val,\n        tile_width_and_height_tuple=tile_width_and_height_tuple,\n    )\n\n    if debug_mode:\n        _download_block_map(\n            block_map=np.nan_to_num(block_ref_mean, nan=nodata_val),\n            bounding_rect=bounding_rect,\n            output_image_path= os.path.join(output_image_folder, \"BlockReferenceMean\", \"BlockReferenceMean.tif\"),\n            nodata_value=nodata_val,\n            projection=projection,\n        )\n\n    if parallel and max_workers is None:\n        max_workers = mp.cpu_count()\n\n    out_paths: List[str] = []\n    for img_path in input_image_paths:\n        in_name = os.path.splitext(os.path.basename(img_path))[0]\n        out_name = os.path.splitext(os.path.basename(img_path))[0] + output_local_basename\n        out_path = os.path.join(out_img_dir, f\"{out_name}.tif\")\n        out_paths.append(str(out_path))\n\n        if debug_mode: print(f\"Processing {in_name}\")\n        if debug_mode: print(f\"Computing local block map\")\n        block_loc_mean, block_loc_count = _compute_blocks(\n            [img_path],\n            bounding_rect,\n            M,\n            N,\n            num_bands,\n            nodata_value=nodata_val,\n            tile_width_and_height_tuple=tile_width_and_height_tuple,\n        )\n\n        # block_local_mean = _smooth_array(block_local_mean, nodata_value=global_nodata_value)\n\n        if debug_mode:\n            _download_block_map(\n                block_map=np.nan_to_num(block_loc_mean, nan=nodata_val),\n                bounding_rect=bounding_rect,\n                output_image_path=os.path.join(output_image_folder, \"BlockLocalMean\", f\"{out_name}_BlockLocalMean.tif\"),\n                nodata_value=nodata_val,\n                projection=projection,\n            )\n            _download_block_map(\n                block_map=np.nan_to_num(block_loc_count, nan=nodata_val),\n                bounding_rect=bounding_rect,\n                output_image_path=os.path.join(output_image_folder, \"BlockLocalCount\", f\"{out_name}_BlockLocalCount.tif\"),\n                nodata_value=nodata_val,\n                projection=projection,\n            )\n\n        if debug_mode: print(f\"Computing local correction, applying, and saving\")\n        with rasterio.open(img_path) as src:\n            meta = src.meta.copy()\n            meta.update({\"count\": num_bands, \"dtype\": output_dtype, \"nodata\": nodata_val})\n            with rasterio.open(out_path, \"w\", **meta) as dst:\n\n                if tile_width_and_height_tuple:\n                    tw, th = tile_width_and_height_tuple\n                    windows = list(_create_windows(src.width, src.height, tw, th))\n                else:\n                    windows = [Window(0, 0, src.width, src.height)]\n\n                if parallel:\n                    ctx = _choose_context(prefer_fork=True)\n\n                    pool = ProcessPoolExecutor(\n                        max_workers=max_workers,\n                        mp_context=ctx,\n                        initializer=_init_worker,\n                        initargs=(img_path,),\n                    )\n\n                    futures = [\n                        pool.submit(_compute_tile_local,\n                                    w,\n                                    b,\n                                    M,\n                                    N,\n                                    bounding_rect,\n                                    block_ref_mean,\n                                    block_loc_mean,\n                                    nodata_val,\n                                    alpha,\n                                    correction_method,\n                                    calculation_dtype_precision,\n                                    debug_mode,\n                                    )\n                        for b in range(num_bands)\n                        for w in windows\n                    ]\n                    for fut in as_completed(futures):\n                        win, b_idx, buf = fut.result()\n                        dst.write(buf.astype(output_dtype), b_idx + 1, window=win)\n                    pool.shutdown()\n                else:\n                    _init_worker(img_path)\n\n                    for b in range(num_bands):\n                        for win in windows:\n                            win_, b_idx, buf = _compute_tile_local(\n                                win,\n                                b,\n                                M,\n                                N,\n                                bounding_rect,\n                                block_ref_mean,\n                                block_loc_mean,\n                                nodata_val,\n                                alpha,\n                                correction_method,\n                                calculation_dtype_precision,\n                                debug_mode\n                            )\n                            dst.write(buf.astype(output_dtype), b_idx + 1, window=win_)\n    print(\"Finished local matching\")\n    return out_paths\n</code></pre>"},{"location":"api/statistics/","title":"Statistics","text":""},{"location":"api/statistics/#spectralmatch.statistics.compare_spatial_spectral_difference_individual_bands","title":"<code>compare_spatial_spectral_difference_individual_bands(input_overlapping_image_pair_paths, output_image_path)</code>","text":"<p>Compare two overlapping images on a per-band, per-pixel basis and produce a color-coded difference visualization as a PNG image.</p>"},{"location":"api/statistics/#spectralmatch.statistics.compare_spatial_spectral_difference_individual_bands--parameters","title":"Parameters","text":"<p>input_overlapping_image_pair_paths : tuple or list of str A tuple/list of exactly two file paths to the images to compare. output_image_path : str The file path (e.g. \"output.png\") where the resulting visualization will be saved as a PNG.</p> Source code in <code>spectralmatch/statistics.py</code> <pre><code>def compare_spatial_spectral_difference_individual_bands(\n    input_overlapping_image_pair_paths,\n    output_image_path\n    ):\n\n    \"\"\"\n    Compare two overlapping images on a per-band, per-pixel basis and produce\n    a color-coded difference visualization as a PNG image.\n\n    Parameters\n    ----------\n    input_overlapping_image_pair_paths : tuple or list of str\n    A tuple/list of exactly two file paths to the images to compare.\n    output_image_path : str\n    The file path (e.g. \"output.png\") where the resulting visualization will be saved as a PNG.\n    \"\"\"\n    # -------------------------------------------------------------------------\n    # 1. Read the input images as NumPy arrays\n    # -------------------------------------------------------------------------\n    path1, path2 = input_overlapping_image_pair_paths\n    with rasterio.open(path1) as src1, rasterio.open(path2) as src2:\n        img1 = src1.read()  # shape: (num_bands, height, width)\n        img2 = src2.read()  # shape: (num_bands, height, width)\n\n        if img1.shape != img2.shape:\n            raise ValueError(\n                f\"Input images do not have the same shape:\\n\"\n                f\" Image1 shape: {img1.shape}, Image2 shape: {img2.shape}\"\n            )\n\n        num_bands, height, width = img1.shape\n\n    # -------------------------------------------------------------------------\n    # 2. Compute absolute difference per band, per pixel\n    # -------------------------------------------------------------------------\n    diff = np.abs(img1 - img2).astype(np.float32)  # (bands, height, width)\n\n    # -------------------------------------------------------------------------\n    # 3. Compute global min/max difference for optional brightness scaling\n    # -------------------------------------------------------------------------\n    global_min = diff.min()  # often 0\n    global_max = diff.max()\n\n    # -------------------------------------------------------------------------\n    # 4. Assign colors for each band\n    # -------------------------------------------------------------------------\n    # You can assign your own color palette. Below is a simple example:\n    default_colors = [\n        (1.0, 0.0, 0.0),  # Band 1 -&gt; Red\n        (0.0, 1.0, 0.0),  # Band 2 -&gt; Green\n        (0.0, 0.0, 1.0),  # Band 3 -&gt; Blue\n        (1.0, 1.0, 0.0),  # Band 4 -&gt; Yellow\n        (1.0, 0.0, 1.0),  # Band 5 -&gt; Magenta\n        (0.0, 1.0, 1.0),  # Band 6 -&gt; Cyan\n        (1.0, 0.5, 0.0),  # Band 7 -&gt; Orange\n        # etc. Add more if needed\n    ]\n    # If there are more bands than colors, cycle through them\n    band_colors = [default_colors[i % len(default_colors)] for i in range(num_bands)]\n    band_colors = np.array(band_colors, dtype=np.float32)  # shape: (num_bands, 3)\n\n    # -------------------------------------------------------------------------\n    # 5. Create the output visualization (RGB image) by blending band colors\n    #    according to each band\u2019s fraction of the total difference.\n    # -------------------------------------------------------------------------\n    # Initialize an empty float array for RGB: shape = (3, height, width)\n    output_rgb = np.zeros((3, height, width), dtype=np.float32)\n\n    # sum of differences per pixel across all bands -&gt; shape: (height, width)\n    sum_diff = diff.sum(axis=0)\n    sum_diff_safe = np.where(sum_diff == 0, 1e-10, sum_diff)  # avoid division-by-zero\n\n    # fraction_diff[b, y, x] = diff[b, y, x] / sum_diff[y, x]\n    fraction_diff = diff / sum_diff_safe\n\n    # Accumulate weighted colors\n    for b in range(num_bands):\n        # band_colors[b] is shape (3,)\n        # fraction_diff[b] is shape (height, width)\n        output_rgb += fraction_diff[b] * band_colors[b].reshape(3, 1, 1)\n\n    # -------------------------------------------------------------------------\n    # 6. Optionally scale the brightness by overall difference magnitude\n    #    so pixels with greater differences appear brighter.\n    # -------------------------------------------------------------------------\n    brightness = (sum_diff - global_min) / (global_max - global_min + 1e-10)\n    brightness = np.clip(brightness, 0.0, 1.0)\n    # Multiply the RGB by brightness\n    output_rgb *= brightness.reshape(1, height, width)\n\n    # -------------------------------------------------------------------------\n    # 7. Convert to the format expected by matplotlib (height x width x 3)\n    #    and save as a PNG with matplotlib.\n    # -------------------------------------------------------------------------\n    # Currently: output_rgb has shape (3, height, width).\n    # We transpose to (height, width, 3).\n    output_rgb_for_plot = np.transpose(output_rgb, (1, 2, 0))\n\n    # Ensure the data is in 0..1\n    output_rgb_for_plot = np.clip(output_rgb_for_plot, 0, 1)\n\n    # Use plt.imsave to write out a PNG\n    plt.imsave(output_image_path, output_rgb_for_plot)\n\n    print(f\"Saved difference visualization PNG to: {output_image_path}\")\n</code></pre>"},{"location":"examples/benchmark/","title":"Benchmark Mulithreading","text":"In\u00a0[\u00a0]: Copied! <pre>import os, shutil, tempfile, time\nfrom pathlib import Path\n</pre> import os, shutil, tempfile, time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_origin\n</pre> import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.transform import from_origin In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import global_regression, local_block_adjustment\n</pre> from spectralmatch import global_regression, local_block_adjustment In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>def make_fake_rasters(out_dir, n_images, width, height, nodata=0):\n    out_dir = Path(out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n    profile = dict(\n        driver=\"GTiff\",\n        width=width,\n        height=height,\n        count=8,\n        dtype=\"uint16\",\n        nodata=nodata,\n        crs=\"EPSG:3857\",\n        transform=from_origin(0, 0, 1, 1),\n        tiled=True,\n        blockxsize=512,\n        blockysize=512,\n        compress=\"LZW\",\n    )\n    rng = np.random.default_rng(seed=42)\n    paths = []\n    for i in range(n_images):\n        p = out_dir / f\"fake_{i+1}_{width}px.tif\"\n        with rasterio.open(p, \"w\", **profile) as dst:\n            for b in range(1, 9):\n                data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")\n                data[0, 0] = nodata\n                dst.write(data, indexes=b)\n        paths.append(str(p))\n    return paths\n</pre> def make_fake_rasters(out_dir, n_images, width, height, nodata=0):     out_dir = Path(out_dir)     out_dir.mkdir(parents=True, exist_ok=True)     profile = dict(         driver=\"GTiff\",         width=width,         height=height,         count=8,         dtype=\"uint16\",         nodata=nodata,         crs=\"EPSG:3857\",         transform=from_origin(0, 0, 1, 1),         tiled=True,         blockxsize=512,         blockysize=512,         compress=\"LZW\",     )     rng = np.random.default_rng(seed=42)     paths = []     for i in range(n_images):         p = out_dir / f\"fake_{i+1}_{width}px.tif\"         with rasterio.open(p, \"w\", **profile) as dst:             for b in range(1, 9):                 data = rng.integers(1, 1000, size=(height, width), dtype=\"uint16\")                 data[0, 0] = nodata                 dst.write(data, indexes=b)         paths.append(str(p))     return paths In\u00a0[\u00a0]: Copied! <pre>SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288]\nNUM_IMAGES = 2\nTILE_SIZE = (1024, 1024)\nMAX_WORKERS = 32\n</pre> SIZES = [2_048, 4_096, 6_144, 8_192, 10_240, 12_288] NUM_IMAGES = 2 TILE_SIZE = (1024, 1024) MAX_WORKERS = 32 In\u00a0[\u00a0]: Copied! <pre>WORK_DIR = Path(__file__).parent / \"bench_output\"\nWORK_DIR.mkdir(exist_ok=True)\n</pre> WORK_DIR = Path(__file__).parent / \"bench_output\" WORK_DIR.mkdir(exist_ok=True) In\u00a0[\u00a0]: Copied! <pre>SERIAL, PARALLEL = [], []\n</pre> SERIAL, PARALLEL = [], [] In\u00a0[\u00a0]: Copied! <pre>for sz in SIZES:\n    print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")\n    tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))\n    imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)\n\n    t0 = time.time()\n    g_dir = tmp / \"serial_g\"\n    l_dir = tmp / \"serial_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        tile_width_and_height_tuple=TILE_SIZE,\n        parallel=False,\n        debug_mode=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        tile_width_and_height_tuple=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=False,\n        debug_mode=False,\n    )\n    SERIAL.append(time.time() - t0)\n    print(f\"serial   : {SERIAL[-1]:.1f} s\")\n\n    t0 = time.time()\n    g_dir = tmp / \"parallel_g\"\n    l_dir = tmp / \"parallel_l\"\n\n    global_regression(\n        imgs,\n        g_dir,\n        custom_mean_factor=3,\n        custom_std_factor=1,\n        tile_width_and_height_tuple=TILE_SIZE,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_mode=False,\n    )\n    glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))\n\n    local_block_adjustment(\n        [str(p) for p in glob_imgs],\n        l_dir,\n        target_blocks_per_image=100,\n        tile_width_and_height_tuple=TILE_SIZE,\n        custom_nodata_value=-9999,\n        parallel=True,\n        max_workers=MAX_WORKERS,\n        debug_mode=False,\n    )\n    PARALLEL.append(time.time() - t0)\n    print(f\"parallel : {PARALLEL[-1]:.1f} s\")\n\n    shutil.rmtree(tmp, ignore_errors=True)\n</pre> for sz in SIZES:     print(f\"\\n=== {sz} \u00d7 {sz} px  ({NUM_IMAGES} images) ===\")     tmp = Path(tempfile.mkdtemp(prefix=f\"fake_{sz}px_\", dir=WORK_DIR))     imgs = make_fake_rasters(tmp, NUM_IMAGES, sz, sz)      t0 = time.time()     g_dir = tmp / \"serial_g\"     l_dir = tmp / \"serial_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         tile_width_and_height_tuple=TILE_SIZE,         parallel=False,         debug_mode=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         tile_width_and_height_tuple=TILE_SIZE,         custom_nodata_value=-9999,         parallel=False,         debug_mode=False,     )     SERIAL.append(time.time() - t0)     print(f\"serial   : {SERIAL[-1]:.1f} s\")      t0 = time.time()     g_dir = tmp / \"parallel_g\"     l_dir = tmp / \"parallel_l\"      global_regression(         imgs,         g_dir,         custom_mean_factor=3,         custom_std_factor=1,         tile_width_and_height_tuple=TILE_SIZE,         parallel=True,         max_workers=MAX_WORKERS,         debug_mode=False,     )     glob_imgs = sorted((g_dir / \"Images\").glob(\"*.tif\"))      local_block_adjustment(         [str(p) for p in glob_imgs],         l_dir,         target_blocks_per_image=100,         tile_width_and_height_tuple=TILE_SIZE,         custom_nodata_value=-9999,         parallel=True,         max_workers=MAX_WORKERS,         debug_mode=False,     )     PARALLEL.append(time.time() - t0)     print(f\"parallel : {PARALLEL[-1]:.1f} s\")      shutil.rmtree(tmp, ignore_errors=True) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 5))\nplt.plot(SIZES, SERIAL, \"-o\", label=\"serial\")\nplt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\")\nplt.xlabel(\"Raster width = height (pixels)\")\nplt.ylabel(\"Total runtime: global + local (seconds)\")\nplt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(8, 5)) plt.plot(SIZES, SERIAL, \"-o\", label=\"serial\") plt.plot(SIZES, PARALLEL, \"-o\", label=f\"parallel ({MAX_WORKERS} workers)\") plt.xlabel(\"Raster width = height (pixels)\") plt.ylabel(\"Total runtime: global + local (seconds)\") plt.title(\"Pipeline runtime vs. image size (8-band, 2 images)\") plt.grid(True) plt.legend() plt.tight_layout() plt.show()"},{"location":"examples/calculate_statistics/","title":"Calculate Statistics","text":"In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import (\n    compare_spatial_spectral_difference_individual_bands,\n    compare_image_spectral_profiles_pairs,\n    compare_image_spectral_profiles,\n    compare_spatial_spectral_difference_average)\n</pre> from spectralmatch import (     compare_spatial_spectral_difference_individual_bands,     compare_image_spectral_profiles_pairs,     compare_image_spectral_profiles,     compare_spatial_spectral_difference_average) In\u00a0[\u00a0]: Copied! <pre>compare_spatial_spectral_difference_individual_bands(\n    ('/image/a.tif',\n     '/image/b.tif'\n     ),\n    '/output.png'\n)\n</pre> compare_spatial_spectral_difference_individual_bands(     ('/image/a.tif',      '/image/b.tif'      ),     '/output.png' ) In\u00a0[\u00a0]: Copied! <pre>compare_image_spectral_profiles_pairs(\n    {\n        'Image A': [\n            '/image/before/a.tif',\n            'image/after/a.tif'\n        ],\n        'Image B': [\n            '/image/before/b.tif',\n            '/image/after/b.tif'\n        ]\n    },\n    '/output.png'\n)\n</pre> compare_image_spectral_profiles_pairs(     {         'Image A': [             '/image/before/a.tif',             'image/after/a.tif'         ],         'Image B': [             '/image/before/b.tif',             '/image/after/b.tif'         ]     },     '/output.png' ) In\u00a0[\u00a0]: Copied! <pre>compare_image_spectral_profiles(\n    \"Digital Number Spectral Profile Comparison\",\n    'Band',\n    'Digital Number(0-2,047)',\n    {\n        'Image A': 'image/a.tif',\n        'Image B': '/image/b.tif'\n    },\n    \"/output.png\",\n)\n</pre> compare_image_spectral_profiles(     \"Digital Number Spectral Profile Comparison\",     'Band',     'Digital Number(0-2,047)',     {         'Image A': 'image/a.tif',         'Image B': '/image/b.tif'     },     \"/output.png\", ) In\u00a0[\u00a0]: Copied! <pre>compare_spatial_spectral_difference_average(\n    [\n        '/image/a.tif',\n        '/image/a.tif'\n     ],\n    '/output.png'\n)\n</pre> compare_spatial_spectral_difference_average(     [         '/image/a.tif',         '/image/a.tif'      ],     '/output.png' )"},{"location":"examples/example_global_to_local/","title":"Global to Local","text":"In\u00a0[\u00a0]: Copied! <pre>import os\n</pre> import os In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import global_regression, local_block_adjustment\nfrom spectralmatch import merge_rasters\n</pre> from spectralmatch import global_regression, local_block_adjustment from spectralmatch import merge_rasters In\u00a0[\u00a0]: Copied! <pre># -------------------- Parameters\nworking_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"example_data\")\n# This script is setup to perform matching on all tif files from a folder within the working directory called \"input\" e.g. working_directory/input/*.tif.\n</pre> # -------------------- Parameters working_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"example_data\") # This script is setup to perform matching on all tif files from a folder within the working directory called \"input\" e.g. working_directory/input/*.tif. In\u00a0[\u00a0]: Copied! <pre>vector_mask_path = working_directory + \"/Input/Masks.gpkg\"\n</pre> vector_mask_path = working_directory + \"/Input/Masks.gpkg\" In\u00a0[\u00a0]: Copied! <pre>input_folder = os.path.join(working_directory, \"Input\")\nglobal_folder = os.path.join(working_directory, \"Output/GlobalMatch\")\nlocal_folder = os.path.join(working_directory, \"Output/LocalMatch\")\n</pre> input_folder = os.path.join(working_directory, \"Input\") global_folder = os.path.join(working_directory, \"Output/GlobalMatch\") local_folder = os.path.join(working_directory, \"Output/LocalMatch\") In\u00a0[\u00a0]: Copied! <pre># -------------------- Global histogram matching\ninput_image_paths_array = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")]\n</pre> # -------------------- Global histogram matching input_image_paths_array = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.lower().endswith(\".tif\")] In\u00a0[\u00a0]: Copied! <pre>matched_global_images_paths = global_regression(\n    input_image_paths_array,\n    global_folder,\n    custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together\n    custom_std_factor = 1,\n    # vector_mask_path=vector_mask_path,\n    debug_mode=False,\n    tile_width_and_height_tuple=(512, 512),\n    parallel=True,\n    custom_nodata_value=-9999,\n    )\n</pre> matched_global_images_paths = global_regression(     input_image_paths_array,     global_folder,     custom_mean_factor = 3, # Defualt 1; 3 often works better to 'move' the spectral mean of images closer together     custom_std_factor = 1,     # vector_mask_path=vector_mask_path,     debug_mode=False,     tile_width_and_height_tuple=(512, 512),     parallel=True,     custom_nodata_value=-9999,     ) In\u00a0[\u00a0]: Copied! <pre>merge_rasters(\n    matched_global_images_paths, # Rasters are layered with the last ones on top\n    os.path.join(working_directory, \"Output/GlobalMatch/MatchedGlobalImages.tif\"),\n    tile_width_and_height_tuple=(512, 512),\n    )\n</pre> merge_rasters(     matched_global_images_paths, # Rasters are layered with the last ones on top     os.path.join(working_directory, \"Output/GlobalMatch/MatchedGlobalImages.tif\"),     tile_width_and_height_tuple=(512, 512),     ) In\u00a0[\u00a0]: Copied! <pre># -------------------- Local histogram matching\nglobal_image_paths_array = [os.path.join(f\"{global_folder}/Images\", f) for f in os.listdir(f\"{global_folder}/Images\") if f.lower().endswith(\".tif\")]\n</pre> # -------------------- Local histogram matching global_image_paths_array = [os.path.join(f\"{global_folder}/Images\", f) for f in os.listdir(f\"{global_folder}/Images\") if f.lower().endswith(\".tif\")] In\u00a0[\u00a0]: Copied! <pre>matched_local_images_paths = local_block_adjustment(\n    global_image_paths_array,\n    local_folder,\n    target_blocks_per_image=100,\n    projection=\"EPSG:6635\",\n    debug_mode=False,\n    tile_width_and_height_tuple=(512, 512),\n    parallel=True,\n    custom_nodata_value=-9999,\n    )\n</pre> matched_local_images_paths = local_block_adjustment(     global_image_paths_array,     local_folder,     target_blocks_per_image=100,     projection=\"EPSG:6635\",     debug_mode=False,     tile_width_and_height_tuple=(512, 512),     parallel=True,     custom_nodata_value=-9999,     ) In\u00a0[\u00a0]: Copied! <pre>merge_rasters(\n    matched_local_images_paths, # Rasters are layered with the last ones on top\n    os.path.join(working_directory, \"Output/LocalMatch/MatchedLocalImages.tif\"),\n    tile_width_and_height_tuple=(512, 512),\n    )\n</pre> merge_rasters(     matched_local_images_paths, # Rasters are layered with the last ones on top     os.path.join(working_directory, \"Output/LocalMatch/MatchedLocalImages.tif\"),     tile_width_and_height_tuple=(512, 512),     ) In\u00a0[\u00a0]: Copied! <pre>print(\"Done with global and local histogram matching\")\n</pre> print(\"Done with global and local histogram matching\")"},{"location":"examples/mask_cloud/","title":"Cloud Masking","text":"In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import (\n    create_cloud_mask_with_omnicloudmask,\n    post_process_raster_cloud_mask_to_vector,\n)\n</pre> from spectralmatch import (     create_cloud_mask_with_omnicloudmask,     post_process_raster_cloud_mask_to_vector, ) In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import write_vector\n</pre> from spectralmatch import write_vector In\u00a0[\u00a0]: Copied! <pre>create_cloud_mask_with_omnicloudmask(\n    \"input_image_path.tif\",\n    5,\n    3,\n    8,\n    \"output_mask&gt;path.tif\",\n    down_sample_m=10\n)\nwrite_vector(\n    post_process_raster_cloud_mask_to_vector(\n        \"input_image_path.tif\",\n        None,\n        {1: 50},\n        {0: 0, 1: 1, 2: 1, 3: 1}\n    ),\n    \"output_vector_path.tif\",\n)\n</pre> create_cloud_mask_with_omnicloudmask(     \"input_image_path.tif\",     5,     3,     8,     \"output_mask&gt;path.tif\",     down_sample_m=10 ) write_vector(     post_process_raster_cloud_mask_to_vector(         \"input_image_path.tif\",         None,         {1: 50},         {0: 0, 1: 1, 2: 1, 3: 1}     ),     \"output_vector_path.tif\", )"},{"location":"examples/mask_ndvi/","title":"Mask ndvi","text":"In\u00a0[\u00a0]: Copied! <pre>from spectralmatch import (\n    create_ndvi_mask,\n    post_process_threshold_to_vector\n)\n</pre> from spectralmatch import (     create_ndvi_mask,     post_process_threshold_to_vector ) In\u00a0[\u00a0]: Copied! <pre>create_ndvi_mask(\n    \"input_image_path.tif\",\n    \"output_image_path.tif\",\n    4,\n    3,\n)\npost_process_threshold_to_vector(\n    \"input_image_path.tif\",\n    'output_vector_path.gpkg',\n    0.2,\n    \"&lt;=\",\n)\n</pre> create_ndvi_mask(     \"input_image_path.tif\",     \"output_image_path.tif\",     4,     3, ) post_process_threshold_to_vector(     \"input_image_path.tif\",     'output_vector_path.gpkg',     0.2,     \"&lt;=\", )"}]}